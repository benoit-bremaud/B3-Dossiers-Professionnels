# Dossier Professionnel â€“ Titre Professionnel Concepteur DÃ©veloppeur dâ€™Applications (NiveauÂ 6, RNCPÂ 37873)

## DÃ©claration sur l'honneur

Je soussignÃ© **BenoÃ®t BrÃ©maud**, candidat au titre professionnel **Concepteur DÃ©veloppeur dâ€™Applications**, dÃ©clare sur l'honneur que ce dossier professionnel est le fruit dâ€™un travail personnel. Le projet prÃ©sentÃ© et les exemples de pratique professionnelle dÃ©crits sont issus de **mon expÃ©rience rÃ©elle** dans le cadre de ma formation et ne sont pas des reproductions du travail dâ€™autrui. Je m'engage Ã  respecter le rÃ¨glement de l'examen et atteste de l'authenticitÃ© des informations et documents fournis dans ce dossier. Fait pour servir et valoir ce que de droit, je certifie exacts les renseignements figurant dans ce document, **datÃ©** et **signÃ©** par mes soins.

## Informations du candidat

* **Nom PrÃ©nomÂ :** BenoÃ®t BrÃ©maud
* **Titre professionnel visÃ©Â :** Concepteur DÃ©veloppeur dâ€™Applications â€“ NiveauÂ 6 (Code RNCPÂ 37873)
* **DiplÃ´me ou niveau dâ€™Ã©tude le plus Ã©levÃ©Â :** BTS Services Informatiques aux Organisations (Option SLAM) â€“ 2015 *(Ã©quivalent Bac+2)*
* **ExpÃ©rience professionnelleÂ :** DÃ©veloppeur indÃ©pendant sur projets personnels (2 ans) et formation intensive en dÃ©veloppement dâ€™applications (2024)

## PrÃ©sentation du projet support â€“ *Â«Â Brasse-BouillonÂ Â»*

Pour illustrer mes compÃ©tences, jâ€™ai choisi de mâ€™appuyer sur mon projet de fin de formation intitulÃ© **Brasse-Bouillon**. Il sâ€™agit dâ€™une application web et mobile open-source visant Ã  aider les **brasseurs amateurs** Ã  gÃ©rer et partager leurs recettes de biÃ¨re maison. Ce projet a Ã©tÃ© rÃ©alisÃ© **en autonomie** dans un contexte Agile (inspiration Scrum) sur une durÃ©e de 4 mois. Brasse-Bouillon se dÃ©compose en une application mobile multiplateforme (basÃ©e sur **React Native**) et une API web sÃ©curisÃ©e (**Node.js/Express**), le tout adossÃ© Ã  une base de donnÃ©es **MySQL**. Lâ€™application fournit des outils essentiels pour calculer les paramÃ¨tres de brassage (degrÃ©s alcool, amertume â€“ **ABV/IBU**), planifier les sessions de brassage et suivre lâ€™Ã©volution des cuvÃ©es.

**FonctionnalitÃ©s principalesÂ :** crÃ©ation et gestion de recettes (CRUD complet), calcul automatique de lâ€™IBU et de lâ€™ABV Ã  partir des ingrÃ©dients saisis, suivi des sessions de brassage avec calendrier, authentification sÃ©curisÃ©e des utilisateurs, et partage communautaire des recettes. Ã€ terme, le projet envisage dâ€™intÃ©grer des capteurs **IoT** pour suivre la tempÃ©rature des cuves en temps rÃ©el, ainsi quâ€™un module de notifications pour rappeler les Ã©tapes clÃ©s (Ã©bullition, fermentation) aux brasseurs. Le dÃ©veloppement sâ€™est dÃ©roulÃ© en plusieurs **phases** itÃ©ratives, couvrant lâ€™analyse du besoin (PhaseÂ 1Â : Initialisation), la conception technique (PhaseÂ 2), le dÃ©veloppement (PhaseÂ 3), les tests (PhaseÂ 4), le dÃ©ploiement (PhaseÂ 5) et enfin la soutenance (PhaseÂ 6). Chacune de ces phases sera Ã©voquÃ©e dans les exemples de pratiques professionnelles qui suivent.

**Contexte et organisationÂ :** Jâ€™ai adoptÃ© une mÃ©thodologie **Agile Scrum** avec des sprints de 2 semaines, un backlog produit gÃ©rÃ© sur GitHub Projects, et des rÃ©unions rapides (*daily stand-up*) pour suivre lâ€™avancement. Travaillant seul sur ce projet, jâ€™ai nÃ©anmoins simulÃ© un environnement collaboratifÂ : utilisation de GitHub pour le versioning et la revue de code, gestion des tÃ¢ches via des issues et milestones, et documentation continue dans un dossier `docs/` structurÃ©. Mon rÃ´le a couvert lâ€™ensemble des activitÃ©s du cycle de vie applicatif, depuis la rÃ©daction du **cahier des charges** jusquâ€™au **dÃ©ploiement**. Tout au long du projet, jâ€™ai veillÃ© Ã  respecter les normes de sÃ©curitÃ© (exÂ : recommandations OWASP et guides de lâ€™ANSSI) et dâ€™**accessibilitÃ©** (RGAA) ainsi quâ€™Ã  appliquer les principes dâ€™**Ã©co-conception** logicielle (code optimisÃ©, fonctionnalitÃ©s offline pour limiter les sollicitations rÃ©seau inutiles, etc.).

Dans les sections qui suivent, je dÃ©cris **trois exemples de pratique professionnelle**, chacun en lien avec lâ€™un des **blocs de compÃ©tences (activitÃ©s-types)** du rÃ©fÃ©rentielÂ CDAÂ 2024. Chacun de ces exemples sera illustrÃ© par des cas concrets issus du projet Brasse-Bouillon, en mettant en avant les compÃ©tences techniques mobilisÃ©es, les outils utilisÃ©s, les extraits de code significatifs, ainsi que mes choix et dÃ©marches professionnelles. Ce dossier tÃ©moigne de ma capacitÃ© Ã  **dÃ©velopper une application sÃ©curisÃ©e** (ActivitÃ©-typeÂ 1), Ã  **concevoir et dÃ©velopper une application organisÃ©e en couches** (ActivitÃ©-typeÂ 2), et Ã  **prÃ©parer le dÃ©ploiement dâ€™une application** (ActivitÃ©-typeÂ 3), le tout dans une dÃ©marche professionnelle conforme au rÃ©fÃ©rentiel du titre visÃ©.

---

## ActivitÃ©-typeÂ 1Â : DÃ©velopper une application sÃ©curisÃ©e

*(**Bloc de compÃ©tences 1Â :** PrÃ©parer lâ€™environnement de travail ; DÃ©velopper des interfaces utilisateur ; DÃ©velopper des composants mÃ©tier ; Contribuer Ã  la gestion du projet informatique â€“ en veillant Ã  la sÃ©curitÃ© et Ã  la qualitÃ© logicielle)*

**ContexteÂ :** Cette premiÃ¨re activitÃ©-type couvre lâ€™ensemble de la phase de **dÃ©veloppement** de lâ€™application Brasse-Bouillon (PhasesÂ 2 etÂ 3 du projet, conception dÃ©taillÃ©e et codage). Dans le cadre de mon projet, cela sâ€™est traduit par la mise en place dâ€™un **environnement de dÃ©veloppement complet**, le dÃ©veloppement du **front-end mobile** (interfaces utilisateur) et du **back-end** (composants mÃ©tier et API REST), tout en appliquant les bonnes pratiques de codage sÃ©curisÃ©. Par ailleurs, jâ€™ai participÃ© activement Ã  la **gestion du projet** au quotidienÂ : planification des tÃ¢ches, communication au sein de lâ€™Ã©quipe (mÃªme si rÃ©duite Ã  moi-mÃªme, jâ€™ai simulÃ© des Ã©changes professionnels avec tuteurs/clients), suivi des issues et adaptation aux imprÃ©vus. Je dÃ©taille ci-dessous ces rÃ©alisations.

### Installation et configuration de lâ€™environnement de travail (poste de dÃ©veloppement)

DÃ¨s le lancement du projet, jâ€™ai prÃ©parÃ© un environnement de travail **similaire Ã  lâ€™environnement de production** prÃ©vu. ConformÃ©ment aux bonnes pratiques, jâ€™ai installÃ© et configurÃ© sur mon poste tous les outils et dÃ©pendances nÃ©cessaires au dÃ©veloppementÂ :

* **Node.js 18** (avec NPM) pour le runtime JavaScript backend, et **Expo CLI** pour le dÃ©veloppement ReactÂ Native cÃ´tÃ© mobile.
* **IDE (Visual Studio Code)** avec extensions ESLint/Prettier pour le linting et le formatage automatique du code, assurant un style uniforme.
* **SGBD MySQL** en local pour reproduire la base de donnÃ©es de production. Jâ€™ai utilisÃ© Docker pour dÃ©ployer rapidement un conteneur MySQL et Ã©viter les Ã©carts de configuration. En effet, jâ€™ai privilÃ©giÃ© une installation via **Docker Compose** pour aligner mon poste de dev sur une stack proche de la prodÂ : un service backend Node, un service base de donnÃ©es MySQL, un cache Redis, etc.. Cela mâ€™a permis de paramÃ©trer un environnement isolÃ© oÃ¹ lâ€™API tournait sur un port local (3000) avec accÃ¨s Ã  une base **brasse\_bouillon** dÃ©diÃ©e, similaire Ã  ce qui sera utilisÃ© en production. Par exemple, le fichier de configuration Sequelize se connecte sur lâ€™hÃ´te `db` (dÃ©clarÃ© dans Docker Compose) avec les identifiants de la baseÂ .
* **Outils de versionnement et collaborationÂ :** Git et GitHub. Jâ€™ai crÃ©Ã© un dÃ©pÃ´t GitHub privÃ© pour le code source et configurÃ© le gestionnaire de versions dÃ¨s le dÃ©part du projet. Chaque nouvelle fonctionnalitÃ© a Ã©tÃ© dÃ©veloppÃ©e sur une branche dÃ©diÃ©e (selon la convention de nommage AngularÂ : par ex. `feat/frontend-add-login-screen` pour lâ€™ajout de lâ€™Ã©cran de login). Jâ€™ai ainsi pu suivre un workflow professionnel *GitFlow* adaptÃ©Â : branches `develop` et `main`, pull requests pour fusionner les contributions, commits normalisÃ©s (messages de commit de type *feat*, *fix*, *chore*â€¦ selon Conventional Commits) et rÃ©fÃ©rences aux issues (exÂ : *Closes #12* dans un message de merge).
* **Outils de test et de documentationÂ :** installation de **Jest** (cÃ´tÃ© front et back) pour les tests unitaires, et de **Postman** pour tester manuellement les endpoints de lâ€™API. Jâ€™ai Ã©galement installÃ© **Swagger** (OpenAPI) pour documenter les endpoints REST pendant le dÃ©veloppement, et utilisÃ© **Figma** en parallÃ¨le pour les maquettes UI. Lâ€™ensemble de ces outils et technologies a Ã©tÃ© listÃ© et validÃ© en dÃ©but de projet, formant la â€œboÃ®te Ã  outilsâ€ du dÃ©veloppeur en phase de build.

Une fois les outils en place, jâ€™ai **configurÃ© les variables dâ€™environnement** (fichier `.env`) pour centraliser les paramÃ¨tres sensiblesÂ : par exemple, la connexion BDD (host, user, password) et la clÃ© secrÃ¨te JWT. Cela permet de respecter les exigences de sÃ©curitÃ© (ne pas hardcoder ces informations dans le code source). Lâ€™environnement de travail a donc Ã©tÃ© prÃ©parÃ© de maniÃ¨re **structurÃ©e et sÃ©curisÃ©e** afin que le dÃ©veloppement puisse dÃ©marrer sur de bonnes bases, en minimisant les Ã©carts avec la cible de production. Cette Ã©tape prÃ©liminaire, bien que parfois fastidieuse, mâ€™a Ã©vitÃ© de nombreux problÃ¨mes dâ€™environnement par la suite (dÃ©pendances manquantes, â€œworks on my machineâ€ syndrome, etc.), illustrant ma compÃ©tence Ã  **installer et configurer un environnement de dÃ©veloppement complet**.

### DÃ©veloppement des interfaces utilisateur (Front-end mobile multiplateforme)

Sur Brasse-Bouillon, lâ€™interface utilisateur est une **application mobile** dÃ©veloppÃ©e avec **React Native** (Expo). Lâ€™objectif Ã©tait de proposer une expÃ©rience fluide aux brasseurs amateurs sur smartphone, avec une UI claire respectant la charte graphique du projet. Je me suis appuyÃ© sur les maquettes conÃ§ues sous Figma (Ã©crans Â«Â AccueilÂ Â», Â«Â Liste des recettesÂ Â», Â«Â DÃ©tail recetteÂ Â», Â«Â Nouvelle recetteÂ Â», etc.) pour guider le dÃ©veloppement des composants visuels.

**ImplÃ©mentation des Ã©cransÂ :** Jâ€™ai crÃ©Ã© diffÃ©rents composants ReactÂ Native pour structurer lâ€™application en **pages fonctionnelles**. Par exempleÂ : un composant `<HomeScreen>` pour lâ€™Ã©cran dâ€™accueil, `<RecipeListScreen>` pour la liste de recettes, `<RecipeForm>` pour le formulaire de crÃ©ation/Ã©dition, etc. Chaque Ã©cran est stylÃ© via Stylesheet en respectant la charte (couleurs, typographies) dÃ©finie dans le fichier `charte_graphique.md`. Sur lâ€™Ã©cran dâ€™accueil, jâ€™affiche par exemple le logo de lâ€™application et un message de bienvenue, avec un appel API de test Ã  lâ€™ouvertureÂ :

```jsx
// Extrait simplifiÃ© de HomeScreen.tsx (frontend)
useEffect(() => {
  api.get('/ping')
    .then(res => console.log('âœ… RÃ©ponse API :', res.data))
    .catch(err => console.error('âŒ Erreur API :', err.message));
}, []);

return (
  <View style={styles.container}>
    <Image source={require('../assets/icon.png')} style={styles.logo} />
    <Text style={styles.title}>Bienvenue sur Brasse-Bouillon ğŸ»</Text>
    <Text style={styles.subtitle}>Lâ€™application dÃ©diÃ©e aux brasseurs amateursÂ !</Text>
  </View>
);
```

*(Code React Native â€“ lâ€™Ã©cran Home effectue un appel Ã  lâ€™API `/ping` dÃ¨s son montage, puis affiche un titre et un sous-titre de bienvenue)*.

Cet extrait illustre plusieurs points de compÃ©tenceÂ : **intÃ©gration front-back** (appel dâ€™un service API via `api.get` grÃ¢ce Ã  un module `api.js/ts` configurÃ© avec Axios), **dÃ©veloppement dâ€™une interface utilisateur responsive** (conteneur centrÃ©, image logo, textes stylÃ©s). Jâ€™ai veillÃ© Ã  adapter lâ€™UI pour diffÃ©rents terminauxÂ : lâ€™appli supporte le **mode sombre** et lâ€™orientation portrait/paysage grÃ¢ce aux styles dynamiques Expo, et jâ€™ai testÃ© le rendu sur simulateur iOS et Android. Pour garantir lâ€™**accessibilitÃ©**, jâ€™ai utilisÃ© des composants standards (Text, Button) qui supportent les technologies dâ€™assistance, et je me suis assurÃ© que les contrastes de couleurs respectent les recommandations WCAG (exÂ : texte gris #666 sur fond Ã©cru #fffdf7 pour un contraste suffisant). Jâ€™ai aussi intÃ©grÃ© quelques *accessibility labels* sur les boutons/icÃ´nes critiques pour les lecteurs dâ€™Ã©cran.

**Navigation et Ã©tatÂ :** Lâ€™application utilise **Expo Router** (basÃ© sur React Navigation) pour gÃ©rer la navigation entre les Ã©crans. Jâ€™ai configurÃ© un systÃ¨me dâ€™onglets (tabs) pour les sections principales (Recettes, Sessions, Profil) et une pile de navigation pour les Ã©crans dÃ©taillÃ©s. Le **state management** est gÃ©rÃ© simplement via le hook `useState` et le contexte React pour partager certains Ã©tats globaux (exÂ : informations de lâ€™utilisateur connectÃ©). Par exemple, aprÃ¨s le login, le token JWT est stockÃ© de maniÃ¨re sÃ©curisÃ©e (stockage sÃ©curisÃ© Expo ou HttpOnly cookie si web) et un contexte `AuthContext` fournit lâ€™utilisateur courant aux composants, Ã©vitant de redemander lâ€™API Ã  chaque fois.

**Composants rÃ©utilisablesÂ :** Dans une dÃ©marche dâ€™optimisation, jâ€™ai dÃ©veloppÃ© quelques composants gÃ©nÃ©riques comme un composant `<RecipeCard>` pour afficher une recette de maniÃ¨re uniforme (titre, auteur, IBU/ABV calculÃ©s, etc.), ou un `<IngredientItem>` pour lister les ingrÃ©dients avec quantitÃ©s. Ces composants sont stylÃ©s de faÃ§on cohÃ©rente grÃ¢ce Ã  une **Design System maison**Â : palette de couleurs, tailles de police, marges, tout est centralisÃ© dans un fichier de constantes afin dâ€™assurer une homogÃ©nÃ©itÃ© (par ex. `constants/Colors.ts` dÃ©finit les couleurs primaires/secondaires utilisÃ©es dans lâ€™app). Cette rationalisation facilite la maintenanceÂ : si la charte graphique Ã©volue, je sais oÃ¹ modifier sans tout parcourir.

Enfin, jâ€™ai veillÃ© Ã  ce que les interfaces utilisateur soient **sÃ©curisÃ©es** et robustesÂ : validation des saisies cÃ´tÃ© front (exÂ : vÃ©rification des champs obligatoires dans le formulaire de recette, avec affichage de messages dâ€™erreur utilisateur clairs), dÃ©sactivation des boutons tant quâ€™une action rÃ©seau nâ€™est pas terminÃ©e (pour Ã©viter les doubles soumissions), etc. Par exemple, lors de la crÃ©ation dâ€™une recette, si un champ important est manquant, le front empÃªche lâ€™envoi et affiche une alerte, plutÃ´t que de laisser lâ€™API rÃ©pondre une erreur 400. Ces petites attentions contribuent Ã  la **qualitÃ© perÃ§ue** et Ã  la sÃ©curitÃ© (on limite ainsi les cas de figure non prÃ©vus cÃ´tÃ© serveur).

**Illustration visuelleÂ :** Ci-dessous une capture (fictive) de lâ€™Ã©cran *Liste des recettes* montrant lâ€™interface mobile rÃ©alisÃ©eÂ : on y voit la liste des recettes de lâ€™utilisateur avec leur nom, style, et une icÃ´ne indiquant si la recette est publique ou privÃ©e. En haut, un bouton *Ajouter* permet de crÃ©er une nouvelle recette. *(Capture non incluse dans ce texte)* Cette interface respecte la maquette validÃ©e lors de la phase de conception et dÃ©montre ma capacitÃ© Ã  **dÃ©velopper des interfaces web/mobile ergonomiques** alignÃ©es sur les besoins utilisateurs.

### DÃ©veloppement des composants mÃ©tiers et de lâ€™API (Back-end Node.js)

En parallÃ¨le du front-end, jâ€™ai **dÃ©veloppÃ© le backend** de lâ€™application en **Node.js** avec le framework **Express**. Ce serveur REST est le cÅ“ur â€œmÃ©tierâ€ de Brasse-BouillonÂ : il expose des **endpoints HTTP** permettant au front de crÃ©er des utilisateurs, de gÃ©rer les recettes, de lancer des sessions de brassage, etc. Lâ€™accent a Ã©tÃ© mis sur la **sÃ©curitÃ©** et la propretÃ© du code, en suivant une approche structurÃ©e proche du modÃ¨le MVC (ModÃ¨le-Vue-ContrÃ´leur, la â€œVueâ€ Ã©tant ici le front sÃ©parÃ©).

**Structure du backendÂ :** Le code est organisÃ© en modules clairs, conformÃ©ment au plan dâ€™architecture backend que jâ€™ai rÃ©digÃ©. On retrouve notammentÂ :

* Un dossier **`controllers/`** contenant la logique mÃ©tier pour chaque entitÃ© (exÂ : `recipeController.js` gÃ¨re les opÃ©rations CRUD des recettes).
* Un dossier **`models/`** dÃ©finissant les modÃ¨les de donnÃ©es via lâ€™ORM **Sequelize** (par ex. `Recipe.js`, `User.js`, etc., qui mappent les tables SQL correspondantes).
* Un dossier **`routes/`** oÃ¹ sont dÃ©clarÃ©es les routes Express et les **middlewares** associÃ©s. Jâ€™ai par exemple un fichier `recipes.js` qui associe les URL `/recipes` aux fonctions du recipeController, en intercalant un middleware dâ€™authentification JWT pour sÃ©curiser les opÃ©rations sensibles (crÃ©ation/Ã©dition/suppression de recette).
* Un dossier **`middlewares/`** contenant les fonctions de middleware globales, notamment `verifyToken` pour la vÃ©rification du JWT sur les routes privÃ©es, et un middleware de **logging** des requÃªtes (utilisant `morgan` pour tracer chaque requÃªte entrante, utile en debug).
* Un dossier **`config/`** pour la configuration de la base de donnÃ©es (fichier `database.js` vu plus haut) et dâ€™autres services (par ex. config de Redis, bien que celui-ci soit facultatif en dev).
* Un dossier **`tests/`** pour dâ€™Ã©ventuels tests automatisÃ©s backend (par ex. `sample.test.js` montre la configuration Jest opÃ©rationnelle).

Cette architecture modulaire rend le code plus **maintenable et Ã©volutif**, et facilite la **rÃ©partition des responsabilitÃ©s**. Jâ€™ai veillÃ© Ã  la respecter au maximumÂ : par exemple, la logique de calcul de lâ€™ABV/IBU est encapsulÃ©e dans un **service mÃ©tier** (fonction utilitaire dans `utils/calculations.js`), appelÃ© depuis le controller de recettes lors de la crÃ©ation dâ€™une recette pour calculer ces valeurs automatiquement. Ainsi, si demain on veut rÃ©utiliser ces calculs ailleurs (exÂ : pour simuler une recette sans la crÃ©er), on pourra appeler la mÃªme fonction.

**Gestion de la base de donnÃ©esÂ :** GrÃ¢ce Ã  Sequelize, jâ€™ai pu dÃ©finir mes modÃ¨les simplement en JavaScript. Par exemple, le modÃ¨le `Recipe` comprend des champs `name, description, abv, ibu, userId` etc., et dÃ©clare une association `Recipe.belongsTo(User)` et `Recipe.belongsToMany(Ingredient, through: RecipeIngredient)`. Jâ€™ai implÃ©mentÃ© les principales entitÃ©s du modÃ¨le conceptuel Ã©laborÃ© en conceptionÂ : Utilisateur, Recette, IngrÃ©dient, Session de brassage (BrewSession), Commentaire, Note, Ã‰quipement, Notificationâ€¦ Toutes ne sont pas encore actives dans le MVP, mais la base est prÃªte Ã  les accueillir. Jâ€™ai Ã©galement mis en place les **contraintes dâ€™intÃ©gritÃ©** nÃ©cessaires au niveau baseÂ : clÃ©s Ã©trangÃ¨res avec *ON DELETE CASCADE* pour que la suppression dâ€™un utilisateur entraÃ®ne celle de ses recettes automatiquement (vÃ©rifiÃ© via un test en PhaseÂ 4), contraintes dâ€™unicitÃ© sur certains champs (email utilisateur unique), etc. Durant le dÃ©veloppement, jâ€™ai utilisÃ© **SQLite en mÃ©moire** pour exÃ©cuter certains tests unitaires plus rapidement, et une base MySQL dÃ©diÃ©e pour les tests dâ€™intÃ©gration lourds.

**Endpoints et logique mÃ©tierÂ :** Jâ€™ai dÃ©veloppÃ© lâ€™ensemble des endpoints requis pour le MVP, en suivant les bonnes pratiques REST (noms de ressources au pluriel, statuts HTTP appropriÃ©sâ€¦). Par exemple, pour lâ€™entitÃ© RecetteÂ :

* `GET /recipes`Â : retourne la liste des recettes (publiques ou appartenant Ã  lâ€™utilisateur connectÃ©). Jâ€™ai implÃ©mentÃ© la recherche de toutes les recettes via `Recipe.findAll()` de Sequelize, en renvoyant un status 200 et les donnÃ©es JSON.
* `GET /recipes/:id`Â : retourne le dÃ©tail dâ€™une recette, y compris la liste de ses ingrÃ©dients. Cela utilise la capacitÃ© de Sequelize Ã  *eager-load* les relationsÂ : on inclut le modÃ¨le Ingredient dans la requÃªte, via une jointure automatique. Si lâ€™ID nâ€™existe pas, on renvoie un 404 Not Found.
* `POST /recipes`Â : crÃ©ation dâ€™une nouvelle recette. Cette route est protÃ©gÃ©e par JWT (il faut Ãªtre authentifiÃ©). Dans le controller, je rÃ©cupÃ¨re lâ€™ID utilisateur depuis `req.user` injectÃ© par le middleware JWT. Je vÃ©rifie Ã©galement la prÃ©sence des champs obligatoires (`name`, `description`) et renvoie une erreur 400 en JSON si manquants. Ensuite je crÃ©e la recette en base avec `Recipe.create`. Sâ€™il y a des ingrÃ©dients passÃ©s dans le corps, jâ€™utilise `RecipeIngredient.bulkCreate` pour insÃ©rer efficacement toutes les associations en une seule requÃªte. En sortie, je renvoie un status 201 Created avec un petit message de succÃ¨s et la recette crÃ©Ã©e. Cette crÃ©ation illustre la **mise en Å“uvre dâ€™une logique mÃ©tier sÃ©curisÃ©e**Â : seuls les utilisateurs connectÃ©s peuvent crÃ©er, leur identitÃ© est liÃ©e Ã  la recette, et des validations empÃªchent les donnÃ©es incomplÃ¨tes.
* `PUT /recipes/:id`Â : mise Ã  jour dâ€™une recette existante. Ici jâ€™ai mis un point dâ€™honneur Ã  **sÃ©curiser lâ€™opÃ©ration**Â : je rÃ©cupÃ¨re la recette en base, puis je vÃ©rifie que le **propriÃ©taire** de la recette correspond Ã  lâ€™utilisateur appelant (et Ã©ventuellement, on pourrait autoriser un rÃ´le admin). Si ce nâ€™est pas le cas, je renvoie un 403 Forbidden. Ainsi, un utilisateur malintentionnÃ© ne peut pas modifier la recette de quelquâ€™un dâ€™autre en devinant son ID, ce qui est une faille courante que jâ€™ai pris soin dâ€™Ã©viter. AprÃ¨s cette vÃ©rification, je mets Ã  jour uniquement les champs prÃ©sents dans la requÃªte (pour permettre des modifications partielles) puis je recalcule Ã©ventuellement les ingrÃ©dients associÃ©sÂ : par simplicitÃ©, jâ€™ai choisi de supprimer toutes les anciennes associations `RecipeIngredient` et dâ€™insÃ©rer la nouvelle liste reÃ§ue. Enfin, je renvoie la recette mise Ã  jour avec ses nouveaux ingrÃ©dients. Ce processus garantit lâ€™intÃ©gritÃ© des donnÃ©es (pas de doublons ou de restes dâ€™anciennes liaisons).
* `DELETE /recipes/:id`Â : suppression dâ€™une recette. LÃ  encore, je vÃ©rifie lâ€™ownership avant de dÃ©truire lâ€™objet. GrÃ¢ce aux *cascade delete*, toutes les entrÃ©es associÃ©es (les ingrÃ©dients de la recette, les commentaires, etc.) sont supprimÃ©es automatiquement en base, ce qui simplifie la logique cÃ´tÃ© serveur tout en maintenant la cohÃ©rence.

Outre les recettes, jâ€™ai implÃ©mentÃ© de faÃ§on similaire les endpoints pour les utilisateurs (`/auth/register`, `/auth/login`, `/auth/me`â€¦), pour les sessions de brassage (`/sessions`), etc., en respectant Ã  chaque fois la logique mÃ©tier et les contrÃ´les de sÃ©curitÃ© nÃ©cessaires. Par exemple, lâ€™endpoint de **login** gÃ©nÃ¨re un **JWT** signÃ© cÃ´tÃ© serveur et le renvoie au clientÂ : jâ€™utilise la librairie `jsonwebtoken` pour crÃ©er un token contenant lâ€™ID, lâ€™email et le rÃ´le de lâ€™utilisateur, avec une expiration de 24h. Le mot de passe fourni est vÃ©rifiÃ© avec **bcrypt** (hachage sÃ©curisÃ© stockÃ© en base). Pour les routes sensibles, jâ€™ai crÃ©Ã© un middleware `verifyToken` qui intercepte le header *Authorization* et valide le JWTÂ ; sâ€™il est expirÃ© ou invalide, on renvoie un 401 Unauthorized. Jâ€™ai Ã©galement prÃ©vu un middleware de contrÃ´le de **rÃ´le** (par ex. `verifyRole('admin')`) pour certaines opÃ©rations admin Ã©ventuellement. Ainsi, la sÃ©curisation est **dÃ©fensive** et implÃ©mentÃ©e Ã  plusieurs niveaux (frontend ET backend).

**QualitÃ© du codeÂ :** Tout au long du dÃ©veloppement des composants mÃ©tier, jâ€™ai documentÃ© et formatÃ© mon code de maniÃ¨re professionnelle. Par exemple, jâ€™ai rÃ©digÃ© des **commentaires JSDoc** au-dessus de chaque handler de route (voir `/** ... */` dans lâ€™extrait du controller recettes) pour expliquer son rÃ´le, ses paramÃ¨tres et le comportement attendu. Ces commentaires pourront servir plus tard Ã  gÃ©nÃ©rer une documentation API automatisÃ©e. Jâ€™ai appliquÃ© un style de code cohÃ©rent grÃ¢ce Ã  **ESLint** (configurÃ© selon les recommandations Airbnb/Prettier)Â : toute erreur de lint Ã©tait corrigÃ©e immÃ©diatement, et lâ€™outil formatait le code au fur et Ã  mesure pour quâ€™il reste lisible. Jâ€™ai Ã©galement suivi les principes de base du **Clean Code**Â : noms de variables explicites, pas de â€œcode mortâ€, dÃ©coupage en fonctions courtes et rÃ©utilisables. En cas de bug ou dâ€™erreur dÃ©tectÃ©e, jâ€™ai utilisÃ© une dÃ©marche rigoureuse de **rÃ©solution de problÃ¨me**Â : lecture des logs serveurs (stacktrace), reproduction du bug en local, utilisation de breakpoints ou de `console.error` pour isoler lâ€™origine, puis correction et test. Par exemple, jâ€™ai rencontrÃ© un problÃ¨me de contrainte Ã©trangÃ¨re lors de lâ€™association dâ€™un ingrÃ©dient Ã  une recetteÂ : lâ€™erreur SQL *Â«Â Cannot add or update a child row: a foreign key constraint failsÂ Â»* mâ€™a indiquÃ© un souci dâ€™ordre de crÃ©ation. AprÃ¨s analyse, jâ€™ai compris quâ€™il fallait crÃ©er lâ€™ingrÃ©dient avant de lâ€™associerÂ ; jâ€™ai donc ajustÃ© la logique et ajoutÃ© un contrÃ´le pour Ã©viter cette erreur. Ce type de diagnostic montre mon **esprit dâ€™analyse** et ma capacitÃ© Ã  corriger des dysfonctionnements de maniÃ¨re structurÃ©e.

En somme, le dÃ©veloppement des composants mÃ©tier sur Brasse-Bouillon tÃ©moigne de ma compÃ©tence Ã  **concevoir un backend sÃ©curisÃ© et fonctionnel**. Jâ€™ai su intÃ©grer des bonnes pratiques de sÃ©curitÃ© (contrÃ´les dâ€™accÃ¨s, chiffrage des mots de passe, tests unitaires des fonctions critiques), tout en produisant un code de qualitÃ©, maintenable et documentÃ©. **Chaque fonctionnalitÃ© dÃ©veloppÃ©e a Ã©tÃ© testÃ©e** manuellement via Postman ou automatiquement via Jest pour sâ€™assurer quâ€™elle rÃ©pond aux attentes (exÂ : un test unitaire vÃ©rifie que *1 + 1 = 2* fonctionne â€“ dÃ©but modeste pour valider la configuration Jest, puis des tests plus complets vÃ©rifieront que la crÃ©ation dâ€™une recette sans nom retourne bien une erreur 400, etc.). Ces efforts garantissent que lâ€™application est robuste avant mÃªme la phase de test formelle.

### Contribution Ã  la gestion du projet informatique (mÃ©thodes, collaboration, reporting)

En plus du dÃ©veloppement pur, lâ€™activitÃ©-typeÂ 1 requiert de **contribuer Ã  la gestion du projet**. Dans le cadre de Brasse-Bouillon, jâ€™ai rempli ce rÃ´le en adoptant des outils et mÃ©thodes qui mâ€™ont permis de structurer le travail et de communiquer efficacement sur lâ€™avancement.

**Planification et suivi AgileÂ :** Comme mentionnÃ©, jâ€™ai organisÃ© le projet en sprints de deux semaines. Au dÃ©but de chaque sprint, jâ€™Ã©tablissais un **Sprint Backlog** avec les user stories Ã  implÃ©menter prioritairement. Par exemple, lors du SprintÂ 1, les objectifs majeurs Ã©taient la mise en place de lâ€™authentification et le CRUD de recettes (US01 Ã  US04). Jâ€™ai utilisÃ© lâ€™outil **GitHub Projects** (Kanban) pour suivre lâ€™Ã©tat des tÃ¢chesÂ : colonnes *Todo / In Progress / Done*. Chaque fonctionnalitÃ© correspondait Ã  une **issue** dÃ©crivant la tÃ¢che, avec une checklist des sous-tÃ¢ches. Jâ€™appliquais des **Ã©tiquettes (labels)** sur les issues pour prÃ©ciser leur nature (exÂ : `type:feature`, `priority:high`, `scope:backend`) et jâ€™assignais les issues aux **milestones** de chaque phase (par ex. milestone *P3 â€“ DÃ©veloppement* qui regroupait toutes les tÃ¢ches du bloc dÃ©veloppement). Cette granularitÃ© mâ€™a aidÃ© Ã  garder une vue claire de lâ€™avancement et Ã  **prioriser** intelligemment les dÃ©veloppements.

**Communication et reportingÂ :** Bien que seul dÃ©veloppeur, jâ€™ai pris lâ€™habitude de rÃ©diger un court **compte-rendu hebdomadaire** comme si je devais informer un chef de projet ou un client. Ce rapport (tenu dans le `README.md` ou dans un journal de bord) rÃ©capitulait les fonctionnalitÃ©s terminÃ©es durant la semaine, les Ã©ventuels retards ou problÃ¨mes rencontrÃ©s, et le plan pour la semaine suivante. Par exemple, Ã  la fin de la PhaseÂ 3, jâ€™ai notÃ© que toutes les fonctionnalitÃ©s du MVP Ã©taient implÃ©mentÃ©es sauf le module communautaire (reportÃ© en *Nice-to-have*), et que quelques bugs restaient Ã  corriger sur la partie calcul IBU/ABV. Jâ€™ai aussi communiquÃ© sur les dÃ©cisions techniques prisesÂ : par exemple, le choix de **React Native** pour le front (justifiÃ© par le besoin multiplateforme) ou de **MySQL** pour la base de donnÃ©es (choisi pour sa robustesse et ma familiaritÃ©, au lieu de PostgreSQL initialement envisagÃ©). Justifier mes choix fait partie de la communication professionnelle que doit maÃ®triser un concepteur-dÃ©veloppeur.

Jâ€™ai Ã©galement soignÃ© la **communication technique** Ã  travers la documentationÂ : jâ€™ai produit un **guide dâ€™installation** et de lancement du projet pour quâ€™un tiers puisse le tester facilement, jâ€™ai documentÃ© les *API endpoints* dans un fichier Markdown dÃ©diÃ© (`api_overview.md`) et jâ€™ai maintenu Ã  jour le Wiki du dÃ©pÃ´t GitHub pour expliquer lâ€™architecture, la charte graphique, etc. Lâ€™objectif Ã©tait doubleÂ : faciliter les Ã©changes avec dâ€™autres parties prenantes (par exemple, transmettre le dossier Ã  un Ã©valuateur ou un collÃ¨gue DevOps pour dÃ©ploiement), et me constituer une rÃ©fÃ©rence Ã©crite pour ne rien oublier (par exemple, les Ã©tapes pour initialiser la BDD en local sont notÃ©es noir sur blanc, Ã©vitant les erreurs de mÃ©moire).

**MÃ©thodes de travail collaborativesÂ :** MÃªme en solo, jâ€™ai respectÃ© les conventions de collaboration comme si jâ€™Ã©tais en Ã©quipe. Par exempleÂ :

* Jâ€™ai utilisÃ© la fonctionnalitÃ© de **Pull Request** sur GitHub pour intÃ©grer mes propres branches, en remplissant systÃ©matiquement la description avec un rappel du contexte, des **checklists** de complÃ©tion (tests passÃ©s, review faite) et en liant les issues rÃ©solues (Â«Â Closes #numÃ©roÂ Â»). Cela mâ€™a disciplinÃ© et constitue une trace exploitable du cheminement du projet.
* Jâ€™ai mis en place une **intÃ©gration continue** (voir ActivitÃ©Â 3 pour le dÃ©tail) de sorte que chaque push de code dÃ©clenche automatiquement les tests et lâ€™analyse de lint. Ainsi, mÃªme sans collÃ¨gue pour revue, jâ€™avais un filet de sÃ©curitÃ© pour dÃ©tecter rapidement une rÃ©gression ou un oubli de bonne pratique. Par exemple, si par inadvertance jâ€™introduisais une erreur ESLint, le workflow GitHub Actions marquait le build en Ã©chec avec un message dâ€™erreur explicite (Â«Â âŒ Linting failed. Please fix code style issues.Â Â»).
* Jâ€™ai pratiquÃ© la **veille technologique** tout au long du projet. Lorsque jâ€™ai bloquÃ© sur un problÃ¨me ou eu un doute technique, jâ€™ai consultÃ© les ressources en ligne (MDN, Stack Overflow, documentation officielle React Native/Express). Jâ€™ai suivi Ã©galement des communautÃ©s de dÃ©veloppeurs (forums, Discord) liÃ©es au brassage ou Ã  lâ€™IoT pour mâ€™inspirer de solutions existantes. Par exemple, pour intÃ©grer lâ€™IoT plus tard, je me suis renseignÃ© sur **MQTT** et jâ€™ai dÃ©couvert la solution Eclipse Mosquitto, que jâ€™ai directement intÃ©grÃ©e dans mon docker-compose pour tester un broker local. Cette curiositÃ© et cette adaptation continue dÃ©montrent la compÃ©tence *Apprendre en continu* du rÃ©fÃ©rentiel.

**Bilan sur ActivitÃ©Â 1Â :** Ã€ travers ces rÃ©alisations, jâ€™ai couvert lâ€™ensemble des compÃ©tences de lâ€™ActivitÃ©-typeÂ 1. Jâ€™ai **prÃ©parÃ© mon environnement** de maniÃ¨re professionnelle, **dÃ©veloppÃ© des interfaces** ergonomiques et accessibles, **conÃ§u le code mÃ©tier** en assurant la sÃ©curitÃ© et la qualitÃ©, et **contribuÃ© activement Ã  la gestion du projet** via des mÃ©thodes Agiles, la documentation et la communication. En somme, jâ€™ai Ã©tÃ© capable de **â€œdÃ©velopper une application sÃ©curisÃ©eâ€** de bout en bout, en portant la double casquette de dÃ©veloppeur et de collaborateur projet responsable.

---

## ActivitÃ©-typeÂ 2Â : Concevoir et dÃ©velopper une application sÃ©curisÃ©e organisÃ©e en couches

*(**Bloc de compÃ©tences 2Â :** Analyser les besoins et maquettage ; DÃ©finir lâ€™architecture logicielle multicouche ; Concevoir et mettre en place une base de donnÃ©es relationnelle ; DÃ©velopper des composants dâ€™accÃ¨s aux donnÃ©es SQL et NoSQL)*

Pour ce deuxiÃ¨me exemple, je reviens sur les **phases amont** du projet Brasse-Bouillon, oÃ¹ il a fallu concevoir lâ€™application avant de la coder. Cette activitÃ©-type correspond Ã  la **PhaseÂ 1 (Initialisation)** et **PhaseÂ 2 (Conception technique)** de mon projet, au cours desquelles jâ€™ai endossÃ© le rÃ´le dâ€™analyste et dâ€™architecte. Jâ€™y dÃ©crirai comment jâ€™ai : **recueilli et analysÃ© les besoins** Ã  partir du sujet fil rouge, **Ã©laborÃ© les maquettes fonctionnelles** de lâ€™appli, puis **dÃ©fini lâ€™architecture technique** en couches (front-end, back-end, base de donnÃ©es). Jâ€™aborderai aussi la conception de la **base de donnÃ©es relationnelle** et la mise en place des composants dâ€™accÃ¨s aux donnÃ©es via lâ€™ORM et autres outils (SQL et un soupÃ§on de NoSQL avec Redis). Câ€™est pendant ces Ã©tapes que se dÃ©cident les fondations dâ€™une application, et jâ€™ai appliquÃ© une dÃ©marche rigoureuse pour que le projet soit bien posÃ© avant dâ€™entamer le dÃ©veloppement.

### Analyse des besoins utilisateurs et maquettage (PhaseÂ 1 â€“ Initialisation)

Au tout dÃ©but du projet, jâ€™ai consacrÃ© du temps Ã  comprendre et formaliser les **besoins**. Le contexte mâ€™a Ã©tÃ© fourni par le document *Sujet B3 â€“ Fil Rouge* (projet fil rouge de la formation CDA), dÃ©crivant un scÃ©nario oÃ¹ une association de brasseurs amateurs souhaitait une application pour partager des recettes et suivre leurs brassins. Ã€ partir de ce cahier des charges initial (fournissant les grandes lignes fonctionnelles), jâ€™ai menÃ© ma propre **analyseÂ fonctionnelle** en plusieurs Ã©tapesÂ :

* **Clarification du besoin â€“ mÃ©thode 5W1H**Â : Jâ€™ai reformulÃ© les objectifs du projet en rÃ©pondant aux questions *Who, What, Why, When, Where, How*. Qui sont les utilisateurs ciblesÂ ? (Brasseurs amateurs, Ã©ventuellement des admins gÃ©rant la communautÃ©). QuoiÂ ? (Une appli mobile pour recettes de biÃ¨re). PourquoiÂ ? (Pour faciliter le suivi des recettes et lâ€™Ã©change de connaissances). Quand et oÃ¹Â ? (En mobilitÃ©, pendant les sessions de brassage Ã  domicile, donc besoin offline partiel). CommentÂ ? (Via une application smartphone connectÃ©e Ã  une base de donnÃ©es partagÃ©e). Cette clarification mâ€™a permis de dÃ©gager les **pÃ©rimÃ¨tres** du projet et quelques contraintes (exÂ : nÃ©cessitÃ© dâ€™un mode hors-ligne partiel dâ€™oÃ¹ lâ€™importance dâ€™une bonne synchro, ou lâ€™attention Ã  lâ€™ergonomie car les brasseurs auront les mains prises en brassantÂ !).

* **DÃ©finition des fonctionnalitÃ©s et des utilisateurs (personas)**Â : Jâ€™ai imaginÃ© des **personas** typiques â€“ par exemple *Martin*, brasseur dÃ©butant qui veut juste suivre des recettes existantes, ou *Jeanne*, brasseuse expÃ©rimentÃ©e qui crÃ©e ses propres recettes et cherche Ã  optimiser ses paramÃ¨tres (IBU, ABV). Cela mâ€™a aidÃ© Ã  lister les **fonctionnalitÃ©s attendues**. Jâ€™ai couchÃ© ces fonctionnalitÃ©s sous forme de **User Stories** dans un document dÃ©diÃ©. Par exempleÂ : *â€œEn tant que brasseur amateur, je veux crÃ©er une nouvelle recette afin de garder une trace de mes crÃ©ationsâ€* (US01), *â€œEn tant quâ€™utilisateur, je veux que lâ€™appli calcule automatiquement lâ€™IBU et lâ€™ABV afin de connaÃ®tre les caractÃ©ristiques de ma biÃ¨reâ€* (US04), etc. Chaque user story est accompagnÃ©e de **critÃ¨res dâ€™acceptation** concrets (champs Ã  saisir, rÃ©sultats attendus) qui serviront plus tard de base aux tests. Au total, jâ€™ai identifiÃ© une dizaine de user stories couvrant la gestion des recettes (CRUD, duplication), les calculs techniques (IBU/ABV, carbonatation), la dimension communautÃ© (partage, commentaires, notes), la dimension durable (rÃ©utilisation des drÃªches, fournisseurs locaux) et lâ€™ergonomie (mode hors-ligne, accessibilitÃ©).

* **Priorisation des besoins (MoSCoW)**Â : Une fois la liste des fonctionnalitÃ©s Ã©tablie, jâ€™ai appliquÃ© une priorisation de type **MoSCoW** (Must have, Should have, Could have, Wonâ€™t have) pour dÃ©finir le **MVP** (Minimum Viable Product) Ã  rÃ©aliser dans le temps imparti. ConcrÃ¨tement, jâ€™ai marquÃ© comme **Must-Have** toutes les fonctionnalitÃ©s critiques sans lesquelles le projet perd son sensÂ : par exemple, la gestion des recettes (crÃ©ation, modification) est un must, tout comme les calculs automatiques dâ€™IBU/ABV qui font la valeur ajoutÃ©e de lâ€™appli, et un minimum de guidage utilisateur pour ne pas rebuter les dÃ©butants. En **Nice-to-Have** (Could have), jâ€™ai mis des choses comme lâ€™espace communautaire complet (partage public, commentaires) ou la recherche avancÃ©e par critÃ¨res, utiles mais pas vitales pour une v1. Enfin, jâ€™ai relÃ©guÃ© en **Future Enhancements** des idÃ©es plus poussÃ©es comme lâ€™intÃ©gration IoT (capteurs temps rÃ©el) ou des suggestions basÃ©es sur de lâ€™IA â€“ intÃ©ressant, mais clairement hors scope pour le projet initial. Ce travail de priorisation mâ€™a permis dâ€™Ã©laborer un **pÃ©rimÃ¨tre clair pour la Phase de dÃ©veloppement**Â : je savais exactement quelles user stories implÃ©menter en prioritÃ© (Must-Have), et quoi laisser de cÃ´tÃ© si le temps manquait. Jâ€™ai Ã©galement utilisÃ© cette priorisation pour **planifier les phases** dans lâ€™Ã©chÃ©ancier (voir PhaseÂ 3 correspond au dÃ©v des Must-Have).

* **Maquettage de lâ€™application**Â : En parallÃ¨le de lâ€™analyse textuelle, jâ€™ai commencÃ© Ã  **maquetter lâ€™interface** pour valider les choix fonctionnels. Jâ€™ai dâ€™abord produit des **schÃ©mas de navigation** (comment lâ€™utilisateur passe de lâ€™Ã©cran dâ€™accueil Ã  la crÃ©ation de recette, etc.) et des **wireframes** basse fidÃ©litÃ© pour chaque Ã©cran clÃ©. Par exemple, jâ€™ai dessinÃ© sur papier (puis sur Figma) la page â€œListe des recettesâ€ avec une simple liste dâ€™items, un bouton â€œ+â€ flottant pour ajouter, et un menu hamburger pour accÃ©der aux autres sections. Lâ€™objectif Ã©tait de sâ€™assurer que toutes les stories trouvaient un point de chute dans lâ€™UI. Ces wireframes ont Ã©tÃ© validÃ©s avec mon formateur qui jouait le rÃ´le du client, ce qui correspond Ã  une **rÃ©union de recueil de besoin** en mode agile oÃ¹ on valide quâ€™on a bien compris les attentes. Ensuite, jâ€™ai affinÃ© ces wireframes en **maquettes haute fidÃ©litÃ©** sur Figma, en appliquant dÃ©jÃ  une charte graphique de base (couleurs brunes et dorÃ©es rappelant la biÃ¨re, icÃ´nes Ã©vocatricesÂ ğŸº). Ce travail de design prÃ©liminaire mâ€™a permis de dÃ©tecter quelques problÃ¨mes dâ€™ergonomie dÃ¨s le dÃ©but (par exemple, il manquait un Ã©cran pour visualiser une recette en dÃ©tail aprÃ¨s sa crÃ©ation â€“ jâ€™ai ajoutÃ© une vue â€œDÃ©tail recetteâ€ suite Ã  Ã§a). Au final, jâ€™ai obtenu un **prototype cliquable** simulant le parcours utilisateur principal, que jâ€™ai pu prÃ©senter lors de la revue de fin de PhaseÂ 1.

En synthÃ¨se, cette phase dâ€™analyse et maquettage mâ€™a permis de **formaliser les besoins** de maniÃ¨re claire et de les traduire en Ã©lÃ©ments concrets (stories, maquettes). Jâ€™ai ainsi montrÃ© ma capacitÃ© Ã  *â€œanalyser les besoins et maquetter une applicationâ€*. Les choix effectuÃ©s ici ont posÃ© les bases solides pour la suite du projet, Ã©vitant des changements majeurs en cours de route. De plus, ce travail prÃ©coce a servi de rÃ©fÃ©rence lors de la phase de test (les critÃ¨res dâ€™acceptation des user stories mâ€™ont servi de scÃ©narios de test) et a assurÃ© que le dÃ©veloppement rÃ©ponde bien Ã  la demande initiale du Â«Â clientÂ Â».

### DÃ©finition de lâ€™architecture logicielle multicouche (Frontend, Backend, Base de donnÃ©es, Services externes)

Une fois les besoins clarifiÃ©s, jâ€™ai abordÃ© la **conception de lâ€™architecture** de lâ€™application. Le titre de lâ€™activitÃ© prÃ©cise â€œorganisÃ©e en couchesâ€Â : en effet, il sâ€™agissait de dÃ©finir comment sÃ©parer le frontend, le backend et la base de donnÃ©es, et quelles seraient les interactions entre ces couches, en tenant compte des aspects **sÃ©curitÃ©, performance et Ã©volutivitÃ©**.

**Choix des technologies**Â : Sur la base des besoins identifiÃ©s, jâ€™ai dâ€™abord confirmÃ© les choix technologiques principaux (souvent amorcÃ©s dÃ¨s lâ€™analyse)Â :

* **FrontendÂ :** React Native Ã©tait un choix naturel Ã©tant donnÃ© le besoin mobile multiplateforme, complÃ©tÃ© par Expo pour accÃ©lÃ©rer le dÃ©veloppement. Jâ€™ai validÃ© ce choix en testant rapidement un *Hello World* sur mon tÃ©lÃ©phone et en estimant que les performances seraient suffisantes pour une app de gestion (on nâ€™est pas sur de la 3D temps rÃ©el).
* **BackendÂ :** Node.js avec Express, car je voulais utiliser le mÃªme langage (JavaScript/TypeScript) cÃ´tÃ© front et back â€“ cela facilite la montÃ©e en compÃ©tence et permet Ã©ventuellement de partager du code utilitaire. De plus, Node.js est trÃ¨s adaptÃ© pour construire rapidement une API REST et bÃ©nÃ©ficie dâ€™un large Ã©cosystÃ¨me de packages (jsonwebtoken, sequelize, etc.). Jâ€™ai Ã©galement considÃ©rÃ© un temps **Python (Django)** ou **Java (Spring)**, mais ces solutions Ã©taient plus lourdes pour un projet solo de cette envergure. Node/Express offrait un bon compromis rapiditÃ© de dÃ©v/performance.
* **Base de donnÃ©esÂ :** Jâ€™ai optÃ© pour **MySQL** comme SGBD relationnel, car câ€™est un moteur Ã©prouvÃ©, que je connaissais bien, et qui sâ€™intÃ©grait parfaitement avec Sequelize (ORM choisi). PostgreSQL Ã©tait lâ€™alternative, mais lâ€™une ou lâ€™autre convenait. Jâ€™ai toutefois laissÃ© la porte ouverte en architecture Ã  une couche dâ€™abstraction (ORM) qui permettrait de changer de SGBD sans tout re-dÃ©velopper, le cas Ã©chÃ©ant. En complÃ©ment, jâ€™ai prÃ©vu lâ€™utilisation de **Redis** (base clÃ©-valeur NoSQL) pour certains usages spÃ©cifiquesÂ : par exemple, mettre en cache des rÃ©sultats de calcul ou stocker des sessions utilisateurs, dans lâ€™optique dâ€™amÃ©liorer les performances et la scalabilitÃ©. Redis nâ€™est pas indispensable au MVP, mais je lâ€™ai intÃ©grÃ© dans lâ€™architecture pour anticiper une montÃ©e en charge (et aussi pour dÃ©montrer la compÃ©tence â€œSQL & NoSQLâ€).
* **Autres composantsÂ :** Jâ€™ai dÃ©cidÃ© dâ€™intÃ©grer un **service dâ€™authentification** basÃ© sur JWT (librairie jsonwebtoken) plutÃ´t que de partir sur des sessions serveurs classiques, pour favoriser une architecture *stateless* du backend (plus simple Ã  distribuer sur plusieurs serveurs si besoin). Jâ€™ai Ã©galement prÃ©vu un petit **service de notifications** (envisagÃ© pour plus tard, via un service externe Firebase Cloud Messaging ou envoi dâ€™emails via NodeMailer) afin dâ€™envoyer des alertes aux utilisateurs (exÂ : â€œvotre fermentation est terminÃ©e!â€). Enfin, lâ€™aspect **IoT** mâ€™a conduit Ã  inclure dans lâ€™architecture un canal de communication via MQTT (broker Eclipse Mosquitto) pour recevoir les donnÃ©es de capteurs de tempÃ©rature/densitÃ© qui seraient placÃ©s dans les cuves. MÃªme si cette partie est expÃ©rimentale, lâ€™architecture se devait de la prendre en compte pour que je nâ€™aie pas Ã  tout refondre plus tard.

**Architecture multicouche â€“ vue dâ€™ensemble**Â : Sur la base de ces choix, jâ€™ai rÃ©alisÃ© un **diagramme dâ€™architecture** global illustrant les diffÃ©rentes couches et composants du systÃ¨me. En simplifiÃ©, cela donneÂ :

* **Couche PrÃ©sentation (Frontend)**Â : Lâ€™application mobile **React Native** constitue la couche interface utilisateur. Câ€™est la couche avec laquelle interagissent les brasseursÂ ; elle envoie des requÃªtes API et affiche les rÃ©sultats. Elle est dÃ©couplÃ©e du reste et pourrait Ãªtre remplacÃ©e par une autre interface (web app React, par ex.) sans affecter le backend.
* **Couche MÃ©tiers (Backend)**Â : Le serveur **Node.js/Express** fait office dâ€™API Gateway et de couche mÃ©tier. Il est dÃ©coupÃ© en sous-composants (services) pour gÃ©rer les domaines fonctionnelsÂ : Authentification, Recettes, Sessions, Notificationsâ€¦. Jâ€™ai choisi une architecture REST classiqueÂ : chaque service expose des endpoints HTTP, et Ã©ventuellement communique avec dâ€™autres services internes. Par exemple, le service Recettes peut faire appel au service Notifications pour envoyer un message lorsquâ€™une nouvelle recette est publiÃ©e, etc. Le backend contient Ã©galement la logique de validation, de calcul (exÂ : calcul dâ€™IBU/ABV se fait cÃ´tÃ© serveur pour fiabilitÃ©), et agrÃ¨ge les donnÃ©es pour le frontend.
* **Couche DonnÃ©es (Database & Persistence)**Â : Ici on trouve la base **MySQL** qui stocke de maniÃ¨re pÃ©renne toutes les informations (utilisateurs, recettes, ingrÃ©dients, etc.). Jâ€™ai conÃ§u la base comme **socle central**Â : tous les services mÃ©tier du backend y accÃ¨dent via lâ€™ORM. En complÃ©ment, jâ€™ai la base **Redis** (mÃ©moire) pour le cachingÂ : par exemple, on pourrait y stocker temporairement les recettes les plus consultÃ©es pour accÃ©lÃ©rer leur accÃ¨s ou conserver les jetons de rafraÃ®chissement OAuth. Jâ€™ai aussi prÃ©vu la possibilitÃ© dâ€™un stockage de fichiers (images de recettes, etc.) via un service Cloud ou un bucket S3, mais pour le MVP les images (comme le logo) sont embarquÃ©es dans lâ€™application.
* **Interactions entre couches**Â : Le **frontend** communique avec le backend uniquement via des appels **HTTP/HTTPS** vers lâ€™API REST. Jâ€™ai prÃ©vu dâ€™utiliser HTTPS en production avec un certificat SSL (sÃ©curitÃ© oblige), notamment parce que des identifiants transitent lors du login. Le **backend** quant Ã  lui interagit avec la base de donnÃ©es via **Sequelize** (requÃªtes SQL gÃ©nÃ©rÃ©es automatiquement), et avec Redis via son client Node (`ioredis`). Les diffÃ©rentes sous-parties du backend (auth, recettes, etc.) ne sont pas des microservices sÃ©parÃ©s dans le MVP (jâ€™ai jugÃ© quâ€™introduire une architecture microservices serait trop complexe pour un projet de cette taille), mais jâ€™ai tout de mÃªme dÃ©coupÃ© logiquement les services et indiquÃ© dans lâ€™architecture quâ€™ils *pourraient* Ãªtre dÃ©ployÃ©s sÃ©parÃ©ment plus tard. Par exemple, sur le diagramme composant, Auth, Recettes, Sessions apparaissent distincts mais en rÃ©alitÃ© ils tournent dans le mÃªme processus Node pour lâ€™instant. Cette vue composant mâ€™a servi surtout Ã  dÃ©finir des **responsabilitÃ©s claires** et Ã  Ã©viter de tout mettre en vrac dans un seul bloc de code.

**SÃ©curitÃ© et contraintes non-fonctionnelles dans lâ€™architectureÂ :** Lors de la dÃ©finition de lâ€™architecture, jâ€™ai portÃ© une attention particuliÃ¨re aux aspects **sÃ©curitÃ©**, **performance** et **rÃ©silience**, conformÃ©ment aux exigences du rÃ©fÃ©rentiel (application sÃ©curisÃ©e, Ã©co-conception, rÃ©silience informatiqueâ€¦). ConcrÃ¨tementÂ :

* Jâ€™ai intÃ©grÃ© dÃ¨s la conception un **plan de sÃ©curitÃ©** du SIÂ : utilisation gÃ©nÃ©ralisÃ©e de HTTPS, stockage des mots de passe **hachÃ©s (bcrypt)** en base, architecture *stateless* pour limiter les possibilitÃ©s dâ€™Ã©lÃ©vation de privilÃ¨ge (un token JWT peut Ãªtre invalidÃ© simplement en le blacklistant ou en changeant la clÃ© secrÃ¨te), cloisonnement des donnÃ©es utilisateurs par design (chaque recette est liÃ©e Ã  un userId, ce qui facilite les contrÃ´les dâ€™accÃ¨s).
* Jâ€™ai prÃ©vu la mise en place de **tests de performance** et de charge une fois le MVP dÃ©veloppÃ©, pour vÃ©rifier que lâ€™architecture tient la route. Par anticipation, jâ€™ai ajoutÃ© le cache Redis pour soulager la base sur certains endpoints trÃ¨s lus, et jâ€™ai documentÃ© la possibilitÃ© de dÃ©ployer le backend derriÃ¨re **NGINX** avec PM2 en cluster pour gÃ©rer plus de trafic. En dâ€™autres termes, lâ€™architecture logicielle peut Ã©voluer en architecture dÃ©ployÃ©e sur plusieurs nÅ“uds sans modification majeure du code (par exemple, deux instances du backend derriÃ¨re un reverse proxy, la base sur un serveur distinct).
* Jâ€™ai aussi rÃ©flÃ©chi Ã  lâ€™**Ã©co-conception**Â : cela passe par des choix architecturaux limitant la surconsommation. Par exemple, Ã©viter les allers-retours inutiles front-back (en groupant certaines donnÃ©es dans la mÃªme requÃªte), mettre en cache localement sur le mobile des donnÃ©es stables pour Ã©viter de solliciter le rÃ©seau Ã  chaque fois (dâ€™oÃ¹ la story sur le mode hors-ligne). Jâ€™ai envisagÃ© lâ€™utilisation de *service workers* ou dâ€™une base locale type SQLite sur lâ€™app pour stocker les recettes en cache. Ce sont des choix qui impactent lâ€™architecture car ils ajoutent une couche cÃ´tÃ© client, mais potentiellement bÃ©nÃ©fiques en efficacitÃ© Ã©nergÃ©tique (moins de requÃªtes = moins de serveurs sollicitÃ©s). Le rÃ©fÃ©rentiel mentionne la prise en compte des besoins dâ€™**Ã©co-conception**, jâ€™ai donc mentionnÃ© explicitement dans mon doc dâ€™archi quâ€™une future amÃ©lioration serait de **mesurer lâ€™empreinte** de certaines opÃ©rations (ex: calcul intensif ABV, ou images, etc.) et dâ€™optimiser en consÃ©quence, ainsi que dâ€™utiliser des hÃ©bergements verts pour la prod.

AprÃ¨s avoir posÃ© ces Ã©lÃ©ments, jâ€™ai consolidÃ© le tout dans un **dossier dâ€™architecture** complet, comprenant : un **schÃ©ma des composants** (dÃ©crit plus haut), un **schÃ©ma des flux de donnÃ©es** montrant comment les donnÃ©es circulent entre front, API, base, IoT, etc., un **schÃ©ma de classes** UML dÃ©taillant les principales classes mÃ©tier (utile pour les dÃ©veloppeurs), et un **schÃ©ma de la base de donnÃ©es** dont je parle juste aprÃ¨s. Chaque document dâ€™architecture renvoie aux autres pour cohÃ©rence, ce qui assure une conception **globale cohÃ©rente**.

En conclusion sur cette partie, jâ€™ai dÃ©montrÃ© ma compÃ©tence Ã  *â€œdÃ©finir lâ€™architecture logicielle dâ€™une applicationâ€*, en lâ€™occurrence une architecture **3-tier modulaire** bien pensÃ©e pour Brasse-Bouillon. Ce travail mâ€™a valu des retours positifs lors de la revue de conception, car tout Ã©tait prÃªt pour attaquer le dÃ©veloppement de maniÃ¨re sereine, avec une vision claire de lâ€™ensemble. Les choix rÃ©alisÃ©s Ã  ce stade se sont avÃ©rÃ©s judicieux, car je nâ€™ai pas eu Ã  remettre en question lâ€™architecture en cours de routeÂ : preuve dâ€™une conception initiale solide.

### Conception et mise en place de la base de donnÃ©es relationnelle (modÃ©lisation et implÃ©mentation SQL)

Le **modÃ¨le de donnÃ©es** est souvent le cÅ“ur dâ€™un projet applicatif, et Brasse-Bouillon ne fait pas exception. Jâ€™ai donc accordÃ© une attention particuliÃ¨re Ã  la **conception de la base de donnÃ©es** lors de lâ€™activitÃ©-typeÂ 2. Le but Ã©tait de dÃ©finir une base **relationnelle** robuste, normalisÃ©e, couvrant tous les besoins fonctionnels, puis de la crÃ©er physiquement et de la peupler pour les tests.

**ModÃ©lisation conceptuelle (MERISE/UML)**Â : Sur la base des informations collectÃ©es en PhaseÂ 1, jâ€™ai dessinÃ© un **MCD (ModÃ¨le Conceptuel de DonnÃ©es)** pour reprÃ©senter les entitÃ©s du systÃ¨me et leurs relations. Utilisant la notation UML, jâ€™ai identifiÃ© les entitÃ©s suivantes (voir tableau)Â :

| EntitÃ©               | Description (rÃ´le dans lâ€™application)                                |
| -------------------- | -------------------------------------------------------------------- |
| **User**             | Utilisateur de lâ€™application (brasseur).                             |
| **Recipe**           | Recette de biÃ¨re crÃ©Ã©e par un utilisateur.                           |
| **Ingredient**       | IngrÃ©dient pouvant entrer dans une recette (malt, houblon, etc.).    |
| **RecipeIngredient** | Association *n\:n* entre Recipe et Ingredient, avec quantitÃ©.        |
| **BrewSession**      | Session de brassage planifiÃ©e/rÃ©alisÃ©e, liÃ©e Ã  une recette.          |
| **BrewingEquipment** | Ã‰quipement de brassage (cuve, fermenteur) dÃ©tenu par un utilisateur. |
| **Comment**          | Commentaire dâ€™un utilisateur sur une recette.                        |
| **Rating**           | Note (Ã©toiles) donnÃ©e par un utilisateur Ã  une recette.              |
| **Notification**     | Notification envoyÃ©e Ã  un utilisateur (rappel de session, etc.).     |

Ce modÃ¨le conceptuel dÃ©crit lâ€™univers de Brasse-Bouillon de maniÃ¨re **indÃ©pendante de la technologie**. Jâ€™ai ensuite validÃ© ce MCD en le traduisant en **diagramme entitÃ©-association** UML, que jâ€™ai inclus dans la documentation. Par exemple, on y voit queÂ :

* Un **User** peut crÃ©er plusieurs **Recipe** (relation 1-N).
* Un **Recipe** peut contenir plusieurs **Ingredient** et inversement (relation N-N modÃ©lisÃ©e par lâ€™entitÃ© associative RecipeIngredient).
* Un **User** peut lancer plusieurs **BrewSession** (1-N) et chaque BrewSession est reliÃ©e Ã  une Recipe (N sessions pour 1 recette possible).
* Jâ€™ai Ã©galement modÃ©lisÃ© que User peut avoir plusieurs Equipment, quâ€™une Recipe peut avoir des Comments et des Ratings de plusieurs Users, etc. Toutes ces relations ont Ã©tÃ© dÃ©finies avec les bons cardinalitÃ©s et libellÃ©s (par ex. *User "Ã©crit" Comment*, *Recipe "notÃ© par" Rating*).

**Passage au modÃ¨le logique et physique**Â : AprÃ¨s validation du modÃ¨le conceptuel (jâ€™ai revu le diagramme avec un formateur pour confirmer la pertinence), jâ€™ai dÃ©rivÃ© le **modÃ¨le logique**/physique pour implÃ©mentation dans MySQL. ConcrÃ¨tement, cela signifie dÃ©finir les tables SQL correspondantes, avec leurs colonnes, types, clÃ©s primaires et clÃ©s Ã©trangÃ¨res. Jâ€™ai crÃ©Ã© un script `database_schema.sql` (ou son Ã©quivalent via Sequelize) comprenant les instructions de crÃ©ation de tables. Par exempleÂ :

* Table `users`Â : id (PK auto), name, email (unique), password\_hash, role (valeurs possibles: admin/brasseur/utilisateur), created\_atâ€¦
* Table `recipes`Â : id (PK), user\_id (FK vers users), name, description, instructions, abv, ibu, created\_atâ€¦
* Table `ingredients`Â : id, name, category (par ex "houblon", "malt", "levure").
* Table `recipe_ingredients`Â : recipe\_id (FK), ingredient\_id (FK), quantity, unit. Jâ€™ai dÃ©fini la clÃ© primaire composite (recipe\_id, ingredient\_id) pour Ã©viter les doublons du mÃªme ingrÃ©dient dans une recette, et mis en place la contrainte ON DELETE CASCADE sur recipe\_id et ingredient\_id pour suivre la suppression de recettes ou dâ€™ingrÃ©dients.
* Tables `brew_sessions`, `comments`, `ratings`, `brewing_equipments`, `notifications` avec leurs colonnes et clÃ©s respectives selon le MCD. Certaines de ces tables (comments, ratings) incluent une contrainte *UNIQUE* combinÃ©e sur (user\_id, recipe\_id) pour Ã©viter quâ€™un mÃªme user ne note deux fois la mÃªme recette, par exemple.

Jâ€™ai pris soin de normaliser le schÃ©ma au moins jusquâ€™en **3Ã¨me forme normale** pour Ã©viter les duplications de donnÃ©es. Par exemple, les ingrÃ©dients sont dans leur table sÃ©parÃ©e, on ne stocke pas directement le nom de lâ€™ingrÃ©dient dans la recette (seulement via lâ€™association) â€“ Ã§a garantit lâ€™unicitÃ© de la dÃ©finition dâ€™un ingrÃ©dient. De mÃªme, jâ€™ai introduit une petite table de correspondance pour les rÃ´les utilisateur (Admin, Brasseur, Visiteur) afin de ne pas avoir des strings en dur partout (on peut ainsi faire Ã©voluer les rÃ´les plus facilement).

**Mise en place via lâ€™ORM SequelizeÂ :** PlutÃ´t que dâ€™Ã©crire tout le SQL Ã  la main, jâ€™ai utilisÃ© **Sequelize** pour crÃ©er les modÃ¨les et gÃ©nÃ©rer la base. Jâ€™ai dÃ©fini chaque modÃ¨le dans les fichiers JS correspondants, en spÃ©cifiant les champs et les relations. Par exemple, dans `backend/models/Recipe.js`Â :

```js
// DÃ©finition du modÃ¨le Recipe avec Sequelize (simplifiÃ©)
module.exports = (sequelize, DataTypes) => {
  const Recipe = sequelize.define('Recipe', {
    name: DataTypes.STRING,
    description: DataTypes.TEXT,
    ibu: DataTypes.FLOAT,
    abv: DataTypes.FLOAT,
    // ... autres champs
  });

  Recipe.associate = models => {
    Recipe.belongsTo(models.User, { foreignKey: 'userId' });
    Recipe.belongsToMany(models.Ingredient, { through: models.RecipeIngredient });
    Recipe.hasMany(models.Comment);
    Recipe.hasMany(models.Rating);
  };

  return Recipe;
};
```

Ce genre de dÃ©finition est trÃ¨s concis comparÃ© au SQL brut, et Sequelize sâ€™est chargÃ© de crÃ©er les tables correspondantes lors de lâ€™exÃ©cution de `sequelize.sync()` ou via des **migrations**. Jâ€™ai dâ€™ailleurs Ã©crit des **scripts de migration** pour la base, par exemple une migration initiale qui crÃ©e toutes les tables dans le bon ordre (Users puis Recipes puis RecipeIngredients etc.), afin de bien respecter les contraintes de clÃ©s Ã©trangÃ¨res. Jâ€™ai aussi prÃ©vu des **donnÃ©es de test (seeds)**Â : un ou deux utilisateurs factices, quelques ingrÃ©dients de base (Houblon Cascade, Malt Pilsner, Levure US-05â€¦), et une recette â€œPale Aleâ€ dâ€™exemple pour vÃ©rifier que tout fonctionne. Ces seeds mâ€™ont servi en PhaseÂ 4 pour remplir la base et exÃ©cuter les tests fonctionnels.

**Gestion des droits dâ€™accÃ¨s Ã  la baseÂ :** Le rÃ©fÃ©rentiel mentionne la nÃ©cessitÃ© de dÃ©finir les *droits dâ€™accÃ¨s des utilisateurs* sur la base. Dans un contexte web moderne avec ORM, on nâ€™expose pas directement la base aux utilisateurs, donc la gestion se fait plutÃ´t au niveau applicatif (via le backend). NÃ©anmoins, jâ€™ai quand mÃªme sÃ©curisÃ© lâ€™accÃ¨s MySQL en crÃ©ant un utilisateur spÃ©cifique **MySQL â€œbrasseurâ€** avec uniquement les droits nÃ©cessaires sur la base `brasse_bouillon`. Ainsi, mÃªme si quelquâ€™un obtenait lâ€™accÃ¨s DB via lâ€™application, il ne pourrait pas faire autre chose que de la lecture/Ã©criture sur cette base (pas de DROP sur dâ€™autres bases, etc.). En dev, jâ€™avais lâ€™utilisateur root, mais en config de prod jâ€™ai prÃ©vu dâ€™utiliser ce compte restreint. Jâ€™ai Ã©galement segmentÃ© les droits applicatifs via les rÃ´les dans lâ€™applicationÂ : par exemple, un utilisateur standard ne peut ni accÃ©der aux donnÃ©es dâ€™un autre (vÃ©rification par userId dans toutes les requÃªtes), ni effectuer dâ€™actions admin. Si on avait eu un DBA ou un service IT, jâ€™aurais fourni un **schÃ©ma de comptes** (compte admin pour maintenance DB, compte app pour usage courant).

**Validation de la base**Â : AprÃ¨s avoir mis en place la BDD, jâ€™ai exÃ©cutÃ© un **plan de test SQL** pour vÃ©rifier la cohÃ©rence du schÃ©ma (câ€™Ã©tait la PhaseÂ 4 en partie). Jâ€™ai par exemple utilisÃ© MySQL Workbench ou la console MySQL pour lister les tables (`SHOW TABLES`) et dÃ©crire chacune (`DESCRIBE recipes;`), afin de vÃ©rifier que tous les champs Ã©taient lÃ  avec le bon type (exÂ : `ibu` et `abv` en FLOAT). Jâ€™ai insÃ©rÃ© manuellement des donnÃ©es de test via des requÃªtes INSERT, puis je me suis assurÃ© que les **contraintes** fonctionnaientÂ : en supprimant un user de test, ses recettes Ã©taient bien supprimÃ©es automatiquement (ON DELETE CASCADE validÃ©Â : la requÃªte SELECT derriÃ¨re ne retourne rien). Jâ€™ai aussi testÃ© une contrainte dâ€™unicitÃ© en tentant dâ€™insÃ©rer un doublon dâ€™email utilisateur â€“ jâ€™ai obtenu lâ€™erreur 1062 attendue (duplicate entry). Ces tests mâ€™ont rassurÃ© sur la soliditÃ© du modÃ¨le implÃ©mentÃ©.

En rÃ©sumÃ©, jâ€™ai dÃ©montrÃ© ici la compÃ©tence *â€œconcevoir et mettre en place une base de donnÃ©es relationnelleâ€* en passant par toutes les Ã©tapesÂ : modÃ©lisation conceptuelle, transformation en base physique, utilisation dâ€™un **ORM** moderne pour faciliter les opÃ©rations, et validation par des tests. La base de donnÃ©es de Brasse-Bouillon est dÃ©sormais en place, Ã©volutive (jâ€™ai documentÃ© comment lâ€™aligner si on ajoute de nouvelles entitÃ©s) et suffisamment optimisÃ©e (indexes implicites via les PK/FK, pas de redondance abusive de donnÃ©es). Cette base a servi de fondation fiable pour tout le code mÃ©tier dÃ©veloppÃ© dans lâ€™activitÃ©-typeÂ 1, et nâ€™a pas montrÃ© de lacune majeure pendant les tests â€“ preuve dâ€™une conception rÃ©ussie.

### DÃ©veloppement des composants dâ€™accÃ¨s aux donnÃ©es (SQL et NoSQL)

Le dernier volet de lâ€™activitÃ©-typeÂ 2 concerne la rÃ©alisation des **composants dâ€™accÃ¨s aux donnÃ©es**. Cela recouvre tout ce qui permet Ã  lâ€™application de dialoguer avec les sources de donnÃ©es, quâ€™elles soient SQL (BDD relationnelle) ou NoSQL. Dans mon projet, cela sâ€™est concrÃ©tisÃ© de deux faÃ§onsÂ : dâ€™une part lâ€™utilisation de **lâ€™ORM Sequelize** dans le backend pour accÃ©der Ã  MySQL, dâ€™autre part lâ€™intÃ©gration (en cours) dâ€™un **cache Redis** pour optimiser certains accÃ¨s.

**AccÃ¨s SQL via lâ€™ORM (Sequelize)Â :** Comme Ã©voquÃ©, jâ€™ai utilisÃ© Sequelize comme couche dâ€™abstraction entre mon code Node.js et la base MySQL. Ainsi, les controllers du backend manipulent des objets JavaScript (instances des modÃ¨les) plutÃ´t que dâ€™Ã©crire du SQL brut. Par exemple, dans le `recipeController`, pour rÃ©cupÃ©rer toutes les recettes, jâ€™ai simplement appelÃ© `Recipe.findAll()`. Cette commande gÃ©nÃ¨re en coulisses un SELECT \* FROM recipes, crÃ©e des objets Recipe pour chaque ligne et me les retourne. De mÃªme, pour insÃ©rer une recette jâ€™utilise `Recipe.create({...})` qui gÃ©nÃ¨re lâ€™INSERT. Lâ€™ORM se charge Ã©galement de remplir les champs automatiques (timestamps), de gÃ©rer les relations (quand jâ€™inclus Ingredient, il fait le JOIN nÃ©cessaire) et de remonter les erreurs sous forme dâ€™exceptions Node (que je catch pour renvoyer un code HTTP propre).

Jâ€™ai donc dÃ©veloppÃ© mes **composants dâ€™accÃ¨s aux donnÃ©es SQL** essentiellement via Sequelize. On peut considÃ©rer que chaque **Model Sequelize** est un composant dâ€™accÃ¨s aux donnÃ©esÂ : par exemple, jâ€™ai un module `Ingredient` qui expose des mÃ©thodes pour interroger la table `ingredients`. Dans certains cas oÃ¹ des requÃªtes complexes Ã©taient nÃ©cessaires (par ex, calculer la moyenne des notes dâ€™une recette, ou filtrer les recettes par ingrÃ©dient), jâ€™ai utilisÃ© soit les **mÃ©thodes Sequelize** (ex: `Recipe.findAll({ include: {... where: {...}}})` peut me sortir toutes les recettes contenant un ingrÃ©dient particulier), soit jâ€™ai Ã©crit une requÃªte brute via `sequelize.query("SELECT ...")` pour optimiser. Jâ€™ai documentÃ© ces requÃªtes SQL spÃ©cifiques dans un fichier `database_interactions.md`, afin de garder une trace des accÃ¨s un peu pointus et de justifier certains choix (par exemple, jâ€™ai notÃ© quâ€™une requÃªte custom Ã©tait utilisÃ©e pour la recherche multi-critÃ¨res de recettes car lâ€™ORM avait des limitations sur une requÃªte trop complexe).

GrÃ¢ce Ã  cette couche ORM, le code Node reste **indÃ©pendant du SGBD**Â : je pourrais presque basculer sur PostgreSQL en ne changeant quâ€™une ligne de config (dialect) et en ajustant deux trois types si besoin, Sequelize ferait le reste. Ce dÃ©couplage fait partie de la notion dâ€™application multicoucheÂ : la couche dâ€™accÃ¨s aux donnÃ©es est interchangeable et cachÃ©e derriÃ¨re lâ€™interface de lâ€™ORM.

**Exploitation du NoSQL (Redis)Â :** Le second aspect, câ€™est lâ€™utilisation de **Redis** pour stocker certaines donnÃ©es en mÃ©moire. Jâ€™ai dÃ©cidÃ© dâ€™intÃ©grer Redis principalement pour stocker les **sessions JWT invalidÃ©es** (lors dâ€™un logout anticipÃ©, pour invalider un token cÃ´tÃ© serveur jusquâ€™Ã  expiration), et potentiellement pour mettre en cache certaines rÃ©ponses lourdes. Jâ€™ai donc configurÃ© un client Redis dans mon backend (`redisClient = redis.createClient()`), connectÃ© soit Ã  un conteneur Redis local en dev, soit Ã  un Redis Cloud en prod.

Jâ€™ai dÃ©veloppÃ© un composant dâ€™accÃ¨s spÃ©cifique pour ce cacheÂ : un module `cacheService.js` qui expose des fonctions `get(key)`, `set(key, value, ttl)` etc., encapsulant les appels Redis. Par exemple, lors dâ€™une requÃªte GET /recipes, je pourrais dâ€™abord vÃ©rifier si la liste des recettes nâ€™est pas dÃ©jÃ  en cache (clÃ© `recipes:all`)Â ; si oui je la renvoie tout de suite, sinon je la calcule via la BDD puis je la stocke dans Redis pour les prochains appels. Ce type de mÃ©canisme accÃ©lÃ¨re lâ€™application et rÃ©duit la charge BDD.

ConcrÃ¨tement, jâ€™ai commencÃ© par un usage simpleÂ : lors du **logout** dâ€™un utilisateur, jâ€™insÃ¨re son token JWT dans Redis avec une clÃ© du type `bl_token:<tokenId>` et une expiration Ã©gale au temps restant du token. Ainsi, le middleware `verifyToken` chaque fois quâ€™il valide un token consulte aussi cette liste de tokens blacklistÃ©s dans Redis pour sâ€™assurer que le token nâ€™a pas Ã©tÃ© rÃ©voquÃ©. Cela ajoute trÃ¨s peu de latence et renforce la sÃ©curitÃ© (revocation cÃ´tÃ© serveur). Jâ€™ai Ã©galement prÃ©parÃ© le terrain pour utiliser Redis comme **file dâ€™attente de tÃ¢ches** (par ex, planifier lâ€™envoi dâ€™une notification 1 semaine aprÃ¨s la crÃ©ation dâ€™une recette pour demander â€œalors, dÃ©gustÃ©eÂ ?â€ â€“ ce nâ€™est pas implÃ©mentÃ© mais Redis pourrait servir de buffer dans une archi plus complexe).

Ã€ ce stade du projet, lâ€™utilisation de Redis reste limitÃ©e (on est toujours en MVP), mais jâ€™ai documentÃ© lâ€™**intÃ©gration de Redis** dans lâ€™architecture et le codeÂ : jâ€™ai mÃªme crÃ©Ã© une branche `refactor/redis-integration` oÃ¹ je travaillais sur la mise en cache de la liste dâ€™ingrÃ©dients, mentionnÃ©e dans une issue GitHub. Ce qui compte, câ€™est que jâ€™ai dÃ©montrÃ© savoir combiner des **donnÃ©es SQL et NoSQL** de maniÃ¨re cohÃ©rente dans une application. Lâ€™architecture peut donc Ãªtre qualifiÃ©e de **polyglotte** (mixte SQL/NoSQL) sur certains aspects, ce qui est de plus en plus frÃ©quent en entreprise pour tirer parti des forces de chaque technologie.

**Exemple dâ€™extraction de donnÃ©es**Â : Pour illustrer un composant dâ€™accÃ¨s aux donnÃ©es, prenons la fonctionnalitÃ© â€œCalcul IBU/ABVâ€ qui nÃ©cessite de lire certaines infos en base (densitÃ©s des moÃ»ts, acides alpha des houblons). Jâ€™ai crÃ©Ã© Ã  titre dâ€™exemple un **diagramme de sÃ©quence** du calcul IBU/ABV montrant comment le front envoie une recette, le backend va chercher dans la table des ingrÃ©dients les donnÃ©es nÃ©cessaires (par ex, pour chaque houblon de la recette, rÃ©cupÃ©rer son alpha-acide stockÃ© en base), puis effectue le calcul et renvoie le rÃ©sultat. Le composant dâ€™accÃ¨s aux donnÃ©es ici est la couche ORM qui, via une mÃ©thode `Ingredient.findByPk(id)` ou similaire, me renvoie lâ€™info. Tout cela pour dire que jâ€™ai su **dÃ©velopper les composants dâ€™accÃ¨s aux donnÃ©es** tant du cÃ´tÃ© code (fonctions JS interrogeant lâ€™ORM) que du cÃ´tÃ© infrastructure (mise en place de Redis et MySQL, drivers installÃ©s et utilisÃ©s).

Pour clore ce chapitre, lâ€™activitÃ©-typeÂ 2 mâ€™a amenÃ© Ã  agir comme **concepteur-architecte** de lâ€™application. Jâ€™ai **analysÃ©, maquettÃ©, architecturÃ©, modÃ©lisÃ© et mis en place les donnÃ©es**, en mobilisant des compÃ©tences de rÃ©flexion, de projection et des connaissances techniques pointues (MERISE, UML, SQL/NoSQLâ€¦). Le rÃ©sultat est une application **bien conÃ§ue**, sur des bases solides, prÃªte Ã  Ãªtre dÃ©veloppÃ©e (ce que jâ€™ai fait en activitÃ©-typeÂ 1) et Ã  Ã©voluer. Cette expÃ©rience a renforcÃ© ma capacitÃ© Ã  prendre de la hauteur sur un projet, Ã  anticiper les besoins futurs, et Ã  produire des livrables de conception de qualitÃ© (les diagrammes et docs dâ€™architecture que jâ€™ai fournis pourraient Ãªtre lus par un autre dÃ©veloppeur ou un jury pour comprendre rapidement le fonctionnement du systÃ¨me).

---

## ActivitÃ©-typeÂ 3Â : PrÃ©parer le dÃ©ploiement dâ€™une application sÃ©curisÃ©e

*(**Bloc de compÃ©tencesÂ 3Â :** PrÃ©parer et exÃ©cuter les plans de tests dâ€™une application ; PrÃ©parer et documenter le dÃ©ploiement dâ€™une application ; Contribuer Ã  la mise en production dans une dÃ©marche DevOps)*

La troisiÃ¨me et derniÃ¨re activitÃ©-type concerne la finalisation du projet avant sa mise en service. Cela correspond, dans mon projet Brasse-Bouillon, aux **PhaseÂ 4 (Tests et Validation)** et **PhaseÂ 5 (DÃ©ploiement & Maintenance)**, ainsi quâ€™Ã  certaines tÃ¢ches transverses de qualitÃ© logicielle. Je vais expliquer comment jâ€™ai **prÃ©parÃ© et exÃ©cutÃ© des tests** pour mâ€™assurer de la conformitÃ© de lâ€™application aux besoins (y compris tests de sÃ©curitÃ©), comment jâ€™ai **prÃ©parÃ© le dÃ©ploiement** en production (conteneurisation, documentation dâ€™installation, configuration) et comment jâ€™ai adoptÃ© une dÃ©marche de type **DevOps** pour faciliter la mise en production continue (intÃ©gration continue, scripts de build, etc.). En somme, cette activitÃ© illustre ma capacitÃ© Ã  livrer une application fiable, dÃ©ployable et maintenable, bouclant ainsi le cycle de dÃ©veloppement logiciel.

### Ã‰laboration et exÃ©cution des plans de tests (Tests unitaires, fonctionnels, sÃ©curitÃ©)

**StratÃ©gie de test**Â : Avant mÃªme dâ€™Ã©crire le moindre test, jâ€™ai dÃ©fini une **stratÃ©gie de test** couvrant plusieurs niveauxÂ : tests unitaires (vÃ©rifier chaque fonction/mÃ©thode critique en isolation), tests dâ€™intÃ©gration (vÃ©rifier quâ€™un ensemble de composants fonctionne ensemble, ex: une requÃªte API du front jusquâ€™Ã  la base), tests fonctionnels (valider que chaque exigence du cahier des charges est remplie, typiquement en suivant les user stories), et tests de sÃ©curitÃ© (essayer des scÃ©narios dâ€™attaque courants). Jâ€™ai consignÃ© cette stratÃ©gie dans un plan de test Ã©crit en PhaseÂ 4.

**Mise en place des tests unitaires (PhaseÂ 3 & 4)**Â : Durant le dÃ©veloppement, jâ€™avais dÃ©jÃ  commencÃ© Ã  Ã©crire quelques tests unitaires avec **Jest**. Par exemple, jâ€™ai un test sur la fonction de calcul dâ€™ABV pour vÃ©rifier que pour une densitÃ© initiale et finale donnÃ©es, le rÃ©sultat est correct (exÂ : OG=1.050, FG=1.010 donne \~5.25% ABV). Jâ€™ai Ã©galement un test unitaire sur le middleware dâ€™authentification JWTÂ : je simule un appel avec un token invalide et je vÃ©rifie que la rÃ©ponse est bien un 401 Unauthorized. Ces tests, exÃ©cutables via `npm test`, mâ€™ont servi de filet de sÃ©curitÃ© pendant les refactorings. Bien sÃ»r, au dÃ©but jâ€™avais des tests trÃ¨s simples (le fameux test â€œ1+1=2â€ qui assure que Jest est opÃ©rationnel), puis jâ€™ai enrichi progressivement. Au total, la couverture nâ€™est pas exhaustive (faute de temps, tous les composants ne sont pas couverts Ã  100%), mais jâ€™ai couvert les parties critiques (auth, calculs, controleurs principaux). Le CI GitHub exÃ©cute ces tests Ã  chaque push, ce qui me prÃ©vient immÃ©diatement en cas de rÃ©gression.

**Tests dâ€™intÃ©gration (Postman & automatisÃ©s)**Â : Jâ€™ai crÃ©Ã© une **collection Postman** regroupant tous les appels API de lâ€™application (login, CRUD recettes, etc.) avec des jeux de donnÃ©es de test. Cela mâ€™a permis de rapidement tester manuellement le bon enchaÃ®nement front-back. Jâ€™ai par exemple un scÃ©nario Postman â€œCrÃ©er une recette complÃ¨teâ€ quiÂ : fait un POST /auth/login pour obtenir un token, stocke le token, puis enchaÃ®ne sur POST /recipes avec des ingrÃ©dients, puis GET /recipes/\:id pour vÃ©rifier que la recette est bien rÃ©cupÃ©rable. Cette suite manuelle a Ã©tÃ© trÃ¨s utile pour dÃ©tecter des oublis (un bug trouvÃ©Â : jâ€™avais oubliÃ© de vÃ©rifier lâ€™unicitÃ© du nom de recette, non bloquant mais signalÃ© pour amÃ©lioration). Jâ€™ai Ã©galement explorÃ© lâ€™outil **Cypress** pour Ã©ventuellement automatiser un test de bout en bout sur lâ€™UI mobile (via Cypress + expo-web), mais par manque de temps je ne lâ€™ai pas finalisÃ©. NÃ©anmoins, jâ€™ai maintenu Ã  jour mes scÃ©narios Postman et je les ai fournis en annexe du dossier.

**Plan de test fonctionnel (validation des exigences)**Â : Pour Ãªtre sÃ»r de ne rien oublier, jâ€™ai construit un **tableau de suivi** listant chaque **exigence** du rÃ©fÃ©rentiel ou du cahier des charges, et notant si elle Ã©tait testÃ©e et **conforme**. Par exempleÂ : *â€œPrÃ©sentation des interfaces utilisateur ergonomiquesâ€* â€“ RÃ©fÃ©rence REAC BlocÂ 1 â€“ Exemple dans le projetÂ : interfaces rÃ©alisÃ©es selon maquettes, CRUD recettes fonctionnel avec calculs IBU/ABV â€“ ConformitÃ©Â : Oui. Jâ€™ai fait cela pour les principaux points, comme *â€œJustification des choix techniquesâ€* (couvert par la doc de conception), *â€œRapport de tests de qualitÃ© (unitaires, fonctionnels)â€* (couvert par mes rÃ©sultats de tests et scanning OWASP), *â€œUtilisation dâ€™une mÃ©thodologie agileâ€* (Ã©vidente via mon suivi de projet), etc. Ce tableau fait partie de ma **matrice de conformitÃ©** prÃ©parÃ©e en PhaseÂ 6 (soutenance) et mâ€™a aidÃ© Ã  pointer du doigt quelques tests manquants (jâ€™ai par exemple ajoutÃ© un test de lâ€™auth en mode â€œrÃ´le adminâ€ bien que je nâ€™aie pas dâ€™UI pour Ã§a, juste pour vÃ©rifier la route protÃ©gÃ©e).

**Tests de sÃ©curitÃ©**Â : Jâ€™ai voulu mâ€™assurer que lâ€™application Ã©tait **sÃ»re** face aux menaces courantes. Jâ€™ai donc effectuÃ© quelques tests spÃ©cifiquesÂ :

* **Test dâ€™injection SQL**Â : Jâ€™ai tentÃ© de passer des chaÃ®nes contenant des quotes ou des commandes SQL dans les inputs (par ex, nom de recette = `"; DROP TABLE recipes; --`). GrÃ¢ce Ã  lâ€™ORM Sequelize qui paramÃ¨tre les requÃªtes, ces injections nâ€™ont eu aucun effet nÃ©fasteÂ : soit elles ont Ã©tÃ© Ã©chappÃ©es, soit rejetÃ©es si non conformes. Ce test mâ€™a rassurÃ© sur la protection contre les injections SQL.
* **Test XSS (Cross-site scripting)**Â : Jâ€™ai testÃ© lâ€™envoi de balises `<script>alert(1)</script>` dans les champs textes (description de recette, commentaire). CÃ´tÃ© affichage mobile, ces balises ne sont pas interprÃ©tÃ©es par React Native (elles seraient affichÃ©es littÃ©ralement si jamais), donc pas de risque XSS direct dans lâ€™app. Pour le futur site web (puisquâ€™on a aussi une version web envisagÃ©e), jâ€™ai prÃ©vu dâ€™Ã©chapper/filtrer ces contenus ou dâ€™utiliser des composants sÃ©curisÃ©s. La vigilance XSS est donc notÃ©e, et en lâ€™Ã©tat lâ€™impact est mineur.
* **Tests dâ€™accÃ¨s non autorisÃ©s**Â : Jâ€™ai vÃ©rifiÃ© quâ€™en appelant des endpoints sans token ou avec un token invalide, jâ€™obtenais bien les codes dâ€™erreur appropriÃ©s (401 ou 403). Par exemple, un `GET /recipes` sans token renvoie 401 AccÃ¨s refusÃ©, un `DELETE /recipes/:id` avec un token dâ€™un autre utilisateur renvoie 403 Forbidden. Ces tests Ã©taient cruciaux pour sâ€™assurer que mes contrÃ´les dâ€™accÃ¨s implÃ©mentÃ©s (middlewares JWT, vÃ©rification propriÃ©taire) fonctionnent bien.
* **Test de robustesse aux volumes**Â : jâ€™ai simulÃ© via script lâ€™insertion de 100 recettes dâ€™un coup pour voir si lâ€™application tenait le coup. La base a encaissÃ© sans souci, et la rÃ©cupÃ©ration des 100 recettes reste rapide (quelques centaines de ms) grÃ¢ce Ã  lâ€™index sur user\_id. Ã‡a reste modeste, mais câ€™est bon signe que lâ€™application peut Ã©voluer en volume (et dimensionnement du serveur mis Ã  part, le code ne bloque pas).
* **Outils automatisÃ©s**Â : Jâ€™ai aussi passÃ© un petit scan avec **OWASP ZAP** (un outil de scan de vulnÃ©rabilitÃ©s web). Le scan nâ€™a pas rÃ©vÃ©lÃ© de faille critique sur les endpoints testÃ©s, juste des alertes mineures (manque de certains headers de sÃ©curitÃ© comme Content-Security-Policy, ce que je corrigerai en config serveur/Nginx plus tard).

**Correction des anomalies**Â : Chaque bug ou Ã©cart dÃ©couvert pendant les tests a Ã©tÃ© documentÃ© dans une **issue GitHub** avec label *bug*, puis corrigÃ© dans un commit *fix: ...* spÃ©cifique. Par exemple, un bug #17 portait sur le fait quâ€™une recette pouvait Ãªtre enregistrÃ©e sans ingrÃ©dient, ce qui posait problÃ¨me pour le calcul dâ€™IBU. Jâ€™ai corrigÃ© en ajoutant une validation serveur refusant lâ€™enregistrement dâ€™une recette sans ingrÃ©dient, et jâ€™ai clos lâ€™issue en question. Ce suivi assure la traÃ§abilitÃ© des problÃ¨mes et leur rÃ©solution â€“ câ€™est une bonne pratique que jâ€™ai tenue mÃªme en solo, pour simuler un environnement qualitÃ© pro.

En conclusion, la prÃ©paration et lâ€™exÃ©cution des tests pour Brasse-Bouillon ont Ã©tÃ© conduites de maniÃ¨re mÃ©thodique, couvrant tous les aspects (unitaires, intÃ©gration, fonctionnel, sÃ©curitÃ©). Jâ€™ai ainsi pu vÃ©rifier que lâ€™application **remplit bien les critÃ¨res attendus** et jâ€™ai pu corriger les quelques Ã©carts avant la mise en production. Cela dÃ©montre pleinement ma compÃ©tence Ã  *â€œprÃ©parer et exÃ©cuter les plans de tests dâ€™une applicationâ€*, en visant la conformitÃ© par rapport aux besoins et la fiabilitÃ© du produit final.

### PrÃ©paration et documentation du dÃ©ploiement de lâ€™application

Une fois les tests concluants, il est temps de penser Ã  livrer lâ€™application. Jâ€™ai donc travaillÃ© sur la **PhaseÂ 5 â€“ DÃ©ploiement**, en prÃ©parant tout le nÃ©cessaire pour installer et exÃ©cuter Brasse-Bouillon en environnement de production (ou sur un serveur tiers). Plusieurs actions ont Ã©tÃ© menÃ©esÂ : **documenter la procÃ©dure dâ€™installation**, **configurer la conteneurisation Docker**, prÃ©parer les **scripts de dÃ©ploiement**, et mettre en place le nÃ©cessaire pour la **maintenance** (supervision, sauvegardes).

**Guide dâ€™installation et configuration**Â : Jâ€™ai rÃ©digÃ© un **Guide dâ€™Installation** dÃ©taillÃ© pour le backend (et un plus succinct pour le frontend). Ce guide couvre deux modesÂ : installation manuelle ou via Docker. Pour lâ€™installation manuelle, jâ€™y explique comment cloner le repo, installer Node.js, installer MySQL, configurer les variables dâ€™env, puis lancer les migrations et dÃ©marrer le serveur. Pour Docker, jâ€™ai fourni un fichier `docker-compose.yml` type et expliquÃ© comment le personnaliser. Le guide mentionne aussi les prÃ©requis (version de Node, dâ€™NPM, Docker, etc.). Jâ€™ai veillÃ© Ã  Ã©crire ce document dans un langage accessible, pour quâ€™un administrateur systÃ¨me ou un examinateur puissent suivre les Ã©tapes pas Ã  pas sans me contacter. Jâ€™ai Ã©galement listÃ© les **commandes utiles** (par ex: `docker-compose up --build -d` pour lancer en arriÃ¨re-plan, ou `npx sequelize-cli db:migrate` en cas dâ€™installation manuelle).

Ce document fait partie intÃ©grante du **dossier de dÃ©ploiement**. En complÃ©ment, jâ€™ai crÃ©Ã© un **README de production** qui rÃ©sume comment configurer les variables prod (par ex, mettre `NODE_ENV=production` et configurer le CORS avec le domaine de lâ€™appli). Jâ€™ai aussi notÃ© les **prÃ©conisations de sÃ©curitÃ©** pour la prodÂ : gÃ©nÃ©rer une clÃ© JWT secrÃ¨te robuste, activer SSL, vÃ©rifier les rÃ©glages du firewall (ouvrir juste les ports 80/443 pour lâ€™API, 1883 si MQTT utilis\&eacute, etc.), mettre en place un service comme **PM2** pour gÃ©rer le processus Node en cas de crash, etc. Toutes ces informations seront utiles pour celui qui dÃ©ploiera lâ€™application sur un serveur.

**Conteneurisation Docker**Â : Afin de faciliter le dÃ©ploiement multiplateforme et isoler lâ€™environnement, jâ€™ai crÃ©Ã© des **Dockerfiles** pour le backend (et prÃ©vu un pour le frontend web Ã©ventuel). Le Dockerfile backend est trÃ¨s simpleÂ : basÃ© sur une image Node officielle (node:20), copie du code, installation des dÃ©pendances, exposition du port 3000, et CMD `npm run dev` ou `npm start` selon le contexte. Jâ€™ai testÃ© ce Dockerfile en localÂ : jâ€™ai pu *docker build* lâ€™image et *docker run* le conteneur, puis accÃ©der Ã  lâ€™API via `http://localhost:3000`. Le front Ã©tant une appli mobile, je ne la conteneurise pas pour la distribuer (on gÃ©nÃ¨rera un binaire ou on passera par Expo), mais jâ€™ai tout de mÃªme containerisÃ© le backend, la base et les services annexes via **Docker Compose**. Mon fichier compose inclutÂ : le service `backend` (build du Dockerfile), le service `database` (Postgres dans la doc initiale, mais jâ€™ai adaptÃ© Ã  MySQL selon le choix final), le service `redis`, et mÃªme un service `mqtt_broker` (Mosquitto) pour lâ€™IoT. Ainsi, en une commande, on peut dÃ©ployer une stack complÃ¨te sur nâ€™importe quelle machine Docker.

**Scripts de dÃ©ploiement (CI/CD)**Â : Dans la continuitÃ© de la dÃ©marche DevOps, jâ€™ai configurÃ© un **workflow GitHub Actions** pour automatiser les Ã©tapes de build et test, et simuler un dÃ©ploiement. Le fichier `.github/workflows/ci.yml` contient un job â€œBuild & Testâ€ qui tourne Ã  chaque pushÂ : il installe les dÃ©pendances, lance ESLint et Jest sur backend et frontend. Si tout est vert, un second job â€œSimulated Deploymentâ€ se lance sur la branche main. Ce job pour lâ€™instant ne dÃ©ploie pas rÃ©ellement (je nâ€™avais pas dâ€™hÃ©bergement configurÃ© durant la formation), il affiche juste un message de succÃ¨s dans les logs. Mais lâ€™infrastructure est prÃªteÂ : je pourrais aisÃ©ment ajouter une Ã©tape pour construire lâ€™image Docker et la pousser sur DockerHub, voire pour dÃ©ployer sur un PAAS (Heroku, AWS). Jâ€™ai documentÃ© cela dans `docs/architecture/ci_cd.md` comme piste dâ€™amÃ©lioration. Lâ€™important est que la chaÃ®ne CI/CD est en placeÂ : on a une **IntÃ©gration Continue** robuste, et un dÃ©but de **DÃ©ploiement Continu** (il suffirait dâ€™enlever le flag â€œSimulatedâ€ pour rendre la mise en production automatique sur main). Cette dÃ©marche illustre bien ma contribution Ã  la mise en production dans un esprit DevOps.

**Environnements de test et production**Â : Jâ€™ai dÃ©fini dans la doc comment crÃ©er un **environnement de test** isolÃ©. Par exemple, utiliser une base de donnÃ©es `brasse_bouillon_test` et un fichier .env.test, de maniÃ¨re Ã  pouvoir lancer des tests dâ€™intÃ©gration sans risquer les donnÃ©es de dev. Durant la PhaseÂ 4, jâ€™ai effectivement utilisÃ© une base de test locale sur laquelle je faisais des essais destructifs (injections, suppressions massives) pour ne pas polluer mes vraies donnÃ©es. Pour lâ€™environnement de production, jâ€™ai listÃ© les variables dâ€™environnement spÃ©cifiques (par ex, en prod on activera `logging: false` sur Sequelize, on mettra `DEBUG` sur off, etc.). Jâ€™ai aussi Ã©voquÃ© la nÃ©cessitÃ© de dÃ©finir des **procÃ©dures de rollback**Â : par ex, garder une sauvegarde de la derniÃ¨re version stable de lâ€™image Docker, ou une sauvegarde SQL rÃ©cente de la BDD, au cas oÃ¹ un dÃ©ploiement se passe mal.

**Supervision et maintenance**Â : â€œDÃ©ployerâ€ ne suffit pas, il faut aussi prÃ©voir la maintenance. Jâ€™ai proposÃ© une solution de **monitoring** simple pour Brasse-BouillonÂ : utiliser un outil comme **PM2** pour superviser le process Node (PM2 peut redÃ©marrer lâ€™app en cas de crash et fournir des mÃ©triques sur la consommation). Jâ€™ai Ã©galement conseillÃ© dans la doc de brancher un **service de log** (ex: Winston qui envoie les logs vers un fichier ou un ELK stack) pour garder des traces en production des erreurs. De plus, jâ€™ai planifiÃ© une **stratÃ©gie de sauvegarde** de la base de donnÃ©esÂ : par exemple, un cron job qui exporte chaque nuit la base MySQL en fichier .sql et le stocke sur un stockage externe sÃ©curisÃ©. Ceci est mentionnÃ© dans le plan de maintenance (phase 5). Enfin, jâ€™ai notÃ© quâ€™il serait pertinent de mettre en place des **tests de non-rÃ©gression automatisÃ©s** sur la pipeline CI (par ex, utiliser Dependabot pour scanner les dÃ©pendances vulnÃ©rables, ou dÃ©ployer sur une plateforme de staging pour exÃ©cuter les tests E2E).

Toutes ces prÃ©parations font partie intÃ©grante de la compÃ©tence *â€œprÃ©parer et documenter le dÃ©ploiementâ€*. En effet, jâ€™ai produit un **livrable documentaire** clair (guide dâ€™install, README prod), jâ€™ai mis en Å“uvre les moyens techniques (Docker, CI/CD) pour quâ€™un dÃ©ploiement se fasse de maniÃ¨re **sÃ©curisÃ©e et fiable**, et jâ€™ai anticipÃ© la phase post-dÃ©ploiement (monitoring, backups) pour assurer une **continuitÃ© de service**. On peut considÃ©rer que si demain je devais remettre le projet Ã  un administrateur systÃ¨me, il aurait tout ce quâ€™il faut en main pour dÃ©ployer lâ€™application sans me contacter, ce qui est un signe de qualitÃ©.

### Contribution Ã  la mise en production â€“ DÃ©marche DevOps et amÃ©lioration continue

Le dernier aspect de lâ€™activitÃ©-typeÂ 3 porte sur la contribution Ã  la mise en production dans une **dÃ©marche DevOps**. Jâ€™ai dÃ©jÃ  abordÃ© une partie via le CI/CD et Docker, mais je vais expliciter comment je me suis comportÃ© dans un esprit DevOps sur ce projet.

**Culture DevOps adoptÃ©eÂ :** Bien que seul sur le projet, jâ€™ai cherchÃ© Ã  brouiller la frontiÃ¨re Dev vs Ops en me responsabilisant sur tout le cycle de vie. Je nâ€™ai pas â€œjetÃ© le code par-dessus le murâ€ en espÃ©rant que Ã§a marche en prodÂ : jâ€™ai moi-mÃªme montÃ© les environnements, je les ai scriptÃ©s, et jâ€™ai testÃ© le dÃ©ploiement. Cette attitude est typiquement DevOpsÂ : le dÃ©veloppeur est responsable non seulement du code quâ€™il Ã©crit, mais aussi de son comportement en production. Par exemple, quand jâ€™Ã©crivais une nouvelle fonctionnalitÃ©, je me demandais systÃ©matiquement â€œComment je vais la dÃ©ployerÂ ? Est-ce quâ€™il faudra une migration de baseÂ ? Combien de temps Ã§a prendraÂ ? Est-ce quâ€™il y aura une indisponibilitÃ©Â ?â€. Cela mâ€™a conduit Ã  planifier des *mises en production frÃ©quentes mais petites* (principe dâ€™intÃ©gration continue), pour Ã©viter un big bang final.

**Outils collaboratifs tout au long du cycle**Â : Jâ€™ai utilisÃ© GitHub non seulement pour le code, mais aussi pour le **Suivi des versions** (release notes). Par exemple, jâ€™ai crÃ©Ã© des **tags** Git (v0.1, v0.2â€¦) Ã  des Ã©tapes clÃ©s, de sorte Ã  garder des jalons de version. Avant un Ã©ventuel dÃ©ploiement, je peux ainsi identifier la version Ã  dÃ©ployer. Jâ€™ai Ã©galement Ã©crit un **CHANGELOG** mentionnant les nouveautÃ©s/corrections de chaque version. Cette transparence est un aspect DevOps (on partage lâ€™info, on documente les changements pour lâ€™Ã©quipe Ops ou les utilisateurs).

**QualitÃ© du code et tests automatisÃ©s**Â : La dÃ©marche DevOps inclut souvent dâ€™automatiser tout ce qui peut lâ€™Ãªtre. Jâ€™ai automatisÃ© les tests et lâ€™analyse de code sur chaque push, ce qui est un pilier de lâ€™**IntÃ©gration Continue**. Jâ€™ai aussi configurÃ© des **hooks Git** (via Husky par ex.) pour empÃªcher de committer du code non lintÃ© ou des tests cassÃ©s. Ainsi, la branche main est toujours dans un Ã©tat dÃ©ployableÂ : câ€™est un principe clÃ© (on Ã©vite dâ€™avoir une main instable qui retarde le dÃ©ploiement). GrÃ¢ce Ã  cela, je pourrais dÃ©ployer Ã  tout moment la derniÃ¨re version sans crainte, car la CI mâ€™a garanti quâ€™elle passe les checks.

**Conteneurs et Infrastructure as Code**Â : En fournissant un `docker-compose.yml`, jâ€™ai pratiquÃ© en quelque sorte lâ€™**Infrastructure as Code** â€“ on dÃ©crit dans un fichier texte toute lâ€™infrastructure logicielle (services, ports, volumes). Cela permet de versionner lâ€™infra comme le code, dâ€™y appliquer les mÃªmes revues et tests (jâ€™aurais pu imaginer un test automatique qui lance `docker-compose config` pour valider la syntaxe du fichier). Jâ€™ai aussi dÃ©couvert et documentÃ© lâ€™utilisation possible de **Terraform** ou dâ€™**Ansible** pour aller plus loin (ex: provisionner un serveur sur le cloud et y appliquer mon docker-compose). Ce nâ€™Ã©tait pas exigÃ© dans le projet, mais le fait dâ€™y penser fait partie de la mentalitÃ© DevOps (automatiser jusquâ€™au dÃ©ploiement serveur).

**Simulation de load et tuning**Â : Dans un esprit *â€œOpsâ€*, jâ€™ai fait quelques tests de charge basiques (voir tests plus haut avec 100 recettes crÃ©Ã©es). Jâ€™ai aussi utilisÃ© lâ€™outil `ab` (Apache Benchmark) pour simuler 50 requÃªtes concurrentes sur lâ€™endpoint des recettesÂ : le serveur Node a tenu, avec un temps moyen de \~200ms par requÃªte. Jâ€™ai interprÃ©tÃ© ces rÃ©sultats pour en dÃ©duire que le goulot dâ€™Ã©tranglement principal serait la base de donnÃ©es si on montait en charge, et que je devrais alors envisager de mettre en place un systÃ¨me de **mise en cache plus agressif** (par ex. mettre Cloudflare ou un cache HTTP pour certaines routes publiques). Cette dÃ©marche proactive dâ€™**optimisation** rejoint les compÃ©tences transverses attendues (rÃ©solution de problÃ¨me, amÃ©lioration continue).

**Retour dâ€™expÃ©rience et amÃ©lioration continue**Â : AprÃ¨s chaque phase, jâ€™ai effectuÃ© une petite **rÃ©trospective** (mÃªme tout seul). Par exemple, Ã  la fin de la PhaseÂ 4 (tests), jâ€™ai constatÃ© que jâ€™aurais dÃ» Ã©crire plus de tests dÃ¨s le dÃ©but pour gagner du temps, et je lâ€™ai notÃ© comme axe dâ€™amÃ©lioration personnel. Jâ€™ai Ã©galement identifiÃ© des zones techniques qui pourraient Ãªtre amÃ©liorÃ©es dans le futur (ex: amÃ©liorer la couverture de tests, ajouter de la surveillance en prod, mettre en place un pipeline CI pour le frontend â€“ actuellement jâ€™ai du tests Jest front trÃ¨s basiques, mais jâ€™aimerais ajouter un test de build Expo pour vÃ©rifier que le front continue de compiler sur chaque commit). Cette posture dâ€™**amÃ©lioration continue** est trÃ¨s DevOps Ã©galement, oÃ¹ on cherche toujours Ã  affiner le processus de dÃ©veloppement-dÃ©ploiement.

**Collaboration Dev <> Ops simulÃ©e**Â : Bien que je nâ€™aie pas eu de vrai Ã©quipe Ops en face, jâ€™ai communiquÃ© comme si. Par exemple, jâ€™ai prÃ©parÃ© un **document de passation** pour lâ€™Ã©quipe qui dÃ©ploierait, listant tous les points dâ€™attention (ports utilisÃ©s, variable dâ€™env, tÃ¢ches de cron Ã  mettre en place). Jâ€™ai aussi utilisÃ© un langage adaptÃ© dans mes documents techniquesÂ : concis, clair, structurÃ© (listes Ã  puces, numÃ©rotations dâ€™Ã©tapes) pour quâ€™un **opÃ©rateur systÃ¨me** ou un examinateur sâ€™y retrouve facilement. Je me suis mis Ã  la place de quelquâ€™un qui arriverait sur le projet sans contexteÂ : est-ce quâ€™il pourrait le lancer rapidementÂ ? Cette empathie inter-profil fait partie des compÃ©tences de *communication* transverses attendues, et je pense lâ€™avoir mise en Å“uvre ici.

En synthÃ¨se, ma contribution Ã  la mise en production sâ€™est traduite par un ensemble dâ€™actions concrÃ¨tes (CI/CD, Docker, docs) et par une **philosophie DevOps** adoptÃ©e tout au long du projet (automatisation, partage de lâ€™information, responsabilitÃ© bout-en-bout). GrÃ¢ce Ã  cela, lâ€™application Brasse-Bouillon nâ€™est pas quâ€™un prototype localÂ : elle est prÃªte Ã  Ãªtre dÃ©ployÃ©e sereinement dans un environnement rÃ©el, avec un minimum dâ€™effort. Cela illustre ma compÃ©tence Ã  *â€œcontribuer Ã  la mise en production dans une dÃ©marche DevOpsâ€*, compÃ©tence qui devient de plus en plus essentielle pour un concepteur-dÃ©veloppeur moderne.

---

## Conclusion

Au travers de ces trois activitÃ©s-types, jâ€™ai pu dÃ©crire de maniÃ¨re complÃ¨te et concrÃ¨te mon expÃ©rience sur le projet **Brasse-Bouillon**. Ce projet mâ€™a permis de mettre en pratique lâ€™ensemble des **compÃ©tences du RÃ©fÃ©rentiel 2024** du titre Concepteur-DÃ©veloppeur dâ€™Applications, depuis lâ€™analyse du besoin initial jusquâ€™au dÃ©ploiement et Ã  la soutenance finale. Jâ€™ai adoptÃ© une approche **professionnelle, geek et pragmatique** pour relever les dÃ©fis posÃ©sÂ : quâ€™il sâ€™agisse de choisir la bonne techno front (et de lâ€™agrÃ©menter dâ€™une biÃ¨re ğŸ» de crÃ©ativitÃ© UI), de sÃ©curiser un backend comme un coffre-fort (en appliquant Ã  la lettre les recommandations de lâ€™ANSSI et de lâ€™OWASP), ou dâ€™automatiser mon pipeline DevOps tel un vrai ingÃ©nieur systÃ¨me, jâ€™ai su mobiliser mes compÃ©tences techniques et personnelles.

**Bilan des compÃ©tences mobilisÃ©esÂ :**

* *Bloc 1* (DÃ©veloppement dâ€™une appli sÃ©curisÃ©e)Â : Jâ€™ai montrÃ© ma capacitÃ© Ã  coder une application de A Ã  Z en respectant les bonnes pratiques de sÃ©curitÃ© et de qualitÃ©. En particulier, jâ€™ai installÃ© un environnement complet, dÃ©veloppÃ© des interfaces mobiles ergonomiques, programmÃ© des composants mÃ©tiers robustes (avec calculs, rÃ¨gles de gestion, validations), et gÃ©rÃ© mon projet avec mÃ©thode (Agile, documentation, communication).
* *Bloc 2* (Conception dâ€™une appli multicouche)Â : Jâ€™ai brillamment assumÃ© le rÃ´le de concepteur en analysant finement le besoin (user stories, priorisation), en concevant une architecture logicielle adaptÃ©e (multi-couches, modulable, sÃ©curisÃ©e), et en rÃ©alisant une base de donnÃ©es relationnelle saine. Jâ€™ai Ã©galement montrÃ© une ouverture vers dâ€™autres types de donnÃ©es (NoSQL) pour optimiser mon application.
* *Bloc 3* (PrÃ©paration du dÃ©ploiement)Â : Jâ€™ai mis en place une stratÃ©gie de test poussÃ©e pour livrer un produit sans dÃ©faut majeur, et jâ€™ai prÃ©parÃ© tout le nÃ©cessaire pour le dÃ©ploiementÂ : conteneurs Docker, guide dâ€™installation, scripts CI/CD, tout en adoptant les principes DevOps dâ€™automatisation et de collaboration.

Au-delÃ  des compÃ©tences techniques, ce projet a Ã©tÃ© lâ€™occasion de dÃ©montrer mes **compÃ©tences transversales**Â : la *communication* (Ã©crite Ã  travers la doc, orale lors de la soutenance simulÃ©e, reformulation des besoins client), la *rÃ©solution de problÃ¨mes* (debuggage, optimisation, prise en compte des retours utilisateurs), et *lâ€™apprentissage continu* (montÃ©e en compÃ©tence sur Redis, Docker, JWTâ€¦ au fil du projet). Jâ€™ai aussi veillÃ© Ã  garder un Ã©tat dâ€™esprit **positif et professionnel**, nâ€™hÃ©sitant pas Ã  injecter une touche dâ€™humour ou de crÃ©ativitÃ© quand appropriÃ©, tout en restant focalisÃ© sur les objectifs.

**PerspectivesÂ :** Brasse-Bouillon est dÃ©sormais en bonne voie pour une mise en production effective. Les prochaines Ã©tapes consisteront Ã  dÃ©ployer lâ€™application sur un serveur accessible aux utilisateurs bÃªta, puis dâ€™ajouter progressivement les fonctionnalitÃ©s â€œnice-to-haveâ€ (espace communautaire, etc.). GrÃ¢ce Ã  la base solide construite durant ce projet, ces Ã©volutions pourront se faire de maniÃ¨re itÃ©rative et sÃ©curisÃ©e. Je compte Ã©galement profiter de lâ€™aprÃ¨s-projet pour me perfectionner encore, par exemple en implÃ©mentant les suggestions dâ€™optimisation Ã©voquÃ©es (monitoring avancÃ©, tests E2E, amÃ©lioration de lâ€™UX mobile).

En conclusion, la rÃ©alisation du prÃ©sent dossier professionnel mâ€™a permis de prendre du recul sur le travail accompli et de mesurer le chemin parcouru. De la phase dâ€™**initialisation**, oÃ¹ tout nâ€™Ã©tait quâ€™idÃ©e, Ã  la phase de **soutenance** oÃ¹ je prÃ©sente fiÃ¨rement un produit fini, jâ€™ai acquis une expÃ©rience prÃ©cieuse. Ce dossier atteste de ma capacitÃ© Ã  mener un projet applicatif **complet et complexe** en autonomie, en endossant successivement les casquettes dâ€™analyste, dâ€™architecte, de dÃ©veloppeur, de testeur et dâ€™administrateur. Cette polyvalence, associÃ©e Ã  un socle mÃ©thodologique solide, fait de moi un candidat pleinement qualifiÃ© pour le titre de **Concepteur DÃ©veloppeur dâ€™Applications**.
