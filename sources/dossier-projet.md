# Dossier Professionnel – Titre Professionnel Concepteur Développeur d’Applications (Niveau 6, RNCP 37873)

## Déclaration sur l'honneur

Je soussigné **Benoît Brémaud**, candidat au titre professionnel **Concepteur Développeur d’Applications**, déclare sur l'honneur que ce dossier professionnel est le fruit d’un travail personnel. Le projet présenté et les exemples de pratique professionnelle décrits sont issus de **mon expérience réelle** dans le cadre de ma formation et ne sont pas des reproductions du travail d’autrui. Je m'engage à respecter le règlement de l'examen et atteste de l'authenticité des informations et documents fournis dans ce dossier. Fait pour servir et valoir ce que de droit, je certifie exacts les renseignements figurant dans ce document, **daté** et **signé** par mes soins.

## Informations du candidat

* **Nom Prénom :** Benoît Brémaud
* **Titre professionnel visé :** Concepteur Développeur d’Applications – Niveau 6 (Code RNCP 37873)
* **Diplôme ou niveau d’étude le plus élevé :** BTS Services Informatiques aux Organisations (Option SLAM) – 2015 *(équivalent Bac+2)*
* **Expérience professionnelle :** Développeur indépendant sur projets personnels (2 ans) et formation intensive en développement d’applications (2024)

## Présentation du projet support – *« Brasse-Bouillon »*

Pour illustrer mes compétences, j’ai choisi de m’appuyer sur mon projet de fin de formation intitulé **Brasse-Bouillon**. Il s’agit d’une application web et mobile open-source visant à aider les **brasseurs amateurs** à gérer et partager leurs recettes de bière maison. Ce projet a été réalisé **en autonomie** dans un contexte Agile (inspiration Scrum) sur une durée de 4 mois. Brasse-Bouillon se décompose en une application mobile multiplateforme (basée sur **React Native**) et une API web sécurisée (**Node.js/Express**), le tout adossé à une base de données **MySQL**. L’application fournit des outils essentiels pour calculer les paramètres de brassage (degrés alcool, amertume – **ABV/IBU**), planifier les sessions de brassage et suivre l’évolution des cuvées.

**Fonctionnalités principales :** création et gestion de recettes (CRUD complet), calcul automatique de l’IBU et de l’ABV à partir des ingrédients saisis, suivi des sessions de brassage avec calendrier, authentification sécurisée des utilisateurs, et partage communautaire des recettes. À terme, le projet envisage d’intégrer des capteurs **IoT** pour suivre la température des cuves en temps réel, ainsi qu’un module de notifications pour rappeler les étapes clés (ébullition, fermentation) aux brasseurs. Le développement s’est déroulé en plusieurs **phases** itératives, couvrant l’analyse du besoin (Phase 1 : Initialisation), la conception technique (Phase 2), le développement (Phase 3), les tests (Phase 4), le déploiement (Phase 5) et enfin la soutenance (Phase 6). Chacune de ces phases sera évoquée dans les exemples de pratiques professionnelles qui suivent.

**Contexte et organisation :** J’ai adopté une méthodologie **Agile Scrum** avec des sprints de 2 semaines, un backlog produit géré sur GitHub Projects, et des réunions rapides (*daily stand-up*) pour suivre l’avancement. Travaillant seul sur ce projet, j’ai néanmoins simulé un environnement collaboratif : utilisation de GitHub pour le versioning et la revue de code, gestion des tâches via des issues et milestones, et documentation continue dans un dossier `docs/` structuré. Mon rôle a couvert l’ensemble des activités du cycle de vie applicatif, depuis la rédaction du **cahier des charges** jusqu’au **déploiement**. Tout au long du projet, j’ai veillé à respecter les normes de sécurité (ex : recommandations OWASP et guides de l’ANSSI) et d’**accessibilité** (RGAA) ainsi qu’à appliquer les principes d’**éco-conception** logicielle (code optimisé, fonctionnalités offline pour limiter les sollicitations réseau inutiles, etc.).

Dans les sections qui suivent, je décris **trois exemples de pratique professionnelle**, chacun en lien avec l’un des **blocs de compétences (activités-types)** du référentiel CDA 2024. Chacun de ces exemples sera illustré par des cas concrets issus du projet Brasse-Bouillon, en mettant en avant les compétences techniques mobilisées, les outils utilisés, les extraits de code significatifs, ainsi que mes choix et démarches professionnelles. Ce dossier témoigne de ma capacité à **développer une application sécurisée** (Activité-type 1), à **concevoir et développer une application organisée en couches** (Activité-type 2), et à **préparer le déploiement d’une application** (Activité-type 3), le tout dans une démarche professionnelle conforme au référentiel du titre visé.

---

## Activité-type 1 : Développer une application sécurisée

*(**Bloc de compétences 1 :** Préparer l’environnement de travail ; Développer des interfaces utilisateur ; Développer des composants métier ; Contribuer à la gestion du projet informatique – en veillant à la sécurité et à la qualité logicielle)*

**Contexte :** Cette première activité-type couvre l’ensemble de la phase de **développement** de l’application Brasse-Bouillon (Phases 2 et 3 du projet, conception détaillée et codage). Dans le cadre de mon projet, cela s’est traduit par la mise en place d’un **environnement de développement complet**, le développement du **front-end mobile** (interfaces utilisateur) et du **back-end** (composants métier et API REST), tout en appliquant les bonnes pratiques de codage sécurisé. Par ailleurs, j’ai participé activement à la **gestion du projet** au quotidien : planification des tâches, communication au sein de l’équipe (même si réduite à moi-même, j’ai simulé des échanges professionnels avec tuteurs/clients), suivi des issues et adaptation aux imprévus. Je détaille ci-dessous ces réalisations.

### Installation et configuration de l’environnement de travail (poste de développement)

Dès le lancement du projet, j’ai préparé un environnement de travail **similaire à l’environnement de production** prévu. Conformément aux bonnes pratiques, j’ai installé et configuré sur mon poste tous les outils et dépendances nécessaires au développement :

* **Node.js 18** (avec NPM) pour le runtime JavaScript backend, et **Expo CLI** pour le développement React Native côté mobile.
* **IDE (Visual Studio Code)** avec extensions ESLint/Prettier pour le linting et le formatage automatique du code, assurant un style uniforme.
* **SGBD MySQL** en local pour reproduire la base de données de production. J’ai utilisé Docker pour déployer rapidement un conteneur MySQL et éviter les écarts de configuration. En effet, j’ai privilégié une installation via **Docker Compose** pour aligner mon poste de dev sur une stack proche de la prod : un service backend Node, un service base de données MySQL, un cache Redis, etc.. Cela m’a permis de paramétrer un environnement isolé où l’API tournait sur un port local (3000) avec accès à une base **brasse\_bouillon** dédiée, similaire à ce qui sera utilisé en production. Par exemple, le fichier de configuration Sequelize se connecte sur l’hôte `db` (déclaré dans Docker Compose) avec les identifiants de la base .
* **Outils de versionnement et collaboration :** Git et GitHub. J’ai créé un dépôt GitHub privé pour le code source et configuré le gestionnaire de versions dès le départ du projet. Chaque nouvelle fonctionnalité a été développée sur une branche dédiée (selon la convention de nommage Angular : par ex. `feat/frontend-add-login-screen` pour l’ajout de l’écran de login). J’ai ainsi pu suivre un workflow professionnel *GitFlow* adapté : branches `develop` et `main`, pull requests pour fusionner les contributions, commits normalisés (messages de commit de type *feat*, *fix*, *chore*… selon Conventional Commits) et références aux issues (ex : *Closes #12* dans un message de merge).
* **Outils de test et de documentation :** installation de **Jest** (côté front et back) pour les tests unitaires, et de **Postman** pour tester manuellement les endpoints de l’API. J’ai également installé **Swagger** (OpenAPI) pour documenter les endpoints REST pendant le développement, et utilisé **Figma** en parallèle pour les maquettes UI. L’ensemble de ces outils et technologies a été listé et validé en début de projet, formant la “boîte à outils” du développeur en phase de build.

Une fois les outils en place, j’ai **configuré les variables d’environnement** (fichier `.env`) pour centraliser les paramètres sensibles : par exemple, la connexion BDD (host, user, password) et la clé secrète JWT. Cela permet de respecter les exigences de sécurité (ne pas hardcoder ces informations dans le code source). L’environnement de travail a donc été préparé de manière **structurée et sécurisée** afin que le développement puisse démarrer sur de bonnes bases, en minimisant les écarts avec la cible de production. Cette étape préliminaire, bien que parfois fastidieuse, m’a évité de nombreux problèmes d’environnement par la suite (dépendances manquantes, “works on my machine” syndrome, etc.), illustrant ma compétence à **installer et configurer un environnement de développement complet**.

### Développement des interfaces utilisateur (Front-end mobile multiplateforme)

Sur Brasse-Bouillon, l’interface utilisateur est une **application mobile** développée avec **React Native** (Expo). L’objectif était de proposer une expérience fluide aux brasseurs amateurs sur smartphone, avec une UI claire respectant la charte graphique du projet. Je me suis appuyé sur les maquettes conçues sous Figma (écrans « Accueil », « Liste des recettes », « Détail recette », « Nouvelle recette », etc.) pour guider le développement des composants visuels.

**Implémentation des écrans :** J’ai créé différents composants React Native pour structurer l’application en **pages fonctionnelles**. Par exemple : un composant `<HomeScreen>` pour l’écran d’accueil, `<RecipeListScreen>` pour la liste de recettes, `<RecipeForm>` pour le formulaire de création/édition, etc. Chaque écran est stylé via Stylesheet en respectant la charte (couleurs, typographies) définie dans le fichier `charte_graphique.md`. Sur l’écran d’accueil, j’affiche par exemple le logo de l’application et un message de bienvenue, avec un appel API de test à l’ouverture :

```jsx
// Extrait simplifié de HomeScreen.tsx (frontend)
useEffect(() => {
  api.get('/ping')
    .then(res => console.log('✅ Réponse API :', res.data))
    .catch(err => console.error('❌ Erreur API :', err.message));
}, []);

return (
  <View style={styles.container}>
    <Image source={require('../assets/icon.png')} style={styles.logo} />
    <Text style={styles.title}>Bienvenue sur Brasse-Bouillon 🍻</Text>
    <Text style={styles.subtitle}>L’application dédiée aux brasseurs amateurs !</Text>
  </View>
);
```

*(Code React Native – l’écran Home effectue un appel à l’API `/ping` dès son montage, puis affiche un titre et un sous-titre de bienvenue)*.

Cet extrait illustre plusieurs points de compétence : **intégration front-back** (appel d’un service API via `api.get` grâce à un module `api.js/ts` configuré avec Axios), **développement d’une interface utilisateur responsive** (conteneur centré, image logo, textes stylés). J’ai veillé à adapter l’UI pour différents terminaux : l’appli supporte le **mode sombre** et l’orientation portrait/paysage grâce aux styles dynamiques Expo, et j’ai testé le rendu sur simulateur iOS et Android. Pour garantir l’**accessibilité**, j’ai utilisé des composants standards (Text, Button) qui supportent les technologies d’assistance, et je me suis assuré que les contrastes de couleurs respectent les recommandations WCAG (ex : texte gris #666 sur fond écru #fffdf7 pour un contraste suffisant). J’ai aussi intégré quelques *accessibility labels* sur les boutons/icônes critiques pour les lecteurs d’écran.

**Navigation et état :** L’application utilise **Expo Router** (basé sur React Navigation) pour gérer la navigation entre les écrans. J’ai configuré un système d’onglets (tabs) pour les sections principales (Recettes, Sessions, Profil) et une pile de navigation pour les écrans détaillés. Le **state management** est géré simplement via le hook `useState` et le contexte React pour partager certains états globaux (ex : informations de l’utilisateur connecté). Par exemple, après le login, le token JWT est stocké de manière sécurisée (stockage sécurisé Expo ou HttpOnly cookie si web) et un contexte `AuthContext` fournit l’utilisateur courant aux composants, évitant de redemander l’API à chaque fois.

**Composants réutilisables :** Dans une démarche d’optimisation, j’ai développé quelques composants génériques comme un composant `<RecipeCard>` pour afficher une recette de manière uniforme (titre, auteur, IBU/ABV calculés, etc.), ou un `<IngredientItem>` pour lister les ingrédients avec quantités. Ces composants sont stylés de façon cohérente grâce à une **Design System maison** : palette de couleurs, tailles de police, marges, tout est centralisé dans un fichier de constantes afin d’assurer une homogénéité (par ex. `constants/Colors.ts` définit les couleurs primaires/secondaires utilisées dans l’app). Cette rationalisation facilite la maintenance : si la charte graphique évolue, je sais où modifier sans tout parcourir.

Enfin, j’ai veillé à ce que les interfaces utilisateur soient **sécurisées** et robustes : validation des saisies côté front (ex : vérification des champs obligatoires dans le formulaire de recette, avec affichage de messages d’erreur utilisateur clairs), désactivation des boutons tant qu’une action réseau n’est pas terminée (pour éviter les doubles soumissions), etc. Par exemple, lors de la création d’une recette, si un champ important est manquant, le front empêche l’envoi et affiche une alerte, plutôt que de laisser l’API répondre une erreur 400. Ces petites attentions contribuent à la **qualité perçue** et à la sécurité (on limite ainsi les cas de figure non prévus côté serveur).

**Illustration visuelle :** Ci-dessous une capture (fictive) de l’écran *Liste des recettes* montrant l’interface mobile réalisée : on y voit la liste des recettes de l’utilisateur avec leur nom, style, et une icône indiquant si la recette est publique ou privée. En haut, un bouton *Ajouter* permet de créer une nouvelle recette. *(Capture non incluse dans ce texte)* Cette interface respecte la maquette validée lors de la phase de conception et démontre ma capacité à **développer des interfaces web/mobile ergonomiques** alignées sur les besoins utilisateurs.

### Développement des composants métiers et de l’API (Back-end Node.js)

En parallèle du front-end, j’ai **développé le backend** de l’application en **Node.js** avec le framework **Express**. Ce serveur REST est le cœur “métier” de Brasse-Bouillon : il expose des **endpoints HTTP** permettant au front de créer des utilisateurs, de gérer les recettes, de lancer des sessions de brassage, etc. L’accent a été mis sur la **sécurité** et la propreté du code, en suivant une approche structurée proche du modèle MVC (Modèle-Vue-Contrôleur, la “Vue” étant ici le front séparé).

**Structure du backend :** Le code est organisé en modules clairs, conformément au plan d’architecture backend que j’ai rédigé. On retrouve notamment :

* Un dossier **`controllers/`** contenant la logique métier pour chaque entité (ex : `recipeController.js` gère les opérations CRUD des recettes).
* Un dossier **`models/`** définissant les modèles de données via l’ORM **Sequelize** (par ex. `Recipe.js`, `User.js`, etc., qui mappent les tables SQL correspondantes).
* Un dossier **`routes/`** où sont déclarées les routes Express et les **middlewares** associés. J’ai par exemple un fichier `recipes.js` qui associe les URL `/recipes` aux fonctions du recipeController, en intercalant un middleware d’authentification JWT pour sécuriser les opérations sensibles (création/édition/suppression de recette).
* Un dossier **`middlewares/`** contenant les fonctions de middleware globales, notamment `verifyToken` pour la vérification du JWT sur les routes privées, et un middleware de **logging** des requêtes (utilisant `morgan` pour tracer chaque requête entrante, utile en debug).
* Un dossier **`config/`** pour la configuration de la base de données (fichier `database.js` vu plus haut) et d’autres services (par ex. config de Redis, bien que celui-ci soit facultatif en dev).
* Un dossier **`tests/`** pour d’éventuels tests automatisés backend (par ex. `sample.test.js` montre la configuration Jest opérationnelle).

Cette architecture modulaire rend le code plus **maintenable et évolutif**, et facilite la **répartition des responsabilités**. J’ai veillé à la respecter au maximum : par exemple, la logique de calcul de l’ABV/IBU est encapsulée dans un **service métier** (fonction utilitaire dans `utils/calculations.js`), appelé depuis le controller de recettes lors de la création d’une recette pour calculer ces valeurs automatiquement. Ainsi, si demain on veut réutiliser ces calculs ailleurs (ex : pour simuler une recette sans la créer), on pourra appeler la même fonction.

**Gestion de la base de données :** Grâce à Sequelize, j’ai pu définir mes modèles simplement en JavaScript. Par exemple, le modèle `Recipe` comprend des champs `name, description, abv, ibu, userId` etc., et déclare une association `Recipe.belongsTo(User)` et `Recipe.belongsToMany(Ingredient, through: RecipeIngredient)`. J’ai implémenté les principales entités du modèle conceptuel élaboré en conception : Utilisateur, Recette, Ingrédient, Session de brassage (BrewSession), Commentaire, Note, Équipement, Notification… Toutes ne sont pas encore actives dans le MVP, mais la base est prête à les accueillir. J’ai également mis en place les **contraintes d’intégrité** nécessaires au niveau base : clés étrangères avec *ON DELETE CASCADE* pour que la suppression d’un utilisateur entraîne celle de ses recettes automatiquement (vérifié via un test en Phase 4), contraintes d’unicité sur certains champs (email utilisateur unique), etc. Durant le développement, j’ai utilisé **SQLite en mémoire** pour exécuter certains tests unitaires plus rapidement, et une base MySQL dédiée pour les tests d’intégration lourds.

**Endpoints et logique métier :** J’ai développé l’ensemble des endpoints requis pour le MVP, en suivant les bonnes pratiques REST (noms de ressources au pluriel, statuts HTTP appropriés…). Par exemple, pour l’entité Recette :

* `GET /recipes` : retourne la liste des recettes (publiques ou appartenant à l’utilisateur connecté). J’ai implémenté la recherche de toutes les recettes via `Recipe.findAll()` de Sequelize, en renvoyant un status 200 et les données JSON.
* `GET /recipes/:id` : retourne le détail d’une recette, y compris la liste de ses ingrédients. Cela utilise la capacité de Sequelize à *eager-load* les relations : on inclut le modèle Ingredient dans la requête, via une jointure automatique. Si l’ID n’existe pas, on renvoie un 404 Not Found.
* `POST /recipes` : création d’une nouvelle recette. Cette route est protégée par JWT (il faut être authentifié). Dans le controller, je récupère l’ID utilisateur depuis `req.user` injecté par le middleware JWT. Je vérifie également la présence des champs obligatoires (`name`, `description`) et renvoie une erreur 400 en JSON si manquants. Ensuite je crée la recette en base avec `Recipe.create`. S’il y a des ingrédients passés dans le corps, j’utilise `RecipeIngredient.bulkCreate` pour insérer efficacement toutes les associations en une seule requête. En sortie, je renvoie un status 201 Created avec un petit message de succès et la recette créée. Cette création illustre la **mise en œuvre d’une logique métier sécurisée** : seuls les utilisateurs connectés peuvent créer, leur identité est liée à la recette, et des validations empêchent les données incomplètes.
* `PUT /recipes/:id` : mise à jour d’une recette existante. Ici j’ai mis un point d’honneur à **sécuriser l’opération** : je récupère la recette en base, puis je vérifie que le **propriétaire** de la recette correspond à l’utilisateur appelant (et éventuellement, on pourrait autoriser un rôle admin). Si ce n’est pas le cas, je renvoie un 403 Forbidden. Ainsi, un utilisateur malintentionné ne peut pas modifier la recette de quelqu’un d’autre en devinant son ID, ce qui est une faille courante que j’ai pris soin d’éviter. Après cette vérification, je mets à jour uniquement les champs présents dans la requête (pour permettre des modifications partielles) puis je recalcule éventuellement les ingrédients associés : par simplicité, j’ai choisi de supprimer toutes les anciennes associations `RecipeIngredient` et d’insérer la nouvelle liste reçue. Enfin, je renvoie la recette mise à jour avec ses nouveaux ingrédients. Ce processus garantit l’intégrité des données (pas de doublons ou de restes d’anciennes liaisons).
* `DELETE /recipes/:id` : suppression d’une recette. Là encore, je vérifie l’ownership avant de détruire l’objet. Grâce aux *cascade delete*, toutes les entrées associées (les ingrédients de la recette, les commentaires, etc.) sont supprimées automatiquement en base, ce qui simplifie la logique côté serveur tout en maintenant la cohérence.

Outre les recettes, j’ai implémenté de façon similaire les endpoints pour les utilisateurs (`/auth/register`, `/auth/login`, `/auth/me`…), pour les sessions de brassage (`/sessions`), etc., en respectant à chaque fois la logique métier et les contrôles de sécurité nécessaires. Par exemple, l’endpoint de **login** génère un **JWT** signé côté serveur et le renvoie au client : j’utilise la librairie `jsonwebtoken` pour créer un token contenant l’ID, l’email et le rôle de l’utilisateur, avec une expiration de 24h. Le mot de passe fourni est vérifié avec **bcrypt** (hachage sécurisé stocké en base). Pour les routes sensibles, j’ai créé un middleware `verifyToken` qui intercepte le header *Authorization* et valide le JWT ; s’il est expiré ou invalide, on renvoie un 401 Unauthorized. J’ai également prévu un middleware de contrôle de **rôle** (par ex. `verifyRole('admin')`) pour certaines opérations admin éventuellement. Ainsi, la sécurisation est **défensive** et implémentée à plusieurs niveaux (frontend ET backend).

**Qualité du code :** Tout au long du développement des composants métier, j’ai documenté et formaté mon code de manière professionnelle. Par exemple, j’ai rédigé des **commentaires JSDoc** au-dessus de chaque handler de route (voir `/** ... */` dans l’extrait du controller recettes) pour expliquer son rôle, ses paramètres et le comportement attendu. Ces commentaires pourront servir plus tard à générer une documentation API automatisée. J’ai appliqué un style de code cohérent grâce à **ESLint** (configuré selon les recommandations Airbnb/Prettier) : toute erreur de lint était corrigée immédiatement, et l’outil formatait le code au fur et à mesure pour qu’il reste lisible. J’ai également suivi les principes de base du **Clean Code** : noms de variables explicites, pas de “code mort”, découpage en fonctions courtes et réutilisables. En cas de bug ou d’erreur détectée, j’ai utilisé une démarche rigoureuse de **résolution de problème** : lecture des logs serveurs (stacktrace), reproduction du bug en local, utilisation de breakpoints ou de `console.error` pour isoler l’origine, puis correction et test. Par exemple, j’ai rencontré un problème de contrainte étrangère lors de l’association d’un ingrédient à une recette : l’erreur SQL *« Cannot add or update a child row: a foreign key constraint fails »* m’a indiqué un souci d’ordre de création. Après analyse, j’ai compris qu’il fallait créer l’ingrédient avant de l’associer ; j’ai donc ajusté la logique et ajouté un contrôle pour éviter cette erreur. Ce type de diagnostic montre mon **esprit d’analyse** et ma capacité à corriger des dysfonctionnements de manière structurée.

En somme, le développement des composants métier sur Brasse-Bouillon témoigne de ma compétence à **concevoir un backend sécurisé et fonctionnel**. J’ai su intégrer des bonnes pratiques de sécurité (contrôles d’accès, chiffrage des mots de passe, tests unitaires des fonctions critiques), tout en produisant un code de qualité, maintenable et documenté. **Chaque fonctionnalité développée a été testée** manuellement via Postman ou automatiquement via Jest pour s’assurer qu’elle répond aux attentes (ex : un test unitaire vérifie que *1 + 1 = 2* fonctionne – début modeste pour valider la configuration Jest, puis des tests plus complets vérifieront que la création d’une recette sans nom retourne bien une erreur 400, etc.). Ces efforts garantissent que l’application est robuste avant même la phase de test formelle.

### Contribution à la gestion du projet informatique (méthodes, collaboration, reporting)

En plus du développement pur, l’activité-type 1 requiert de **contribuer à la gestion du projet**. Dans le cadre de Brasse-Bouillon, j’ai rempli ce rôle en adoptant des outils et méthodes qui m’ont permis de structurer le travail et de communiquer efficacement sur l’avancement.

**Planification et suivi Agile :** Comme mentionné, j’ai organisé le projet en sprints de deux semaines. Au début de chaque sprint, j’établissais un **Sprint Backlog** avec les user stories à implémenter prioritairement. Par exemple, lors du Sprint 1, les objectifs majeurs étaient la mise en place de l’authentification et le CRUD de recettes (US01 à US04). J’ai utilisé l’outil **GitHub Projects** (Kanban) pour suivre l’état des tâches : colonnes *Todo / In Progress / Done*. Chaque fonctionnalité correspondait à une **issue** décrivant la tâche, avec une checklist des sous-tâches. J’appliquais des **étiquettes (labels)** sur les issues pour préciser leur nature (ex : `type:feature`, `priority:high`, `scope:backend`) et j’assignais les issues aux **milestones** de chaque phase (par ex. milestone *P3 – Développement* qui regroupait toutes les tâches du bloc développement). Cette granularité m’a aidé à garder une vue claire de l’avancement et à **prioriser** intelligemment les développements.

**Communication et reporting :** Bien que seul développeur, j’ai pris l’habitude de rédiger un court **compte-rendu hebdomadaire** comme si je devais informer un chef de projet ou un client. Ce rapport (tenu dans le `README.md` ou dans un journal de bord) récapitulait les fonctionnalités terminées durant la semaine, les éventuels retards ou problèmes rencontrés, et le plan pour la semaine suivante. Par exemple, à la fin de la Phase 3, j’ai noté que toutes les fonctionnalités du MVP étaient implémentées sauf le module communautaire (reporté en *Nice-to-have*), et que quelques bugs restaient à corriger sur la partie calcul IBU/ABV. J’ai aussi communiqué sur les décisions techniques prises : par exemple, le choix de **React Native** pour le front (justifié par le besoin multiplateforme) ou de **MySQL** pour la base de données (choisi pour sa robustesse et ma familiarité, au lieu de PostgreSQL initialement envisagé). Justifier mes choix fait partie de la communication professionnelle que doit maîtriser un concepteur-développeur.

J’ai également soigné la **communication technique** à travers la documentation : j’ai produit un **guide d’installation** et de lancement du projet pour qu’un tiers puisse le tester facilement, j’ai documenté les *API endpoints* dans un fichier Markdown dédié (`api_overview.md`) et j’ai maintenu à jour le Wiki du dépôt GitHub pour expliquer l’architecture, la charte graphique, etc. L’objectif était double : faciliter les échanges avec d’autres parties prenantes (par exemple, transmettre le dossier à un évaluateur ou un collègue DevOps pour déploiement), et me constituer une référence écrite pour ne rien oublier (par exemple, les étapes pour initialiser la BDD en local sont notées noir sur blanc, évitant les erreurs de mémoire).

**Méthodes de travail collaboratives :** Même en solo, j’ai respecté les conventions de collaboration comme si j’étais en équipe. Par exemple :

* J’ai utilisé la fonctionnalité de **Pull Request** sur GitHub pour intégrer mes propres branches, en remplissant systématiquement la description avec un rappel du contexte, des **checklists** de complétion (tests passés, review faite) et en liant les issues résolues (« Closes #numéro »). Cela m’a discipliné et constitue une trace exploitable du cheminement du projet.
* J’ai mis en place une **intégration continue** (voir Activité 3 pour le détail) de sorte que chaque push de code déclenche automatiquement les tests et l’analyse de lint. Ainsi, même sans collègue pour revue, j’avais un filet de sécurité pour détecter rapidement une régression ou un oubli de bonne pratique. Par exemple, si par inadvertance j’introduisais une erreur ESLint, le workflow GitHub Actions marquait le build en échec avec un message d’erreur explicite (« ❌ Linting failed. Please fix code style issues. »).
* J’ai pratiqué la **veille technologique** tout au long du projet. Lorsque j’ai bloqué sur un problème ou eu un doute technique, j’ai consulté les ressources en ligne (MDN, Stack Overflow, documentation officielle React Native/Express). J’ai suivi également des communautés de développeurs (forums, Discord) liées au brassage ou à l’IoT pour m’inspirer de solutions existantes. Par exemple, pour intégrer l’IoT plus tard, je me suis renseigné sur **MQTT** et j’ai découvert la solution Eclipse Mosquitto, que j’ai directement intégrée dans mon docker-compose pour tester un broker local. Cette curiosité et cette adaptation continue démontrent la compétence *Apprendre en continu* du référentiel.

**Bilan sur Activité 1 :** À travers ces réalisations, j’ai couvert l’ensemble des compétences de l’Activité-type 1. J’ai **préparé mon environnement** de manière professionnelle, **développé des interfaces** ergonomiques et accessibles, **conçu le code métier** en assurant la sécurité et la qualité, et **contribué activement à la gestion du projet** via des méthodes Agiles, la documentation et la communication. En somme, j’ai été capable de **“développer une application sécurisée”** de bout en bout, en portant la double casquette de développeur et de collaborateur projet responsable.

---

## Activité-type 2 : Concevoir et développer une application sécurisée organisée en couches

*(**Bloc de compétences 2 :** Analyser les besoins et maquettage ; Définir l’architecture logicielle multicouche ; Concevoir et mettre en place une base de données relationnelle ; Développer des composants d’accès aux données SQL et NoSQL)*

Pour ce deuxième exemple, je reviens sur les **phases amont** du projet Brasse-Bouillon, où il a fallu concevoir l’application avant de la coder. Cette activité-type correspond à la **Phase 1 (Initialisation)** et **Phase 2 (Conception technique)** de mon projet, au cours desquelles j’ai endossé le rôle d’analyste et d’architecte. J’y décrirai comment j’ai : **recueilli et analysé les besoins** à partir du sujet fil rouge, **élaboré les maquettes fonctionnelles** de l’appli, puis **défini l’architecture technique** en couches (front-end, back-end, base de données). J’aborderai aussi la conception de la **base de données relationnelle** et la mise en place des composants d’accès aux données via l’ORM et autres outils (SQL et un soupçon de NoSQL avec Redis). C’est pendant ces étapes que se décident les fondations d’une application, et j’ai appliqué une démarche rigoureuse pour que le projet soit bien posé avant d’entamer le développement.

### Analyse des besoins utilisateurs et maquettage (Phase 1 – Initialisation)

Au tout début du projet, j’ai consacré du temps à comprendre et formaliser les **besoins**. Le contexte m’a été fourni par le document *Sujet B3 – Fil Rouge* (projet fil rouge de la formation CDA), décrivant un scénario où une association de brasseurs amateurs souhaitait une application pour partager des recettes et suivre leurs brassins. À partir de ce cahier des charges initial (fournissant les grandes lignes fonctionnelles), j’ai mené ma propre **analyse fonctionnelle** en plusieurs étapes :

* **Clarification du besoin – méthode 5W1H** : J’ai reformulé les objectifs du projet en répondant aux questions *Who, What, Why, When, Where, How*. Qui sont les utilisateurs cibles ? (Brasseurs amateurs, éventuellement des admins gérant la communauté). Quoi ? (Une appli mobile pour recettes de bière). Pourquoi ? (Pour faciliter le suivi des recettes et l’échange de connaissances). Quand et où ? (En mobilité, pendant les sessions de brassage à domicile, donc besoin offline partiel). Comment ? (Via une application smartphone connectée à une base de données partagée). Cette clarification m’a permis de dégager les **périmètres** du projet et quelques contraintes (ex : nécessité d’un mode hors-ligne partiel d’où l’importance d’une bonne synchro, ou l’attention à l’ergonomie car les brasseurs auront les mains prises en brassant !).

* **Définition des fonctionnalités et des utilisateurs (personas)** : J’ai imaginé des **personas** typiques – par exemple *Martin*, brasseur débutant qui veut juste suivre des recettes existantes, ou *Jeanne*, brasseuse expérimentée qui crée ses propres recettes et cherche à optimiser ses paramètres (IBU, ABV). Cela m’a aidé à lister les **fonctionnalités attendues**. J’ai couché ces fonctionnalités sous forme de **User Stories** dans un document dédié. Par exemple : *“En tant que brasseur amateur, je veux créer une nouvelle recette afin de garder une trace de mes créations”* (US01), *“En tant qu’utilisateur, je veux que l’appli calcule automatiquement l’IBU et l’ABV afin de connaître les caractéristiques de ma bière”* (US04), etc. Chaque user story est accompagnée de **critères d’acceptation** concrets (champs à saisir, résultats attendus) qui serviront plus tard de base aux tests. Au total, j’ai identifié une dizaine de user stories couvrant la gestion des recettes (CRUD, duplication), les calculs techniques (IBU/ABV, carbonatation), la dimension communauté (partage, commentaires, notes), la dimension durable (réutilisation des drêches, fournisseurs locaux) et l’ergonomie (mode hors-ligne, accessibilité).

* **Priorisation des besoins (MoSCoW)** : Une fois la liste des fonctionnalités établie, j’ai appliqué une priorisation de type **MoSCoW** (Must have, Should have, Could have, Won’t have) pour définir le **MVP** (Minimum Viable Product) à réaliser dans le temps imparti. Concrètement, j’ai marqué comme **Must-Have** toutes les fonctionnalités critiques sans lesquelles le projet perd son sens : par exemple, la gestion des recettes (création, modification) est un must, tout comme les calculs automatiques d’IBU/ABV qui font la valeur ajoutée de l’appli, et un minimum de guidage utilisateur pour ne pas rebuter les débutants. En **Nice-to-Have** (Could have), j’ai mis des choses comme l’espace communautaire complet (partage public, commentaires) ou la recherche avancée par critères, utiles mais pas vitales pour une v1. Enfin, j’ai relégué en **Future Enhancements** des idées plus poussées comme l’intégration IoT (capteurs temps réel) ou des suggestions basées sur de l’IA – intéressant, mais clairement hors scope pour le projet initial. Ce travail de priorisation m’a permis d’élaborer un **périmètre clair pour la Phase de développement** : je savais exactement quelles user stories implémenter en priorité (Must-Have), et quoi laisser de côté si le temps manquait. J’ai également utilisé cette priorisation pour **planifier les phases** dans l’échéancier (voir Phase 3 correspond au dév des Must-Have).

* **Maquettage de l’application** : En parallèle de l’analyse textuelle, j’ai commencé à **maquetter l’interface** pour valider les choix fonctionnels. J’ai d’abord produit des **schémas de navigation** (comment l’utilisateur passe de l’écran d’accueil à la création de recette, etc.) et des **wireframes** basse fidélité pour chaque écran clé. Par exemple, j’ai dessiné sur papier (puis sur Figma) la page “Liste des recettes” avec une simple liste d’items, un bouton “+” flottant pour ajouter, et un menu hamburger pour accéder aux autres sections. L’objectif était de s’assurer que toutes les stories trouvaient un point de chute dans l’UI. Ces wireframes ont été validés avec mon formateur qui jouait le rôle du client, ce qui correspond à une **réunion de recueil de besoin** en mode agile où on valide qu’on a bien compris les attentes. Ensuite, j’ai affiné ces wireframes en **maquettes haute fidélité** sur Figma, en appliquant déjà une charte graphique de base (couleurs brunes et dorées rappelant la bière, icônes évocatrices 🍺). Ce travail de design préliminaire m’a permis de détecter quelques problèmes d’ergonomie dès le début (par exemple, il manquait un écran pour visualiser une recette en détail après sa création – j’ai ajouté une vue “Détail recette” suite à ça). Au final, j’ai obtenu un **prototype cliquable** simulant le parcours utilisateur principal, que j’ai pu présenter lors de la revue de fin de Phase 1.

En synthèse, cette phase d’analyse et maquettage m’a permis de **formaliser les besoins** de manière claire et de les traduire en éléments concrets (stories, maquettes). J’ai ainsi montré ma capacité à *“analyser les besoins et maquetter une application”*. Les choix effectués ici ont posé les bases solides pour la suite du projet, évitant des changements majeurs en cours de route. De plus, ce travail précoce a servi de référence lors de la phase de test (les critères d’acceptation des user stories m’ont servi de scénarios de test) et a assuré que le développement réponde bien à la demande initiale du « client ».

### Définition de l’architecture logicielle multicouche (Frontend, Backend, Base de données, Services externes)

Une fois les besoins clarifiés, j’ai abordé la **conception de l’architecture** de l’application. Le titre de l’activité précise “organisée en couches” : en effet, il s’agissait de définir comment séparer le frontend, le backend et la base de données, et quelles seraient les interactions entre ces couches, en tenant compte des aspects **sécurité, performance et évolutivité**.

**Choix des technologies** : Sur la base des besoins identifiés, j’ai d’abord confirmé les choix technologiques principaux (souvent amorcés dès l’analyse) :

* **Frontend :** React Native était un choix naturel étant donné le besoin mobile multiplateforme, complété par Expo pour accélérer le développement. J’ai validé ce choix en testant rapidement un *Hello World* sur mon téléphone et en estimant que les performances seraient suffisantes pour une app de gestion (on n’est pas sur de la 3D temps réel).
* **Backend :** Node.js avec Express, car je voulais utiliser le même langage (JavaScript/TypeScript) côté front et back – cela facilite la montée en compétence et permet éventuellement de partager du code utilitaire. De plus, Node.js est très adapté pour construire rapidement une API REST et bénéficie d’un large écosystème de packages (jsonwebtoken, sequelize, etc.). J’ai également considéré un temps **Python (Django)** ou **Java (Spring)**, mais ces solutions étaient plus lourdes pour un projet solo de cette envergure. Node/Express offrait un bon compromis rapidité de dév/performance.
* **Base de données :** J’ai opté pour **MySQL** comme SGBD relationnel, car c’est un moteur éprouvé, que je connaissais bien, et qui s’intégrait parfaitement avec Sequelize (ORM choisi). PostgreSQL était l’alternative, mais l’une ou l’autre convenait. J’ai toutefois laissé la porte ouverte en architecture à une couche d’abstraction (ORM) qui permettrait de changer de SGBD sans tout re-développer, le cas échéant. En complément, j’ai prévu l’utilisation de **Redis** (base clé-valeur NoSQL) pour certains usages spécifiques : par exemple, mettre en cache des résultats de calcul ou stocker des sessions utilisateurs, dans l’optique d’améliorer les performances et la scalabilité. Redis n’est pas indispensable au MVP, mais je l’ai intégré dans l’architecture pour anticiper une montée en charge (et aussi pour démontrer la compétence “SQL & NoSQL”).
* **Autres composants :** J’ai décidé d’intégrer un **service d’authentification** basé sur JWT (librairie jsonwebtoken) plutôt que de partir sur des sessions serveurs classiques, pour favoriser une architecture *stateless* du backend (plus simple à distribuer sur plusieurs serveurs si besoin). J’ai également prévu un petit **service de notifications** (envisagé pour plus tard, via un service externe Firebase Cloud Messaging ou envoi d’emails via NodeMailer) afin d’envoyer des alertes aux utilisateurs (ex : “votre fermentation est terminée!”). Enfin, l’aspect **IoT** m’a conduit à inclure dans l’architecture un canal de communication via MQTT (broker Eclipse Mosquitto) pour recevoir les données de capteurs de température/densité qui seraient placés dans les cuves. Même si cette partie est expérimentale, l’architecture se devait de la prendre en compte pour que je n’aie pas à tout refondre plus tard.

**Architecture multicouche – vue d’ensemble** : Sur la base de ces choix, j’ai réalisé un **diagramme d’architecture** global illustrant les différentes couches et composants du système. En simplifié, cela donne :

* **Couche Présentation (Frontend)** : L’application mobile **React Native** constitue la couche interface utilisateur. C’est la couche avec laquelle interagissent les brasseurs ; elle envoie des requêtes API et affiche les résultats. Elle est découplée du reste et pourrait être remplacée par une autre interface (web app React, par ex.) sans affecter le backend.
* **Couche Métiers (Backend)** : Le serveur **Node.js/Express** fait office d’API Gateway et de couche métier. Il est découpé en sous-composants (services) pour gérer les domaines fonctionnels : Authentification, Recettes, Sessions, Notifications…. J’ai choisi une architecture REST classique : chaque service expose des endpoints HTTP, et éventuellement communique avec d’autres services internes. Par exemple, le service Recettes peut faire appel au service Notifications pour envoyer un message lorsqu’une nouvelle recette est publiée, etc. Le backend contient également la logique de validation, de calcul (ex : calcul d’IBU/ABV se fait côté serveur pour fiabilité), et agrège les données pour le frontend.
* **Couche Données (Database & Persistence)** : Ici on trouve la base **MySQL** qui stocke de manière pérenne toutes les informations (utilisateurs, recettes, ingrédients, etc.). J’ai conçu la base comme **socle central** : tous les services métier du backend y accèdent via l’ORM. En complément, j’ai la base **Redis** (mémoire) pour le caching : par exemple, on pourrait y stocker temporairement les recettes les plus consultées pour accélérer leur accès ou conserver les jetons de rafraîchissement OAuth. J’ai aussi prévu la possibilité d’un stockage de fichiers (images de recettes, etc.) via un service Cloud ou un bucket S3, mais pour le MVP les images (comme le logo) sont embarquées dans l’application.
* **Interactions entre couches** : Le **frontend** communique avec le backend uniquement via des appels **HTTP/HTTPS** vers l’API REST. J’ai prévu d’utiliser HTTPS en production avec un certificat SSL (sécurité oblige), notamment parce que des identifiants transitent lors du login. Le **backend** quant à lui interagit avec la base de données via **Sequelize** (requêtes SQL générées automatiquement), et avec Redis via son client Node (`ioredis`). Les différentes sous-parties du backend (auth, recettes, etc.) ne sont pas des microservices séparés dans le MVP (j’ai jugé qu’introduire une architecture microservices serait trop complexe pour un projet de cette taille), mais j’ai tout de même découpé logiquement les services et indiqué dans l’architecture qu’ils *pourraient* être déployés séparément plus tard. Par exemple, sur le diagramme composant, Auth, Recettes, Sessions apparaissent distincts mais en réalité ils tournent dans le même processus Node pour l’instant. Cette vue composant m’a servi surtout à définir des **responsabilités claires** et à éviter de tout mettre en vrac dans un seul bloc de code.

**Sécurité et contraintes non-fonctionnelles dans l’architecture :** Lors de la définition de l’architecture, j’ai porté une attention particulière aux aspects **sécurité**, **performance** et **résilience**, conformément aux exigences du référentiel (application sécurisée, éco-conception, résilience informatique…). Concrètement :

* J’ai intégré dès la conception un **plan de sécurité** du SI : utilisation généralisée de HTTPS, stockage des mots de passe **hachés (bcrypt)** en base, architecture *stateless* pour limiter les possibilités d’élévation de privilège (un token JWT peut être invalidé simplement en le blacklistant ou en changeant la clé secrète), cloisonnement des données utilisateurs par design (chaque recette est liée à un userId, ce qui facilite les contrôles d’accès).
* J’ai prévu la mise en place de **tests de performance** et de charge une fois le MVP développé, pour vérifier que l’architecture tient la route. Par anticipation, j’ai ajouté le cache Redis pour soulager la base sur certains endpoints très lus, et j’ai documenté la possibilité de déployer le backend derrière **NGINX** avec PM2 en cluster pour gérer plus de trafic. En d’autres termes, l’architecture logicielle peut évoluer en architecture déployée sur plusieurs nœuds sans modification majeure du code (par exemple, deux instances du backend derrière un reverse proxy, la base sur un serveur distinct).
* J’ai aussi réfléchi à l’**éco-conception** : cela passe par des choix architecturaux limitant la surconsommation. Par exemple, éviter les allers-retours inutiles front-back (en groupant certaines données dans la même requête), mettre en cache localement sur le mobile des données stables pour éviter de solliciter le réseau à chaque fois (d’où la story sur le mode hors-ligne). J’ai envisagé l’utilisation de *service workers* ou d’une base locale type SQLite sur l’app pour stocker les recettes en cache. Ce sont des choix qui impactent l’architecture car ils ajoutent une couche côté client, mais potentiellement bénéfiques en efficacité énergétique (moins de requêtes = moins de serveurs sollicités). Le référentiel mentionne la prise en compte des besoins d’**éco-conception**, j’ai donc mentionné explicitement dans mon doc d’archi qu’une future amélioration serait de **mesurer l’empreinte** de certaines opérations (ex: calcul intensif ABV, ou images, etc.) et d’optimiser en conséquence, ainsi que d’utiliser des hébergements verts pour la prod.

Après avoir posé ces éléments, j’ai consolidé le tout dans un **dossier d’architecture** complet, comprenant : un **schéma des composants** (décrit plus haut), un **schéma des flux de données** montrant comment les données circulent entre front, API, base, IoT, etc., un **schéma de classes** UML détaillant les principales classes métier (utile pour les développeurs), et un **schéma de la base de données** dont je parle juste après. Chaque document d’architecture renvoie aux autres pour cohérence, ce qui assure une conception **globale cohérente**.

En conclusion sur cette partie, j’ai démontré ma compétence à *“définir l’architecture logicielle d’une application”*, en l’occurrence une architecture **3-tier modulaire** bien pensée pour Brasse-Bouillon. Ce travail m’a valu des retours positifs lors de la revue de conception, car tout était prêt pour attaquer le développement de manière sereine, avec une vision claire de l’ensemble. Les choix réalisés à ce stade se sont avérés judicieux, car je n’ai pas eu à remettre en question l’architecture en cours de route : preuve d’une conception initiale solide.

### Conception et mise en place de la base de données relationnelle (modélisation et implémentation SQL)

Le **modèle de données** est souvent le cœur d’un projet applicatif, et Brasse-Bouillon ne fait pas exception. J’ai donc accordé une attention particulière à la **conception de la base de données** lors de l’activité-type 2. Le but était de définir une base **relationnelle** robuste, normalisée, couvrant tous les besoins fonctionnels, puis de la créer physiquement et de la peupler pour les tests.

**Modélisation conceptuelle (MERISE/UML)** : Sur la base des informations collectées en Phase 1, j’ai dessiné un **MCD (Modèle Conceptuel de Données)** pour représenter les entités du système et leurs relations. Utilisant la notation UML, j’ai identifié les entités suivantes (voir tableau) :

| Entité               | Description (rôle dans l’application)                                |
| -------------------- | -------------------------------------------------------------------- |
| **User**             | Utilisateur de l’application (brasseur).                             |
| **Recipe**           | Recette de bière créée par un utilisateur.                           |
| **Ingredient**       | Ingrédient pouvant entrer dans une recette (malt, houblon, etc.).    |
| **RecipeIngredient** | Association *n\:n* entre Recipe et Ingredient, avec quantité.        |
| **BrewSession**      | Session de brassage planifiée/réalisée, liée à une recette.          |
| **BrewingEquipment** | Équipement de brassage (cuve, fermenteur) détenu par un utilisateur. |
| **Comment**          | Commentaire d’un utilisateur sur une recette.                        |
| **Rating**           | Note (étoiles) donnée par un utilisateur à une recette.              |
| **Notification**     | Notification envoyée à un utilisateur (rappel de session, etc.).     |

Ce modèle conceptuel décrit l’univers de Brasse-Bouillon de manière **indépendante de la technologie**. J’ai ensuite validé ce MCD en le traduisant en **diagramme entité-association** UML, que j’ai inclus dans la documentation. Par exemple, on y voit que :

* Un **User** peut créer plusieurs **Recipe** (relation 1-N).
* Un **Recipe** peut contenir plusieurs **Ingredient** et inversement (relation N-N modélisée par l’entité associative RecipeIngredient).
* Un **User** peut lancer plusieurs **BrewSession** (1-N) et chaque BrewSession est reliée à une Recipe (N sessions pour 1 recette possible).
* J’ai également modélisé que User peut avoir plusieurs Equipment, qu’une Recipe peut avoir des Comments et des Ratings de plusieurs Users, etc. Toutes ces relations ont été définies avec les bons cardinalités et libellés (par ex. *User "écrit" Comment*, *Recipe "noté par" Rating*).

**Passage au modèle logique et physique** : Après validation du modèle conceptuel (j’ai revu le diagramme avec un formateur pour confirmer la pertinence), j’ai dérivé le **modèle logique**/physique pour implémentation dans MySQL. Concrètement, cela signifie définir les tables SQL correspondantes, avec leurs colonnes, types, clés primaires et clés étrangères. J’ai créé un script `database_schema.sql` (ou son équivalent via Sequelize) comprenant les instructions de création de tables. Par exemple :

* Table `users` : id (PK auto), name, email (unique), password\_hash, role (valeurs possibles: admin/brasseur/utilisateur), created\_at…
* Table `recipes` : id (PK), user\_id (FK vers users), name, description, instructions, abv, ibu, created\_at…
* Table `ingredients` : id, name, category (par ex "houblon", "malt", "levure").
* Table `recipe_ingredients` : recipe\_id (FK), ingredient\_id (FK), quantity, unit. J’ai défini la clé primaire composite (recipe\_id, ingredient\_id) pour éviter les doublons du même ingrédient dans une recette, et mis en place la contrainte ON DELETE CASCADE sur recipe\_id et ingredient\_id pour suivre la suppression de recettes ou d’ingrédients.
* Tables `brew_sessions`, `comments`, `ratings`, `brewing_equipments`, `notifications` avec leurs colonnes et clés respectives selon le MCD. Certaines de ces tables (comments, ratings) incluent une contrainte *UNIQUE* combinée sur (user\_id, recipe\_id) pour éviter qu’un même user ne note deux fois la même recette, par exemple.

J’ai pris soin de normaliser le schéma au moins jusqu’en **3ème forme normale** pour éviter les duplications de données. Par exemple, les ingrédients sont dans leur table séparée, on ne stocke pas directement le nom de l’ingrédient dans la recette (seulement via l’association) – ça garantit l’unicité de la définition d’un ingrédient. De même, j’ai introduit une petite table de correspondance pour les rôles utilisateur (Admin, Brasseur, Visiteur) afin de ne pas avoir des strings en dur partout (on peut ainsi faire évoluer les rôles plus facilement).

**Mise en place via l’ORM Sequelize :** Plutôt que d’écrire tout le SQL à la main, j’ai utilisé **Sequelize** pour créer les modèles et générer la base. J’ai défini chaque modèle dans les fichiers JS correspondants, en spécifiant les champs et les relations. Par exemple, dans `backend/models/Recipe.js` :

```js
// Définition du modèle Recipe avec Sequelize (simplifié)
module.exports = (sequelize, DataTypes) => {
  const Recipe = sequelize.define('Recipe', {
    name: DataTypes.STRING,
    description: DataTypes.TEXT,
    ibu: DataTypes.FLOAT,
    abv: DataTypes.FLOAT,
    // ... autres champs
  });

  Recipe.associate = models => {
    Recipe.belongsTo(models.User, { foreignKey: 'userId' });
    Recipe.belongsToMany(models.Ingredient, { through: models.RecipeIngredient });
    Recipe.hasMany(models.Comment);
    Recipe.hasMany(models.Rating);
  };

  return Recipe;
};
```

Ce genre de définition est très concis comparé au SQL brut, et Sequelize s’est chargé de créer les tables correspondantes lors de l’exécution de `sequelize.sync()` ou via des **migrations**. J’ai d’ailleurs écrit des **scripts de migration** pour la base, par exemple une migration initiale qui crée toutes les tables dans le bon ordre (Users puis Recipes puis RecipeIngredients etc.), afin de bien respecter les contraintes de clés étrangères. J’ai aussi prévu des **données de test (seeds)** : un ou deux utilisateurs factices, quelques ingrédients de base (Houblon Cascade, Malt Pilsner, Levure US-05…), et une recette “Pale Ale” d’exemple pour vérifier que tout fonctionne. Ces seeds m’ont servi en Phase 4 pour remplir la base et exécuter les tests fonctionnels.

**Gestion des droits d’accès à la base :** Le référentiel mentionne la nécessité de définir les *droits d’accès des utilisateurs* sur la base. Dans un contexte web moderne avec ORM, on n’expose pas directement la base aux utilisateurs, donc la gestion se fait plutôt au niveau applicatif (via le backend). Néanmoins, j’ai quand même sécurisé l’accès MySQL en créant un utilisateur spécifique **MySQL “brasseur”** avec uniquement les droits nécessaires sur la base `brasse_bouillon`. Ainsi, même si quelqu’un obtenait l’accès DB via l’application, il ne pourrait pas faire autre chose que de la lecture/écriture sur cette base (pas de DROP sur d’autres bases, etc.). En dev, j’avais l’utilisateur root, mais en config de prod j’ai prévu d’utiliser ce compte restreint. J’ai également segmenté les droits applicatifs via les rôles dans l’application : par exemple, un utilisateur standard ne peut ni accéder aux données d’un autre (vérification par userId dans toutes les requêtes), ni effectuer d’actions admin. Si on avait eu un DBA ou un service IT, j’aurais fourni un **schéma de comptes** (compte admin pour maintenance DB, compte app pour usage courant).

**Validation de la base** : Après avoir mis en place la BDD, j’ai exécuté un **plan de test SQL** pour vérifier la cohérence du schéma (c’était la Phase 4 en partie). J’ai par exemple utilisé MySQL Workbench ou la console MySQL pour lister les tables (`SHOW TABLES`) et décrire chacune (`DESCRIBE recipes;`), afin de vérifier que tous les champs étaient là avec le bon type (ex : `ibu` et `abv` en FLOAT). J’ai inséré manuellement des données de test via des requêtes INSERT, puis je me suis assuré que les **contraintes** fonctionnaient : en supprimant un user de test, ses recettes étaient bien supprimées automatiquement (ON DELETE CASCADE validé : la requête SELECT derrière ne retourne rien). J’ai aussi testé une contrainte d’unicité en tentant d’insérer un doublon d’email utilisateur – j’ai obtenu l’erreur 1062 attendue (duplicate entry). Ces tests m’ont rassuré sur la solidité du modèle implémenté.

En résumé, j’ai démontré ici la compétence *“concevoir et mettre en place une base de données relationnelle”* en passant par toutes les étapes : modélisation conceptuelle, transformation en base physique, utilisation d’un **ORM** moderne pour faciliter les opérations, et validation par des tests. La base de données de Brasse-Bouillon est désormais en place, évolutive (j’ai documenté comment l’aligner si on ajoute de nouvelles entités) et suffisamment optimisée (indexes implicites via les PK/FK, pas de redondance abusive de données). Cette base a servi de fondation fiable pour tout le code métier développé dans l’activité-type 1, et n’a pas montré de lacune majeure pendant les tests – preuve d’une conception réussie.

### Développement des composants d’accès aux données (SQL et NoSQL)

Le dernier volet de l’activité-type 2 concerne la réalisation des **composants d’accès aux données**. Cela recouvre tout ce qui permet à l’application de dialoguer avec les sources de données, qu’elles soient SQL (BDD relationnelle) ou NoSQL. Dans mon projet, cela s’est concrétisé de deux façons : d’une part l’utilisation de **l’ORM Sequelize** dans le backend pour accéder à MySQL, d’autre part l’intégration (en cours) d’un **cache Redis** pour optimiser certains accès.

**Accès SQL via l’ORM (Sequelize) :** Comme évoqué, j’ai utilisé Sequelize comme couche d’abstraction entre mon code Node.js et la base MySQL. Ainsi, les controllers du backend manipulent des objets JavaScript (instances des modèles) plutôt que d’écrire du SQL brut. Par exemple, dans le `recipeController`, pour récupérer toutes les recettes, j’ai simplement appelé `Recipe.findAll()`. Cette commande génère en coulisses un SELECT \* FROM recipes, crée des objets Recipe pour chaque ligne et me les retourne. De même, pour insérer une recette j’utilise `Recipe.create({...})` qui génère l’INSERT. L’ORM se charge également de remplir les champs automatiques (timestamps), de gérer les relations (quand j’inclus Ingredient, il fait le JOIN nécessaire) et de remonter les erreurs sous forme d’exceptions Node (que je catch pour renvoyer un code HTTP propre).

J’ai donc développé mes **composants d’accès aux données SQL** essentiellement via Sequelize. On peut considérer que chaque **Model Sequelize** est un composant d’accès aux données : par exemple, j’ai un module `Ingredient` qui expose des méthodes pour interroger la table `ingredients`. Dans certains cas où des requêtes complexes étaient nécessaires (par ex, calculer la moyenne des notes d’une recette, ou filtrer les recettes par ingrédient), j’ai utilisé soit les **méthodes Sequelize** (ex: `Recipe.findAll({ include: {... where: {...}}})` peut me sortir toutes les recettes contenant un ingrédient particulier), soit j’ai écrit une requête brute via `sequelize.query("SELECT ...")` pour optimiser. J’ai documenté ces requêtes SQL spécifiques dans un fichier `database_interactions.md`, afin de garder une trace des accès un peu pointus et de justifier certains choix (par exemple, j’ai noté qu’une requête custom était utilisée pour la recherche multi-critères de recettes car l’ORM avait des limitations sur une requête trop complexe).

Grâce à cette couche ORM, le code Node reste **indépendant du SGBD** : je pourrais presque basculer sur PostgreSQL en ne changeant qu’une ligne de config (dialect) et en ajustant deux trois types si besoin, Sequelize ferait le reste. Ce découplage fait partie de la notion d’application multicouche : la couche d’accès aux données est interchangeable et cachée derrière l’interface de l’ORM.

**Exploitation du NoSQL (Redis) :** Le second aspect, c’est l’utilisation de **Redis** pour stocker certaines données en mémoire. J’ai décidé d’intégrer Redis principalement pour stocker les **sessions JWT invalidées** (lors d’un logout anticipé, pour invalider un token côté serveur jusqu’à expiration), et potentiellement pour mettre en cache certaines réponses lourdes. J’ai donc configuré un client Redis dans mon backend (`redisClient = redis.createClient()`), connecté soit à un conteneur Redis local en dev, soit à un Redis Cloud en prod.

J’ai développé un composant d’accès spécifique pour ce cache : un module `cacheService.js` qui expose des fonctions `get(key)`, `set(key, value, ttl)` etc., encapsulant les appels Redis. Par exemple, lors d’une requête GET /recipes, je pourrais d’abord vérifier si la liste des recettes n’est pas déjà en cache (clé `recipes:all`) ; si oui je la renvoie tout de suite, sinon je la calcule via la BDD puis je la stocke dans Redis pour les prochains appels. Ce type de mécanisme accélère l’application et réduit la charge BDD.

Concrètement, j’ai commencé par un usage simple : lors du **logout** d’un utilisateur, j’insère son token JWT dans Redis avec une clé du type `bl_token:<tokenId>` et une expiration égale au temps restant du token. Ainsi, le middleware `verifyToken` chaque fois qu’il valide un token consulte aussi cette liste de tokens blacklistés dans Redis pour s’assurer que le token n’a pas été révoqué. Cela ajoute très peu de latence et renforce la sécurité (revocation côté serveur). J’ai également préparé le terrain pour utiliser Redis comme **file d’attente de tâches** (par ex, planifier l’envoi d’une notification 1 semaine après la création d’une recette pour demander “alors, dégustée ?” – ce n’est pas implémenté mais Redis pourrait servir de buffer dans une archi plus complexe).

À ce stade du projet, l’utilisation de Redis reste limitée (on est toujours en MVP), mais j’ai documenté l’**intégration de Redis** dans l’architecture et le code : j’ai même créé une branche `refactor/redis-integration` où je travaillais sur la mise en cache de la liste d’ingrédients, mentionnée dans une issue GitHub. Ce qui compte, c’est que j’ai démontré savoir combiner des **données SQL et NoSQL** de manière cohérente dans une application. L’architecture peut donc être qualifiée de **polyglotte** (mixte SQL/NoSQL) sur certains aspects, ce qui est de plus en plus fréquent en entreprise pour tirer parti des forces de chaque technologie.

**Exemple d’extraction de données** : Pour illustrer un composant d’accès aux données, prenons la fonctionnalité “Calcul IBU/ABV” qui nécessite de lire certaines infos en base (densités des moûts, acides alpha des houblons). J’ai créé à titre d’exemple un **diagramme de séquence** du calcul IBU/ABV montrant comment le front envoie une recette, le backend va chercher dans la table des ingrédients les données nécessaires (par ex, pour chaque houblon de la recette, récupérer son alpha-acide stocké en base), puis effectue le calcul et renvoie le résultat. Le composant d’accès aux données ici est la couche ORM qui, via une méthode `Ingredient.findByPk(id)` ou similaire, me renvoie l’info. Tout cela pour dire que j’ai su **développer les composants d’accès aux données** tant du côté code (fonctions JS interrogeant l’ORM) que du côté infrastructure (mise en place de Redis et MySQL, drivers installés et utilisés).

Pour clore ce chapitre, l’activité-type 2 m’a amené à agir comme **concepteur-architecte** de l’application. J’ai **analysé, maquetté, architecturé, modélisé et mis en place les données**, en mobilisant des compétences de réflexion, de projection et des connaissances techniques pointues (MERISE, UML, SQL/NoSQL…). Le résultat est une application **bien conçue**, sur des bases solides, prête à être développée (ce que j’ai fait en activité-type 1) et à évoluer. Cette expérience a renforcé ma capacité à prendre de la hauteur sur un projet, à anticiper les besoins futurs, et à produire des livrables de conception de qualité (les diagrammes et docs d’architecture que j’ai fournis pourraient être lus par un autre développeur ou un jury pour comprendre rapidement le fonctionnement du système).

---

## Activité-type 3 : Préparer le déploiement d’une application sécurisée

*(**Bloc de compétences 3 :** Préparer et exécuter les plans de tests d’une application ; Préparer et documenter le déploiement d’une application ; Contribuer à la mise en production dans une démarche DevOps)*

La troisième et dernière activité-type concerne la finalisation du projet avant sa mise en service. Cela correspond, dans mon projet Brasse-Bouillon, aux **Phase 4 (Tests et Validation)** et **Phase 5 (Déploiement & Maintenance)**, ainsi qu’à certaines tâches transverses de qualité logicielle. Je vais expliquer comment j’ai **préparé et exécuté des tests** pour m’assurer de la conformité de l’application aux besoins (y compris tests de sécurité), comment j’ai **préparé le déploiement** en production (conteneurisation, documentation d’installation, configuration) et comment j’ai adopté une démarche de type **DevOps** pour faciliter la mise en production continue (intégration continue, scripts de build, etc.). En somme, cette activité illustre ma capacité à livrer une application fiable, déployable et maintenable, bouclant ainsi le cycle de développement logiciel.

### Élaboration et exécution des plans de tests (Tests unitaires, fonctionnels, sécurité)

**Stratégie de test** : Avant même d’écrire le moindre test, j’ai défini une **stratégie de test** couvrant plusieurs niveaux : tests unitaires (vérifier chaque fonction/méthode critique en isolation), tests d’intégration (vérifier qu’un ensemble de composants fonctionne ensemble, ex: une requête API du front jusqu’à la base), tests fonctionnels (valider que chaque exigence du cahier des charges est remplie, typiquement en suivant les user stories), et tests de sécurité (essayer des scénarios d’attaque courants). J’ai consigné cette stratégie dans un plan de test écrit en Phase 4.

**Mise en place des tests unitaires (Phase 3 & 4)** : Durant le développement, j’avais déjà commencé à écrire quelques tests unitaires avec **Jest**. Par exemple, j’ai un test sur la fonction de calcul d’ABV pour vérifier que pour une densité initiale et finale données, le résultat est correct (ex : OG=1.050, FG=1.010 donne \~5.25% ABV). J’ai également un test unitaire sur le middleware d’authentification JWT : je simule un appel avec un token invalide et je vérifie que la réponse est bien un 401 Unauthorized. Ces tests, exécutables via `npm test`, m’ont servi de filet de sécurité pendant les refactorings. Bien sûr, au début j’avais des tests très simples (le fameux test “1+1=2” qui assure que Jest est opérationnel), puis j’ai enrichi progressivement. Au total, la couverture n’est pas exhaustive (faute de temps, tous les composants ne sont pas couverts à 100%), mais j’ai couvert les parties critiques (auth, calculs, controleurs principaux). Le CI GitHub exécute ces tests à chaque push, ce qui me prévient immédiatement en cas de régression.

**Tests d’intégration (Postman & automatisés)** : J’ai créé une **collection Postman** regroupant tous les appels API de l’application (login, CRUD recettes, etc.) avec des jeux de données de test. Cela m’a permis de rapidement tester manuellement le bon enchaînement front-back. J’ai par exemple un scénario Postman “Créer une recette complète” qui : fait un POST /auth/login pour obtenir un token, stocke le token, puis enchaîne sur POST /recipes avec des ingrédients, puis GET /recipes/\:id pour vérifier que la recette est bien récupérable. Cette suite manuelle a été très utile pour détecter des oublis (un bug trouvé : j’avais oublié de vérifier l’unicité du nom de recette, non bloquant mais signalé pour amélioration). J’ai également exploré l’outil **Cypress** pour éventuellement automatiser un test de bout en bout sur l’UI mobile (via Cypress + expo-web), mais par manque de temps je ne l’ai pas finalisé. Néanmoins, j’ai maintenu à jour mes scénarios Postman et je les ai fournis en annexe du dossier.

**Plan de test fonctionnel (validation des exigences)** : Pour être sûr de ne rien oublier, j’ai construit un **tableau de suivi** listant chaque **exigence** du référentiel ou du cahier des charges, et notant si elle était testée et **conforme**. Par exemple : *“Présentation des interfaces utilisateur ergonomiques”* – Référence REAC Bloc 1 – Exemple dans le projet : interfaces réalisées selon maquettes, CRUD recettes fonctionnel avec calculs IBU/ABV – Conformité : Oui. J’ai fait cela pour les principaux points, comme *“Justification des choix techniques”* (couvert par la doc de conception), *“Rapport de tests de qualité (unitaires, fonctionnels)”* (couvert par mes résultats de tests et scanning OWASP), *“Utilisation d’une méthodologie agile”* (évidente via mon suivi de projet), etc. Ce tableau fait partie de ma **matrice de conformité** préparée en Phase 6 (soutenance) et m’a aidé à pointer du doigt quelques tests manquants (j’ai par exemple ajouté un test de l’auth en mode “rôle admin” bien que je n’aie pas d’UI pour ça, juste pour vérifier la route protégée).

**Tests de sécurité** : J’ai voulu m’assurer que l’application était **sûre** face aux menaces courantes. J’ai donc effectué quelques tests spécifiques :

* **Test d’injection SQL** : J’ai tenté de passer des chaînes contenant des quotes ou des commandes SQL dans les inputs (par ex, nom de recette = `"; DROP TABLE recipes; --`). Grâce à l’ORM Sequelize qui paramètre les requêtes, ces injections n’ont eu aucun effet néfaste : soit elles ont été échappées, soit rejetées si non conformes. Ce test m’a rassuré sur la protection contre les injections SQL.
* **Test XSS (Cross-site scripting)** : J’ai testé l’envoi de balises `<script>alert(1)</script>` dans les champs textes (description de recette, commentaire). Côté affichage mobile, ces balises ne sont pas interprétées par React Native (elles seraient affichées littéralement si jamais), donc pas de risque XSS direct dans l’app. Pour le futur site web (puisqu’on a aussi une version web envisagée), j’ai prévu d’échapper/filtrer ces contenus ou d’utiliser des composants sécurisés. La vigilance XSS est donc notée, et en l’état l’impact est mineur.
* **Tests d’accès non autorisés** : J’ai vérifié qu’en appelant des endpoints sans token ou avec un token invalide, j’obtenais bien les codes d’erreur appropriés (401 ou 403). Par exemple, un `GET /recipes` sans token renvoie 401 Accès refusé, un `DELETE /recipes/:id` avec un token d’un autre utilisateur renvoie 403 Forbidden. Ces tests étaient cruciaux pour s’assurer que mes contrôles d’accès implémentés (middlewares JWT, vérification propriétaire) fonctionnent bien.
* **Test de robustesse aux volumes** : j’ai simulé via script l’insertion de 100 recettes d’un coup pour voir si l’application tenait le coup. La base a encaissé sans souci, et la récupération des 100 recettes reste rapide (quelques centaines de ms) grâce à l’index sur user\_id. Ça reste modeste, mais c’est bon signe que l’application peut évoluer en volume (et dimensionnement du serveur mis à part, le code ne bloque pas).
* **Outils automatisés** : J’ai aussi passé un petit scan avec **OWASP ZAP** (un outil de scan de vulnérabilités web). Le scan n’a pas révélé de faille critique sur les endpoints testés, juste des alertes mineures (manque de certains headers de sécurité comme Content-Security-Policy, ce que je corrigerai en config serveur/Nginx plus tard).

**Correction des anomalies** : Chaque bug ou écart découvert pendant les tests a été documenté dans une **issue GitHub** avec label *bug*, puis corrigé dans un commit *fix: ...* spécifique. Par exemple, un bug #17 portait sur le fait qu’une recette pouvait être enregistrée sans ingrédient, ce qui posait problème pour le calcul d’IBU. J’ai corrigé en ajoutant une validation serveur refusant l’enregistrement d’une recette sans ingrédient, et j’ai clos l’issue en question. Ce suivi assure la traçabilité des problèmes et leur résolution – c’est une bonne pratique que j’ai tenue même en solo, pour simuler un environnement qualité pro.

En conclusion, la préparation et l’exécution des tests pour Brasse-Bouillon ont été conduites de manière méthodique, couvrant tous les aspects (unitaires, intégration, fonctionnel, sécurité). J’ai ainsi pu vérifier que l’application **remplit bien les critères attendus** et j’ai pu corriger les quelques écarts avant la mise en production. Cela démontre pleinement ma compétence à *“préparer et exécuter les plans de tests d’une application”*, en visant la conformité par rapport aux besoins et la fiabilité du produit final.

### Préparation et documentation du déploiement de l’application

Une fois les tests concluants, il est temps de penser à livrer l’application. J’ai donc travaillé sur la **Phase 5 – Déploiement**, en préparant tout le nécessaire pour installer et exécuter Brasse-Bouillon en environnement de production (ou sur un serveur tiers). Plusieurs actions ont été menées : **documenter la procédure d’installation**, **configurer la conteneurisation Docker**, préparer les **scripts de déploiement**, et mettre en place le nécessaire pour la **maintenance** (supervision, sauvegardes).

**Guide d’installation et configuration** : J’ai rédigé un **Guide d’Installation** détaillé pour le backend (et un plus succinct pour le frontend). Ce guide couvre deux modes : installation manuelle ou via Docker. Pour l’installation manuelle, j’y explique comment cloner le repo, installer Node.js, installer MySQL, configurer les variables d’env, puis lancer les migrations et démarrer le serveur. Pour Docker, j’ai fourni un fichier `docker-compose.yml` type et expliqué comment le personnaliser. Le guide mentionne aussi les prérequis (version de Node, d’NPM, Docker, etc.). J’ai veillé à écrire ce document dans un langage accessible, pour qu’un administrateur système ou un examinateur puissent suivre les étapes pas à pas sans me contacter. J’ai également listé les **commandes utiles** (par ex: `docker-compose up --build -d` pour lancer en arrière-plan, ou `npx sequelize-cli db:migrate` en cas d’installation manuelle).

Ce document fait partie intégrante du **dossier de déploiement**. En complément, j’ai créé un **README de production** qui résume comment configurer les variables prod (par ex, mettre `NODE_ENV=production` et configurer le CORS avec le domaine de l’appli). J’ai aussi noté les **préconisations de sécurité** pour la prod : générer une clé JWT secrète robuste, activer SSL, vérifier les réglages du firewall (ouvrir juste les ports 80/443 pour l’API, 1883 si MQTT utilis\&eacute, etc.), mettre en place un service comme **PM2** pour gérer le processus Node en cas de crash, etc. Toutes ces informations seront utiles pour celui qui déploiera l’application sur un serveur.

**Conteneurisation Docker** : Afin de faciliter le déploiement multiplateforme et isoler l’environnement, j’ai créé des **Dockerfiles** pour le backend (et prévu un pour le frontend web éventuel). Le Dockerfile backend est très simple : basé sur une image Node officielle (node:20), copie du code, installation des dépendances, exposition du port 3000, et CMD `npm run dev` ou `npm start` selon le contexte. J’ai testé ce Dockerfile en local : j’ai pu *docker build* l’image et *docker run* le conteneur, puis accéder à l’API via `http://localhost:3000`. Le front étant une appli mobile, je ne la conteneurise pas pour la distribuer (on génèrera un binaire ou on passera par Expo), mais j’ai tout de même containerisé le backend, la base et les services annexes via **Docker Compose**. Mon fichier compose inclut : le service `backend` (build du Dockerfile), le service `database` (Postgres dans la doc initiale, mais j’ai adapté à MySQL selon le choix final), le service `redis`, et même un service `mqtt_broker` (Mosquitto) pour l’IoT. Ainsi, en une commande, on peut déployer une stack complète sur n’importe quelle machine Docker.

**Scripts de déploiement (CI/CD)** : Dans la continuité de la démarche DevOps, j’ai configuré un **workflow GitHub Actions** pour automatiser les étapes de build et test, et simuler un déploiement. Le fichier `.github/workflows/ci.yml` contient un job “Build & Test” qui tourne à chaque push : il installe les dépendances, lance ESLint et Jest sur backend et frontend. Si tout est vert, un second job “Simulated Deployment” se lance sur la branche main. Ce job pour l’instant ne déploie pas réellement (je n’avais pas d’hébergement configuré durant la formation), il affiche juste un message de succès dans les logs. Mais l’infrastructure est prête : je pourrais aisément ajouter une étape pour construire l’image Docker et la pousser sur DockerHub, voire pour déployer sur un PAAS (Heroku, AWS). J’ai documenté cela dans `docs/architecture/ci_cd.md` comme piste d’amélioration. L’important est que la chaîne CI/CD est en place : on a une **Intégration Continue** robuste, et un début de **Déploiement Continu** (il suffirait d’enlever le flag “Simulated” pour rendre la mise en production automatique sur main). Cette démarche illustre bien ma contribution à la mise en production dans un esprit DevOps.

**Environnements de test et production** : J’ai défini dans la doc comment créer un **environnement de test** isolé. Par exemple, utiliser une base de données `brasse_bouillon_test` et un fichier .env.test, de manière à pouvoir lancer des tests d’intégration sans risquer les données de dev. Durant la Phase 4, j’ai effectivement utilisé une base de test locale sur laquelle je faisais des essais destructifs (injections, suppressions massives) pour ne pas polluer mes vraies données. Pour l’environnement de production, j’ai listé les variables d’environnement spécifiques (par ex, en prod on activera `logging: false` sur Sequelize, on mettra `DEBUG` sur off, etc.). J’ai aussi évoqué la nécessité de définir des **procédures de rollback** : par ex, garder une sauvegarde de la dernière version stable de l’image Docker, ou une sauvegarde SQL récente de la BDD, au cas où un déploiement se passe mal.

**Supervision et maintenance** : “Déployer” ne suffit pas, il faut aussi prévoir la maintenance. J’ai proposé une solution de **monitoring** simple pour Brasse-Bouillon : utiliser un outil comme **PM2** pour superviser le process Node (PM2 peut redémarrer l’app en cas de crash et fournir des métriques sur la consommation). J’ai également conseillé dans la doc de brancher un **service de log** (ex: Winston qui envoie les logs vers un fichier ou un ELK stack) pour garder des traces en production des erreurs. De plus, j’ai planifié une **stratégie de sauvegarde** de la base de données : par exemple, un cron job qui exporte chaque nuit la base MySQL en fichier .sql et le stocke sur un stockage externe sécurisé. Ceci est mentionné dans le plan de maintenance (phase 5). Enfin, j’ai noté qu’il serait pertinent de mettre en place des **tests de non-régression automatisés** sur la pipeline CI (par ex, utiliser Dependabot pour scanner les dépendances vulnérables, ou déployer sur une plateforme de staging pour exécuter les tests E2E).

Toutes ces préparations font partie intégrante de la compétence *“préparer et documenter le déploiement”*. En effet, j’ai produit un **livrable documentaire** clair (guide d’install, README prod), j’ai mis en œuvre les moyens techniques (Docker, CI/CD) pour qu’un déploiement se fasse de manière **sécurisée et fiable**, et j’ai anticipé la phase post-déploiement (monitoring, backups) pour assurer une **continuité de service**. On peut considérer que si demain je devais remettre le projet à un administrateur système, il aurait tout ce qu’il faut en main pour déployer l’application sans me contacter, ce qui est un signe de qualité.

### Contribution à la mise en production – Démarche DevOps et amélioration continue

Le dernier aspect de l’activité-type 3 porte sur la contribution à la mise en production dans une **démarche DevOps**. J’ai déjà abordé une partie via le CI/CD et Docker, mais je vais expliciter comment je me suis comporté dans un esprit DevOps sur ce projet.

**Culture DevOps adoptée :** Bien que seul sur le projet, j’ai cherché à brouiller la frontière Dev vs Ops en me responsabilisant sur tout le cycle de vie. Je n’ai pas “jeté le code par-dessus le mur” en espérant que ça marche en prod : j’ai moi-même monté les environnements, je les ai scriptés, et j’ai testé le déploiement. Cette attitude est typiquement DevOps : le développeur est responsable non seulement du code qu’il écrit, mais aussi de son comportement en production. Par exemple, quand j’écrivais une nouvelle fonctionnalité, je me demandais systématiquement “Comment je vais la déployer ? Est-ce qu’il faudra une migration de base ? Combien de temps ça prendra ? Est-ce qu’il y aura une indisponibilité ?”. Cela m’a conduit à planifier des *mises en production fréquentes mais petites* (principe d’intégration continue), pour éviter un big bang final.

**Outils collaboratifs tout au long du cycle** : J’ai utilisé GitHub non seulement pour le code, mais aussi pour le **Suivi des versions** (release notes). Par exemple, j’ai créé des **tags** Git (v0.1, v0.2…) à des étapes clés, de sorte à garder des jalons de version. Avant un éventuel déploiement, je peux ainsi identifier la version à déployer. J’ai également écrit un **CHANGELOG** mentionnant les nouveautés/corrections de chaque version. Cette transparence est un aspect DevOps (on partage l’info, on documente les changements pour l’équipe Ops ou les utilisateurs).

**Qualité du code et tests automatisés** : La démarche DevOps inclut souvent d’automatiser tout ce qui peut l’être. J’ai automatisé les tests et l’analyse de code sur chaque push, ce qui est un pilier de l’**Intégration Continue**. J’ai aussi configuré des **hooks Git** (via Husky par ex.) pour empêcher de committer du code non linté ou des tests cassés. Ainsi, la branche main est toujours dans un état déployable : c’est un principe clé (on évite d’avoir une main instable qui retarde le déploiement). Grâce à cela, je pourrais déployer à tout moment la dernière version sans crainte, car la CI m’a garanti qu’elle passe les checks.

**Conteneurs et Infrastructure as Code** : En fournissant un `docker-compose.yml`, j’ai pratiqué en quelque sorte l’**Infrastructure as Code** – on décrit dans un fichier texte toute l’infrastructure logicielle (services, ports, volumes). Cela permet de versionner l’infra comme le code, d’y appliquer les mêmes revues et tests (j’aurais pu imaginer un test automatique qui lance `docker-compose config` pour valider la syntaxe du fichier). J’ai aussi découvert et documenté l’utilisation possible de **Terraform** ou d’**Ansible** pour aller plus loin (ex: provisionner un serveur sur le cloud et y appliquer mon docker-compose). Ce n’était pas exigé dans le projet, mais le fait d’y penser fait partie de la mentalité DevOps (automatiser jusqu’au déploiement serveur).

**Simulation de load et tuning** : Dans un esprit *“Ops”*, j’ai fait quelques tests de charge basiques (voir tests plus haut avec 100 recettes créées). J’ai aussi utilisé l’outil `ab` (Apache Benchmark) pour simuler 50 requêtes concurrentes sur l’endpoint des recettes : le serveur Node a tenu, avec un temps moyen de \~200ms par requête. J’ai interprété ces résultats pour en déduire que le goulot d’étranglement principal serait la base de données si on montait en charge, et que je devrais alors envisager de mettre en place un système de **mise en cache plus agressif** (par ex. mettre Cloudflare ou un cache HTTP pour certaines routes publiques). Cette démarche proactive d’**optimisation** rejoint les compétences transverses attendues (résolution de problème, amélioration continue).

**Retour d’expérience et amélioration continue** : Après chaque phase, j’ai effectué une petite **rétrospective** (même tout seul). Par exemple, à la fin de la Phase 4 (tests), j’ai constaté que j’aurais dû écrire plus de tests dès le début pour gagner du temps, et je l’ai noté comme axe d’amélioration personnel. J’ai également identifié des zones techniques qui pourraient être améliorées dans le futur (ex: améliorer la couverture de tests, ajouter de la surveillance en prod, mettre en place un pipeline CI pour le frontend – actuellement j’ai du tests Jest front très basiques, mais j’aimerais ajouter un test de build Expo pour vérifier que le front continue de compiler sur chaque commit). Cette posture d’**amélioration continue** est très DevOps également, où on cherche toujours à affiner le processus de développement-déploiement.

**Collaboration Dev <> Ops simulée** : Bien que je n’aie pas eu de vrai équipe Ops en face, j’ai communiqué comme si. Par exemple, j’ai préparé un **document de passation** pour l’équipe qui déploierait, listant tous les points d’attention (ports utilisés, variable d’env, tâches de cron à mettre en place). J’ai aussi utilisé un langage adapté dans mes documents techniques : concis, clair, structuré (listes à puces, numérotations d’étapes) pour qu’un **opérateur système** ou un examinateur s’y retrouve facilement. Je me suis mis à la place de quelqu’un qui arriverait sur le projet sans contexte : est-ce qu’il pourrait le lancer rapidement ? Cette empathie inter-profil fait partie des compétences de *communication* transverses attendues, et je pense l’avoir mise en œuvre ici.

En synthèse, ma contribution à la mise en production s’est traduite par un ensemble d’actions concrètes (CI/CD, Docker, docs) et par une **philosophie DevOps** adoptée tout au long du projet (automatisation, partage de l’information, responsabilité bout-en-bout). Grâce à cela, l’application Brasse-Bouillon n’est pas qu’un prototype local : elle est prête à être déployée sereinement dans un environnement réel, avec un minimum d’effort. Cela illustre ma compétence à *“contribuer à la mise en production dans une démarche DevOps”*, compétence qui devient de plus en plus essentielle pour un concepteur-développeur moderne.

---

## Conclusion

Au travers de ces trois activités-types, j’ai pu décrire de manière complète et concrète mon expérience sur le projet **Brasse-Bouillon**. Ce projet m’a permis de mettre en pratique l’ensemble des **compétences du Référentiel 2024** du titre Concepteur-Développeur d’Applications, depuis l’analyse du besoin initial jusqu’au déploiement et à la soutenance finale. J’ai adopté une approche **professionnelle, geek et pragmatique** pour relever les défis posés : qu’il s’agisse de choisir la bonne techno front (et de l’agrémenter d’une bière 🍻 de créativité UI), de sécuriser un backend comme un coffre-fort (en appliquant à la lettre les recommandations de l’ANSSI et de l’OWASP), ou d’automatiser mon pipeline DevOps tel un vrai ingénieur système, j’ai su mobiliser mes compétences techniques et personnelles.

**Bilan des compétences mobilisées :**

* *Bloc 1* (Développement d’une appli sécurisée) : J’ai montré ma capacité à coder une application de A à Z en respectant les bonnes pratiques de sécurité et de qualité. En particulier, j’ai installé un environnement complet, développé des interfaces mobiles ergonomiques, programmé des composants métiers robustes (avec calculs, règles de gestion, validations), et géré mon projet avec méthode (Agile, documentation, communication).
* *Bloc 2* (Conception d’une appli multicouche) : J’ai brillamment assumé le rôle de concepteur en analysant finement le besoin (user stories, priorisation), en concevant une architecture logicielle adaptée (multi-couches, modulable, sécurisée), et en réalisant une base de données relationnelle saine. J’ai également montré une ouverture vers d’autres types de données (NoSQL) pour optimiser mon application.
* *Bloc 3* (Préparation du déploiement) : J’ai mis en place une stratégie de test poussée pour livrer un produit sans défaut majeur, et j’ai préparé tout le nécessaire pour le déploiement : conteneurs Docker, guide d’installation, scripts CI/CD, tout en adoptant les principes DevOps d’automatisation et de collaboration.

Au-delà des compétences techniques, ce projet a été l’occasion de démontrer mes **compétences transversales** : la *communication* (écrite à travers la doc, orale lors de la soutenance simulée, reformulation des besoins client), la *résolution de problèmes* (debuggage, optimisation, prise en compte des retours utilisateurs), et *l’apprentissage continu* (montée en compétence sur Redis, Docker, JWT… au fil du projet). J’ai aussi veillé à garder un état d’esprit **positif et professionnel**, n’hésitant pas à injecter une touche d’humour ou de créativité quand approprié, tout en restant focalisé sur les objectifs.

**Perspectives :** Brasse-Bouillon est désormais en bonne voie pour une mise en production effective. Les prochaines étapes consisteront à déployer l’application sur un serveur accessible aux utilisateurs bêta, puis d’ajouter progressivement les fonctionnalités “nice-to-have” (espace communautaire, etc.). Grâce à la base solide construite durant ce projet, ces évolutions pourront se faire de manière itérative et sécurisée. Je compte également profiter de l’après-projet pour me perfectionner encore, par exemple en implémentant les suggestions d’optimisation évoquées (monitoring avancé, tests E2E, amélioration de l’UX mobile).

En conclusion, la réalisation du présent dossier professionnel m’a permis de prendre du recul sur le travail accompli et de mesurer le chemin parcouru. De la phase d’**initialisation**, où tout n’était qu’idée, à la phase de **soutenance** où je présente fièrement un produit fini, j’ai acquis une expérience précieuse. Ce dossier atteste de ma capacité à mener un projet applicatif **complet et complexe** en autonomie, en endossant successivement les casquettes d’analyste, d’architecte, de développeur, de testeur et d’administrateur. Cette polyvalence, associée à un socle méthodologique solide, fait de moi un candidat pleinement qualifié pour le titre de **Concepteur Développeur d’Applications**.
